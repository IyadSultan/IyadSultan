{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJRnFhNoDsd1p8QBAWXIqF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IyadSultan/IyadSultan/blob/main/iPN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgtgrVezx4Ja"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23bfdf34"
      },
      "source": [
        "# Task\n",
        "Create a comprehensive Jupyter notebook cell that implements a multi-agent medical information processing system using LangGraph and LangChain 1.0. Install packages: langchain, langchain-openai, langchain-community, langgraph, faiss-cpu, tiktoken, python-dotenv, pydantic. Import StateGraph, END, ChatPromptTemplate, ChatOpenAI, BaseModel, Field, List, Dict, Optional, Any, Literal, uuid, datetime, json, pathlib, typing, SequenceMatcher from difflib. Configure Google Colab userdata integration: os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY'). Set DEFAULT_MODEL = \"gpt-4o-mini\", TEMPERATURE = 0.1. Create get_llm() function returning ChatOpenAI with model_name=DEFAULT_MODEL, temperature=TEMPERATURE. Include comprehensive error handling for missing API keys and import failures. Add debug flag configuration and logging setup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab7d0e77"
      },
      "source": [
        "## Setup and configuration\n",
        "\n",
        "### Subtask:\n",
        "Install necessary packages, configure API keys, set up logging, and define constants and helper functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ddcaf9"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step is to install the required packages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "938ff546",
        "outputId": "a650af89-c6e1-4546-a2c6-d3b269a6525b"
      },
      "source": [
        "%pip install -qU langchain langchain-openai langchain-community langgraph faiss-cpu tiktoken python-dotenv pydantic"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74c0fd3b"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries, configure the API key, set up logging, define constants, and create the get_llm function with error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYc1A_PyTiE"
      },
      "source": [
        "import os\n",
        "import uuid\n",
        "import datetime\n",
        "import json\n",
        "import pathlib\n",
        "import logging\n",
        "from difflib import SequenceMatcher\n",
        "from typing import List, Dict, Optional, Any, Literal\n",
        "\n",
        "# Error handling for import failures\n",
        "try:\n",
        "    from langgraph.graph import StateGraph, END\n",
        "    from langchain_core.prompts import ChatPromptTemplate\n",
        "    from langchain_openai import ChatOpenAI\n",
        "    from pydantic import BaseModel, Field\n",
        "    from google.colab import userdata\n",
        "except ImportError as e:\n",
        "    print(f\"Error importing required libraries: {e}\")\n",
        "    # Exit or raise an exception if critical imports fail\n",
        "    raise e # Raising the exception to indicate failure\n",
        "\n",
        "# Configure API key\n",
        "try:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except userdata.NotFound:\n",
        "    print(\"Error: OPENAI_API_KEY not found in Google Colab userdata.\")\n",
        "    # Handle the missing API key (e.g., exit, raise error)\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in Google Colab userdata.\")\n",
        "\n",
        "# Define constants\n",
        "DEFAULT_MODEL = \"gpt-4o-mini\"\n",
        "TEMPERATURE = 0.1\n",
        "\n",
        "# Debug flag configuration\n",
        "DEBUG = False # Set to True to enable debug logging\n",
        "\n",
        "# Logging setup\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "if DEBUG:\n",
        "    logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "def get_llm():\n",
        "    \"\"\"Returns a ChatOpenAI instance with default settings.\"\"\"\n",
        "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "        logging.error(\"OPENAI_API_KEY is not set.\")\n",
        "        raise ValueError(\"OPENAI_API_KEY is not set.\")\n",
        "    return ChatOpenAI(model_name=DEFAULT_MODEL, temperature=TEMPERATURE)\n",
        "\n",
        "logging.info(\"Setup complete: Packages imported, API key configured, constants and get_llm function defined.\")\n",
        "print(\"Subtask: Install necessary packages, configure API keys, set up logging, and define constants and helper functions completed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "820b392c"
      },
      "source": [
        "## Agent definitions\n",
        "\n",
        "### Subtask:\n",
        "Define the different agents and their roles in the medical information processing system.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "409d61e5"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the Pydantic BaseModel `AgentState` and the agent functions as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18904c54"
      },
      "source": [
        "# Task\n",
        "Create a comprehensive Jupyter notebook cell that implements a multi-agent medical information processing system using LangGraph and LangChain 1.0. Install packages: langchain, langchain-openai, langchain-community, langgraph, faiss-cpu, tiktoken, python-dotenv, pydantic. Import StateGraph, END, ChatPromptTemplate, ChatOpenAI, BaseModel, Field, List, Dict, Optional, Any, Literal, uuid, datetime, json, pathlib, typing, SequenceMatcher from difflib. Configure Google Colab userdata integration: os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY'). Set DEFAULT_MODEL = \"gpt-4o-mini\", TEMPERATURE = 0.1. Create get_llm() function returning ChatOpenAI with model_name=DEFAULT_MODEL, temperature=TEMPERATURE. Include comprehensive error handling for missing API keys and import failures. Add debug flag configuration and logging setup. Incorporate the enhanced state schema definition into the system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d91f177c"
      },
      "source": [
        "## Agent definitions\n",
        "\n",
        "### Subtask:\n",
        "Define the different agents and their roles in the medical information processing system, incorporating the enhanced state schema.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa1971af"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the AgentState BaseModel and the agent functions with basic logic and state updates.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b453be7"
      },
      "source": [
        "# Enhanced Medical Multi-Agent System - State Schema Definition\n",
        "# Execute this cell to define comprehensive Pydantic models for medical information processing\n",
        "\n",
        "import os\n",
        "import json\n",
        "import uuid\n",
        "import datetime\n",
        "from typing import List, Dict, Optional, Any, Literal\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "print(\"ðŸ“¦ Importing libraries for enhanced medical schemas...\")\n",
        "\n",
        "# =============================================================================\n",
        "# ENHANCED MEDICAL PROBLEM MODEL WITH PRIORITY CLASSIFICATION\n",
        "# =============================================================================\n",
        "\n",
        "class MedicalProblem(BaseModel):\n",
        "    \"\"\"Represents a medical problem with comprehensive metadata and priority classification.\"\"\"\n",
        "\n",
        "    # Core identification\n",
        "    problem_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
        "    problem_name: str = Field(..., description=\"Name of the medical problem\")\n",
        "    patient_mrn: str = Field(..., description=\"Patient Medical Record Number\")\n",
        "\n",
        "    # Status and Priority - YOUR REQUESTED CATEGORIZATION\n",
        "    status: Literal[\"Active\", \"Inactive\"] = Field(default=\"Active\")\n",
        "    priority_flag: Literal[\"critical\", \"important\", \"regular\"] = Field(\n",
        "        default=\"regular\",\n",
        "        description=\"Priority level: critical=life-threatening, important=significant impact, regular=routine\"\n",
        "    )\n",
        "    severity_level: Optional[Literal[\"mild\", \"moderate\", \"severe\"]] = Field(\n",
        "        default=None,\n",
        "        description=\"Clinical severity assessment\"\n",
        "    )\n",
        "    requires_immediate_attention: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Boolean flag for immediate medical attention required\"\n",
        "    )\n",
        "\n",
        "    # Clinical Classification\n",
        "    is_cancer_related: bool = Field(default=False)\n",
        "    is_treatment_related: bool = Field(default=False)\n",
        "    is_psychosocial: bool = Field(default=False)\n",
        "\n",
        "    # Documentation\n",
        "    evidence: Optional[str] = Field(default=None, description=\"Supporting evidence from clinical notes\")\n",
        "    additional_details: Optional[str] = Field(default=None)\n",
        "    clinical_significance: Optional[str] = Field(default=None)\n",
        "\n",
        "    # Temporal tracking\n",
        "    date_identified: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    last_updated: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    note_source: str = Field(default=\"clinical_note\")\n",
        "\n",
        "    # Attribution\n",
        "    created_by: Optional[str] = Field(default=None)\n",
        "    verified_by: Optional[str] = Field(default=None)\n",
        "\n",
        "print(\"âœ… MedicalProblem model defined with priority flags: critical, important, regular\")\n",
        "\n",
        "# =============================================================================\n",
        "# ENHANCED CARE PLAN MODEL WITH WORKFLOW MANAGEMENT\n",
        "# =============================================================================\n",
        "\n",
        "class CarePlan(BaseModel):\n",
        "    \"\"\"Represents a care plan with comprehensive workflow tracking and urgency management.\"\"\"\n",
        "\n",
        "    # Core identification\n",
        "    plan_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
        "    suggested_plan: str = Field(..., description=\"Description of the care plan\")\n",
        "    mrn: Optional[str] = Field(default=None, description=\"Patient MRN\")\n",
        "\n",
        "    # Urgency and Priority - YOUR REQUESTED CATEGORIZATION\n",
        "    urgency_level: Literal[\"urgent\", \"non-urgent\"] = Field(\n",
        "        default=\"non-urgent\",\n",
        "        description=\"urgent=within 24-48hrs, non-urgent=routine scheduling\"\n",
        "    )\n",
        "    plan_urgency: Literal[\"immediate\", \"same-day\", \"within-week\", \"within-month\", \"routine\"] = Field(\n",
        "        default=\"routine\",\n",
        "        description=\"Detailed urgency timeline\"\n",
        "    )\n",
        "\n",
        "    # Workflow Status Management - YOUR REQUESTED STATUS TRACKING\n",
        "    workflow_status: Literal[\"pending\", \"delayed\", \"overdue\", \"in-progress\", \"completed\", \"cancelled\"] = Field(\n",
        "        default=\"pending\",\n",
        "        description=\"Current workflow state: pending/delayed/overdue/in-progress/completed/cancelled\"\n",
        "    )\n",
        "\n",
        "    # Date Management - YOUR REQUESTED DATE TRACKING\n",
        "    date_initiated: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date when plan was started (YYYY-MM-DD)\"\n",
        "    )\n",
        "    date_due: str = Field(\n",
        "        ...,\n",
        "        description=\"Due date for plan completion (YYYY-MM-DD)\"\n",
        "    )\n",
        "    date_completed: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date when plan was completed (YYYY-MM-DD)\"\n",
        "    )\n",
        "    deadline: str = Field(\n",
        "        default_factory=lambda: (datetime.datetime.now() + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\"),\n",
        "        description=\"Final deadline (YYYY-MM-DD)\"\n",
        "    )\n",
        "    days_overdue: int = Field(\n",
        "        default=0,\n",
        "        description=\"Number of days past due date\"\n",
        "    )\n",
        "\n",
        "    # Patient Status - YOUR REQUESTED PATIENT STATUS INTEGRATION\n",
        "    patient_status: Literal[\"stable\", \"improving\", \"declining\", \"critical\", \"unknown\"] = Field(\n",
        "        default=\"unknown\",\n",
        "        description=\"Current patient status affecting plan urgency\"\n",
        "    )\n",
        "    critical_finding: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Plan related to critical clinical finding\"\n",
        "    )\n",
        "    flag_delay: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Plan has been delayed\"\n",
        "    )\n",
        "\n",
        "    # Plan Classification\n",
        "    action_type: Literal[\"diagnostic\", \"treatment\", \"consultation\", \"follow-up\", \"monitoring\", \"medication\", \"procedure\"] = Field(\n",
        "        default=\"follow-up\",\n",
        "        description=\"Type of action required\"\n",
        "    )\n",
        "\n",
        "    # Documentation and Attribution\n",
        "    note_date: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    note_author: str = Field(default=\"Unknown\")\n",
        "    suggested_plan_date: Optional[str] = Field(default=None)\n",
        "\n",
        "    # Execution and Results\n",
        "    result_of_execution: Optional[str] = Field(default=None)\n",
        "    further_plan_proposal: Optional[str] = Field(default=None)\n",
        "\n",
        "    # Relationships and Dependencies\n",
        "    parent_plan_id: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"ID of parent plan if this is a sub-plan\"\n",
        "    )\n",
        "    prerequisites: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of prerequisite plan IDs\"\n",
        "    )\n",
        "\n",
        "    # Assignment and Resources\n",
        "    assigned_to: Optional[str] = Field(default=None)\n",
        "    estimated_duration: Optional[str] = Field(default=None)\n",
        "\n",
        "print(\"âœ… CarePlan model defined with urgency levels: urgent/non-urgent and workflow status: pending/delayed/overdue\")\n",
        "\n",
        "# =============================================================================\n",
        "# PATIENT TREATMENT TRACKING SCHEMA - DEFINED BEFORE MedicalAgentState\n",
        "# =============================================================================\n",
        "\n",
        "class PatientTreatmentTracker(BaseModel):\n",
        "    \"\"\"Comprehensive treatment timeline tracking for oncology patients.\"\"\"\n",
        "\n",
        "    # Core identification\n",
        "    tracker_id: str = Field(default_factory=lambda: str(uuid.uuid4()))\n",
        "    patient_mrn: str = Field(..., description=\"Patient Medical Record Number\")\n",
        "\n",
        "    # Initial Assessment Timeline\n",
        "    date_first_visit: str = Field(\n",
        "        ...,\n",
        "        description=\"Date of first visit to KHCC (YYYY-MM-DD)\"\n",
        "    )\n",
        "    date_biopsy_planned: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date biopsy is planned (YYYY-MM-DD) if applicable\"\n",
        "    )\n",
        "\n",
        "    # Pathology Timeline\n",
        "    date_first_pathology_report: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date of first pathology report at KHCC (YYYY-MM-DD)\"\n",
        "    )\n",
        "    pathology_needs_repeat: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Whether pathology needs to be repeated\"\n",
        "    )\n",
        "\n",
        "    # Radiology Timeline\n",
        "    date_first_radiology_report: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date of first radiology report (YYYY-MM-DD)\"\n",
        "    )\n",
        "    date_full_radiology_evaluation: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Date of complete radiology evaluation (YYYY-MM-DD)\"\n",
        "    )\n",
        "\n",
        "    # Clinical Assessment\n",
        "    proposed_stage: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Proposed cancer stage (e.g., 'Stage II', 'T2N1M0')\"\n",
        "    )\n",
        "    patient_status: Literal[\"new\", \"relapsed\", \"regular\"] = Field(\n",
        "        default=\"new\",\n",
        "        description=\"Patient status: new=first diagnosis, relapsed=recurrence, regular=ongoing care\"\n",
        "    )\n",
        "\n",
        "    # Treatment Planning and Execution\n",
        "    date_should_start_treatment: str = Field(\n",
        "        ...,\n",
        "        description=\"Target date to start treatment (typically 1 month from first visit)\"\n",
        "    )\n",
        "    first_therapy_type: Optional[Literal[\"chemotherapy\", \"radiotherapy\", \"surgery\", \"other\"]] = Field(\n",
        "        default=None,\n",
        "        description=\"Type of first therapy planned/started\"\n",
        "    )\n",
        "    date_first_therapy_started: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Actual date first therapy was started (YYYY-MM-DD)\"\n",
        "    )\n",
        "\n",
        "    # Timeline Tracking\n",
        "    days_remaining_or_delayed: int = Field(\n",
        "        default=0,\n",
        "        description=\"Days until treatment start (negative) or days delayed (positive)\"\n",
        "    )\n",
        "\n",
        "    # Additional tracking\n",
        "    created_date: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    last_updated: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    )\n",
        "    notes: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Additional notes about treatment timeline\"\n",
        "    )\n",
        "\n",
        "    def calculate_target_treatment_date(self) -> str:\n",
        "        \"\"\"Calculate target treatment date (1 month from first visit).\"\"\"\n",
        "        first_visit = datetime.datetime.strptime(self.date_first_visit, \"%Y-%m-%d\")\n",
        "        target_date = first_visit + datetime.timedelta(days=30)\n",
        "        return target_date.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    def calculate_days_remaining_delayed(self, current_date: Optional[str] = None) -> int:\n",
        "        \"\"\"Calculate days remaining (negative) or delayed (positive) from target start date.\"\"\"\n",
        "        if current_date is None:\n",
        "            current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        current = datetime.datetime.strptime(current_date, \"%Y-%m-%d\").date()\n",
        "        target = datetime.datetime.strptime(self.date_should_start_treatment, \"%Y-%m-%d\").date()\n",
        "\n",
        "        # If treatment already started, calculate from actual start date\n",
        "        if self.date_first_therapy_started:\n",
        "            actual_start = datetime.datetime.strptime(self.date_first_therapy_started, \"%Y-%m-%d\").date()\n",
        "            return (actual_start - target).days\n",
        "\n",
        "        # Otherwise calculate from current date\n",
        "        return (current - target).days\n",
        "\n",
        "    def update_timeline_status(self, current_date: Optional[str] = None) -> None:\n",
        "        \"\"\"Update the days_remaining_or_delayed field based on current date.\"\"\"\n",
        "        self.days_remaining_or_delayed = self.calculate_days_remaining_delayed(current_date)\n",
        "        self.last_updated = current_date or datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    def get_timeline_status(self) -> str:\n",
        "        \"\"\"Get human-readable timeline status.\"\"\"\n",
        "        if self.date_first_therapy_started:\n",
        "            if self.days_remaining_or_delayed <= 0:\n",
        "                return f\"Treatment started on time (started {abs(self.days_remaining_or_delayed)} days early)\"\n",
        "            else:\n",
        "                return f\"Treatment delayed by {self.days_remaining_or_delayed} days\"\n",
        "        else:\n",
        "            if self.days_remaining_or_delayed < 0:\n",
        "                return f\"{abs(self.days_remaining_or_delayed)} days remaining until target start date\"\n",
        "            elif self.days_remaining_or_delayed == 0:\n",
        "                return \"Treatment should start today\"\n",
        "            else:\n",
        "                return f\"Treatment delayed by {self.days_remaining_or_delayed} days\"\n",
        "\n",
        "print(\"âœ… PatientTreatmentTracker defined with oncology workflow timeline tracking\")\n",
        "\n",
        "# =============================================================================\n",
        "# COMPREHENSIVE MEDICAL AGENT STATE - NOW CAN REFERENCE PatientTreatmentTracker\n",
        "# =============================================================================\n",
        "\n",
        "class MedicalAgentState(BaseModel):\n",
        "    \"\"\"Master state for the multi-agent medical information processing system.\"\"\"\n",
        "\n",
        "    # === USER INPUT SECTION ===\n",
        "    # Core input data - START AGENT WILL RECEIVE THESE\n",
        "    clinical_note: str = Field(default=\"\", description=\"Clinical note text for processing\")\n",
        "    patient_mrn: str = Field(default=\"\", description=\"Patient Medical Record Number\")\n",
        "    note_author: str = Field(default=\"Unknown\", description=\"Author of the clinical note\")\n",
        "    note_date: str = Field(\n",
        "        default_factory=lambda: datetime.datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "        description=\"Date of the clinical note\"\n",
        "    )\n",
        "\n",
        "    # Previous context - START AGENT WILL RECEIVE THESE AS LISTS\n",
        "    previous_problems: List[MedicalProblem] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Existing medical problems for the patient\"\n",
        "    )\n",
        "    previous_care_plans: List[CarePlan] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Existing care plans for the patient\"\n",
        "    )\n",
        "    treatment_tracker: Optional[PatientTreatmentTracker] = Field(\n",
        "        default=None,\n",
        "        description=\"Patient treatment timeline tracker for oncology workflows\"\n",
        "    )\n",
        "\n",
        "    # === AGENT RESPONSE SECTION ===\n",
        "    # Newly extracted data\n",
        "    extracted_problems: List[MedicalProblem] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Medical problems extracted from current note\"\n",
        "    )\n",
        "    extracted_care_plans: List[CarePlan] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Care plans extracted from current note\"\n",
        "    )\n",
        "\n",
        "    # Processed/merged data\n",
        "    final_problems: List[MedicalProblem] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Final merged list of medical problems\"\n",
        "    )\n",
        "    final_care_plans: List[CarePlan] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Final merged list of care plans\"\n",
        "    )\n",
        "\n",
        "    # === TOOL CALLS SECTION ===\n",
        "    # Processing results\n",
        "    validation_results: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from validation agent\"\n",
        "    )\n",
        "    analysis_results: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from problem analysis agent\"\n",
        "    )\n",
        "    merge_results: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from merging process\"\n",
        "    )\n",
        "    delay_analysis: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from care plan delay analysis\"\n",
        "    )\n",
        "    priority_analysis: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from priority management analysis\"\n",
        "    )\n",
        "    workflow_analysis: Optional[Dict[str, Any]] = Field(\n",
        "        default=None,\n",
        "        description=\"Results from workflow status analysis\"\n",
        "    )\n",
        "\n",
        "    # === FINAL OUTPUT SECTION ===\n",
        "    # Summary and recommendations\n",
        "    final_medical_summary: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Comprehensive medical summary report\"\n",
        "    )\n",
        "    action_recommendations: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Prioritized action recommendations\"\n",
        "    )\n",
        "    priority_alerts: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"High-priority alerts requiring immediate attention\"\n",
        "    )\n",
        "    workflow_alerts: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Workflow-related alerts (delays, overdue items)\"\n",
        "    )\n",
        "\n",
        "    # === DEBUG INFO SECTION ===\n",
        "    # Performance and debugging\n",
        "    processing_metrics: Dict[str, Any] = Field(\n",
        "        default_factory=dict,\n",
        "        description=\"Performance metrics and timing data\"\n",
        "    )\n",
        "    validation_confidence: float = Field(\n",
        "        default=0.0,\n",
        "        description=\"Confidence score for validation results (0.0-1.0)\"\n",
        "    )\n",
        "    extraction_attempts: int = Field(\n",
        "        default=0,\n",
        "        description=\"Number of extraction attempts made\"\n",
        "    )\n",
        "\n",
        "    # Error handling\n",
        "    errors: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of errors encountered during processing\"\n",
        "    )\n",
        "    warnings: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"List of warnings generated during processing\"\n",
        "    )\n",
        "    debug_logs: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Detailed debug information\"\n",
        "    )\n",
        "\n",
        "    # Agent execution tracking\n",
        "    agent_history: List[str] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Log of agent executions and outputs\"\n",
        "    )\n",
        "    tool_outputs: List[Any] = Field(\n",
        "        default_factory=list,\n",
        "        description=\"Outputs from tool executions\"\n",
        "    )\n",
        "\n",
        "    # === PROCESSING CONTROL SECTION ===\n",
        "    # Workflow management\n",
        "    current_step: str = Field(\n",
        "        default=\"start\",\n",
        "        description=\"Current step in the processing workflow\"\n",
        "    )\n",
        "    current_agent: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"Currently executing agent\"\n",
        "    )\n",
        "    is_complete: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Whether processing is complete\"\n",
        "    )\n",
        "    processing_mode: Literal[\"quick\", \"comprehensive\", \"validation_only\", \"emergency\"] = Field(\n",
        "        default=\"comprehensive\",\n",
        "        description=\"Processing mode determining workflow depth\"\n",
        "    )\n",
        "\n",
        "    # Timing and iterations\n",
        "    processing_start_time: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"ISO timestamp when processing started\"\n",
        "    )\n",
        "    processing_end_time: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"ISO timestamp when processing completed\"\n",
        "    )\n",
        "    iterations: int = Field(\n",
        "        default=0,\n",
        "        description=\"Number of processing iterations\"\n",
        "    )\n",
        "\n",
        "    # Configuration\n",
        "    enable_caching: bool = Field(\n",
        "        default=True,\n",
        "        description=\"Whether to use caching for improved performance\"\n",
        "    )\n",
        "    enable_markdown_logging: bool = Field(\n",
        "        default=False,\n",
        "        description=\"Whether to generate markdown activity logs\"\n",
        "    )\n",
        "    max_extraction_attempts: int = Field(\n",
        "        default=3,\n",
        "        description=\"Maximum number of extraction attempts\"\n",
        "    )\n",
        "\n",
        "print(\"âœ… MedicalAgentState defined with comprehensive sections for user input, agent responses, tool calls, and debug info\")\n",
        "\n",
        "# =============================================================================\n",
        "# HELPER CLASSES FOR CONSISTENT CLASSIFICATION\n",
        "# =============================================================================\n",
        "\n",
        "class PriorityClassifier:\n",
        "    \"\"\"Helper class for consistent priority classification.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_problem_priority(\n",
        "        problem_name: str,\n",
        "        clinical_context: str,\n",
        "        patient_status: str = \"unknown\"\n",
        "    ) -> Literal[\"critical\", \"important\", \"regular\"]:\n",
        "        \"\"\"Classify medical problem priority based on clinical context.\"\"\"\n",
        "        problem_lower = problem_name.lower()\n",
        "        context_lower = clinical_context.lower()\n",
        "\n",
        "        # Critical conditions\n",
        "        critical_keywords = [\n",
        "            \"life-threatening\", \"emergency\", \"critical\", \"severe\", \"acute\",\n",
        "            \"progression\", \"metastasis\", \"sepsis\", \"shock\", \"respiratory failure\",\n",
        "            \"cardiac arrest\", \"stroke\", \"seizure\", \"hemorrhage\"\n",
        "        ]\n",
        "\n",
        "        # Important conditions\n",
        "        important_keywords = [\n",
        "            \"cancer\", \"tumor\", \"malignant\", \"chemotherapy\", \"radiation\",\n",
        "            \"neuropathy\", \"significant\", \"moderate\", \"treatment-related\",\n",
        "            \"side effect\", \"complication\", \"anemia\", \"infection\"\n",
        "        ]\n",
        "\n",
        "        if any(keyword in problem_lower or keyword in context_lower for keyword in critical_keywords):\n",
        "            return \"critical\"\n",
        "        elif any(keyword in problem_lower or keyword in context_lower for keyword in important_keywords):\n",
        "            return \"important\"\n",
        "        else:\n",
        "            return \"regular\"\n",
        "\n",
        "    @staticmethod\n",
        "    def classify_plan_urgency(\n",
        "        plan_description: str,\n",
        "        patient_status: str,\n",
        "        critical_finding: bool = False\n",
        "    ) -> Literal[\"urgent\", \"non-urgent\"]:\n",
        "        \"\"\"Classify care plan urgency based on content and context.\"\"\"\n",
        "        plan_lower = plan_description.lower()\n",
        "\n",
        "        # Urgent plan indicators\n",
        "        urgent_keywords = [\n",
        "            \"immediate\", \"urgent\", \"emergent\", \"stat\", \"asap\",\n",
        "            \"abnormal results\", \"critical values\", \"concerning findings\",\n",
        "            \"biopsy\", \"staging\", \"restaging\", \"progression\"\n",
        "        ]\n",
        "\n",
        "        # Patient status considerations\n",
        "        if patient_status in [\"critical\", \"declining\"] or critical_finding:\n",
        "            return \"urgent\"\n",
        "\n",
        "        if any(keyword in plan_lower for keyword in urgent_keywords):\n",
        "            return \"urgent\"\n",
        "        else:\n",
        "            return \"non-urgent\"\n",
        "\n",
        "class WorkflowCalculator:\n",
        "    \"\"\"Helper class for workflow status calculations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_workflow_status(\n",
        "        date_due: str,\n",
        "        date_initiated: Optional[str] = None,\n",
        "        date_completed: Optional[str] = None,\n",
        "        current_date: Optional[str] = None\n",
        "    ) -> tuple[Literal[\"pending\", \"in-progress\", \"delayed\", \"overdue\", \"completed\", \"cancelled\"], int]:\n",
        "        \"\"\"Calculate workflow status and days overdue.\"\"\"\n",
        "\n",
        "        if current_date is None:\n",
        "            current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        current = datetime.datetime.strptime(current_date, \"%Y-%m-%d\").date()\n",
        "        due_date = datetime.datetime.strptime(date_due, \"%Y-%m-%d\").date()\n",
        "\n",
        "        # Completed\n",
        "        if date_completed:\n",
        "            return \"completed\", 0\n",
        "\n",
        "        # Calculate days difference\n",
        "        days_diff = (current - due_date).days\n",
        "\n",
        "        # Not yet started\n",
        "        if not date_initiated:\n",
        "            if days_diff > 0:\n",
        "                return (\"overdue\" if days_diff > 7 else \"delayed\"), max(0, days_diff)\n",
        "            else:\n",
        "                return \"pending\", 0\n",
        "\n",
        "        # In progress\n",
        "        if days_diff <= 0:\n",
        "            return \"in-progress\", 0\n",
        "        elif days_diff <= 7:\n",
        "            return \"delayed\", days_diff\n",
        "        else:\n",
        "            return \"overdue\", days_diff\n",
        "\n",
        "print(\"âœ… Helper classes defined: PriorityClassifier and WorkflowCalculator\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXAMPLE USAGE AND VALIDATION\n",
        "# =============================================================================\n",
        "\n",
        "# Create example medical problem with your requested priority classification\n",
        "example_problem = MedicalProblem(\n",
        "    problem_name=\"Stage II Breast Cancer\",\n",
        "    patient_mrn=\"12345\",\n",
        "    priority_flag=\"critical\",  # YOUR REQUESTED: critical/important/regular\n",
        "    severity_level=\"moderate\",\n",
        "    is_cancer_related=True,\n",
        "    evidence=\"Pathology confirms invasive ductal carcinoma\"\n",
        ")\n",
        "\n",
        "# Create example care plan with your requested workflow tracking\n",
        "example_care_plan = CarePlan(\n",
        "    suggested_plan=\"Schedule PET scan for staging\",\n",
        "    mrn=\"12345\",\n",
        "    urgency_level=\"urgent\",  # YOUR REQUESTED: urgent/non-urgent\n",
        "    workflow_status=\"pending\",  # YOUR REQUESTED: pending/delayed/overdue\n",
        "    date_due=\"2024-01-15\",  # YOUR REQUESTED: date tracking\n",
        "    date_initiated=None,  # YOUR REQUESTED: date initiated\n",
        "    patient_status=\"critical\",  # YOUR REQUESTED: patient status\n",
        "    action_type=\"diagnostic\",\n",
        "    critical_finding=True\n",
        ")\n",
        "\n",
        "# Create example treatment tracker with your requested oncology timeline\n",
        "example_treatment_tracker = PatientTreatmentTracker(\n",
        "    patient_mrn=\"12345\",\n",
        "    date_first_visit=\"2024-01-01\",  # YOUR REQUESTED: first visit date\n",
        "    date_biopsy_planned=\"2024-01-05\",  # YOUR REQUESTED: biopsy planning\n",
        "    date_first_pathology_report=\"2024-01-10\",  # YOUR REQUESTED: path report at KHCC\n",
        "    pathology_needs_repeat=False,  # YOUR REQUESTED: path repeat flag\n",
        "    date_first_radiology_report=\"2024-01-08\",  # YOUR REQUESTED: radiology dates\n",
        "    date_full_radiology_evaluation=\"2024-01-12\",\n",
        "    proposed_stage=\"Stage II (T2N1M0)\",  # YOUR REQUESTED: staging\n",
        "    patient_status=\"new\",  # YOUR REQUESTED: new/relapsed/regular\n",
        "    date_should_start_treatment=\"2024-01-31\",  # YOUR REQUESTED: 1 month from first visit\n",
        "    first_therapy_type=\"chemotherapy\",  # YOUR REQUESTED: therapy type\n",
        "    date_first_therapy_started=None  # YOUR REQUESTED: actual start date\n",
        ")\n",
        "\n",
        "# Calculate timeline status\n",
        "example_treatment_tracker.update_timeline_status(\"2024-01-25\")  # 6 days before target\n",
        "\n",
        "# Create comprehensive state that START AGENT will receive\n",
        "example_state = MedicalAgentState(\n",
        "    clinical_note=\"Patient presents with newly diagnosed breast cancer, reports fatigue and anxiety\",\n",
        "    patient_mrn=\"12345\",\n",
        "    previous_problems=[],  # START AGENT RECEIVES THIS LIST\n",
        "    previous_care_plans=[],  # START AGENT RECEIVES THIS LIST\n",
        "    treatment_tracker=example_treatment_tracker,  # START AGENT RECEIVES THIS\n",
        "    extracted_problems=[example_problem],\n",
        "    extracted_care_plans=[example_care_plan],\n",
        "    processing_mode=\"comprehensive\"\n",
        ")\n",
        "\n",
        "print(\"\\nðŸŽ¯ ENHANCED SCHEMA VALIDATION COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"âœ… Problem priority classification: {example_problem.priority_flag}\")\n",
        "print(f\"âœ… Care plan urgency level: {example_care_plan.urgency_level}\")\n",
        "print(f\"âœ… Care plan workflow status: {example_care_plan.workflow_status}\")\n",
        "print(f\"âœ… Patient status integration: {example_care_plan.patient_status}\")\n",
        "print(f\"âœ… State current step: {example_state.current_step}\")\n",
        "print(\"\\nðŸ¥ TREATMENT TRACKER VALIDATION:\")\n",
        "print(f\"âœ… First visit date: {example_treatment_tracker.date_first_visit}\")\n",
        "print(f\"âœ… Target treatment date: {example_treatment_tracker.date_should_start_treatment}\")\n",
        "print(f\"âœ… Timeline status: {example_treatment_tracker.get_timeline_status()}\")\n",
        "print(f\"âœ… Patient status: {example_treatment_tracker.patient_status}\")\n",
        "print(f\"âœ… Proposed stage: {example_treatment_tracker.proposed_stage}\")\n",
        "print(f\"âœ… Pathology needs repeat: {example_treatment_tracker.pathology_needs_repeat}\")\n",
        "print(\"=\" * 60)\n",
        "print(\"ðŸ“ Ready for agent implementation!\")\n",
        "print(\"\\nNext step: Create start_agent that receives:\")\n",
        "print(\"  - clinical_note: str\")\n",
        "print(\"  - patient_mrn: str\")\n",
        "print(\"  - previous_problems: List[MedicalProblem]\")\n",
        "print(\"  - previous_care_plans: List[CarePlan]\")\n",
        "print(\"  - treatment_tracker: Optional[PatientTreatmentTracker]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a3d43a2",
        "outputId": "ae9f4f2d-dbe3-40a8-dfb8-f2160c8c0ef7"
      },
      "source": [
        "# Enhanced Start Agent for Medical Multi-Agent System\n",
        "# Execute this cell to define the start_agent with comprehensive medical workflow logic\n",
        "\n",
        "import datetime\n",
        "import logging\n",
        "from typing import List, Optional\n",
        "from pydantic import ValidationError\n",
        "\n",
        "def start_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Enhanced start agent that receives clinical note and existing problems/plans.\n",
        "    Initializes processing with medical-specific workflow determination.\n",
        "\n",
        "    Args:\n",
        "        state: MedicalAgentState containing clinical_note, patient_mrn,\n",
        "               previous_problems, previous_care_plans, treatment_tracker\n",
        "\n",
        "    Returns:\n",
        "        Updated MedicalAgentState with processing mode and routing decision\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing enhanced start_agent...\")\n",
        "    state.agent_history.append(\"start_agent: Initializing medical information processing.\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 1. VALIDATE REQUIRED INPUTS\n",
        "    # =============================================================================\n",
        "    try:\n",
        "        if not state.clinical_note or state.clinical_note.strip() == \"\":\n",
        "            raise ValueError(\"clinical_note is required and cannot be empty.\")\n",
        "        if not state.patient_mrn or state.patient_mrn.strip() == \"\":\n",
        "            raise ValueError(\"patient_mrn is required and cannot be empty.\")\n",
        "\n",
        "        # Validate MRN format (basic check)\n",
        "        if not state.patient_mrn.replace(\"-\", \"\").replace(\" \", \"\").isalnum():\n",
        "            raise ValueError(\"patient_mrn contains invalid characters.\")\n",
        "\n",
        "        state.debug_logs.append(\"start_agent: Input validation successful.\")\n",
        "        logging.info(f\"Input validation passed for patient MRN: {state.patient_mrn}\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        error_msg = f\"start_agent input validation error: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.is_complete = True  # Mark as complete due to critical error\n",
        "        state.current_step = \"error\"\n",
        "        state.current_agent = \"error_handler\"\n",
        "        logging.error(error_msg)\n",
        "        return state\n",
        "\n",
        "    # =============================================================================\n",
        "    # 2. INITIALIZE STATE VARIABLES\n",
        "    # =============================================================================\n",
        "    state.processing_start_time = datetime.datetime.now().isoformat()\n",
        "    state.current_step = \"start\"\n",
        "    state.current_agent = \"start_agent\"\n",
        "    state.extraction_attempts = 0\n",
        "    state.is_complete = False\n",
        "    state.iterations += 1\n",
        "\n",
        "    # Log input statistics\n",
        "    note_length = len(state.clinical_note.split())\n",
        "    previous_problems_count = len(state.previous_problems)\n",
        "    previous_plans_count = len(state.previous_care_plans)\n",
        "\n",
        "    state.debug_logs.append(f\"start_agent: Clinical note length: {note_length} words\")\n",
        "    state.debug_logs.append(f\"start_agent: Previous problems: {previous_problems_count}\")\n",
        "    state.debug_logs.append(f\"start_agent: Previous care plans: {previous_plans_count}\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 3. ANALYZE CLINICAL CONTEXT\n",
        "    # =============================================================================\n",
        "    note_lower = state.clinical_note.lower()\n",
        "\n",
        "    # Medical emergency indicators\n",
        "    critical_findings_keywords = [\n",
        "        \"critical findings\", \"emergency\", \"urgent\", \"stat\", \"emergent\",\n",
        "        \"progression\", \"metastasis\", \"sepsis\", \"shock\", \"respiratory failure\",\n",
        "        \"cardiac arrest\", \"stroke\", \"seizure\", \"hemorrhage\", \"acute deterioration\"\n",
        "    ]\n",
        "\n",
        "    # Cancer context indicators\n",
        "    cancer_keywords = [\n",
        "        \"cancer\", \"tumor\", \"malignant\", \"oncology\", \"chemotherapy\", \"radiation\",\n",
        "        \"biopsy\", \"staging\", \"metastatic\", \"carcinoma\", \"sarcoma\", \"lymphoma\"\n",
        "    ]\n",
        "\n",
        "    # Treatment urgency indicators\n",
        "    treatment_urgent_keywords = [\n",
        "        \"abnormal results\", \"concerning findings\", \"immediate treatment\",\n",
        "        \"treatment delay\", \"overdue\", \"pathology repeat\", \"restaging\"\n",
        "    ]\n",
        "\n",
        "    has_critical_findings = any(keyword in note_lower for keyword in critical_findings_keywords)\n",
        "    has_cancer_context = any(keyword in note_lower for keyword in cancer_keywords)\n",
        "    has_treatment_urgency = any(keyword in note_lower for keyword in treatment_urgent_keywords)\n",
        "\n",
        "    # Analyze existing problems for context\n",
        "    has_critical_problems = any(p.priority_flag == \"critical\" for p in state.previous_problems)\n",
        "    has_cancer_problems = any(p.is_cancer_related for p in state.previous_problems)\n",
        "\n",
        "    # Analyze existing care plans for urgency\n",
        "    has_overdue_urgent_plans = any(\n",
        "        cp.workflow_status in [\"overdue\", \"delayed\"] and cp.urgency_level == \"urgent\"\n",
        "        for cp in state.previous_care_plans\n",
        "    )\n",
        "    has_critical_patient_status = any(\n",
        "        cp.patient_status in [\"critical\", \"declining\"]\n",
        "        for cp in state.previous_care_plans\n",
        "    )\n",
        "\n",
        "    state.debug_logs.append(f\"start_agent: Clinical context analysis - Critical findings: {has_critical_findings}, Cancer context: {has_cancer_context}\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 4. TREATMENT TRACKER MANAGEMENT\n",
        "    # =============================================================================\n",
        "    treatment_delay_critical = False\n",
        "\n",
        "    if state.treatment_tracker:\n",
        "        # Update existing treatment tracker\n",
        "        state.treatment_tracker.update_timeline_status()\n",
        "        treatment_delay_critical = state.treatment_tracker.days_remaining_or_delayed > 30\n",
        "\n",
        "        state.debug_logs.append(f\"start_agent: Treatment tracker updated - Status: {state.treatment_tracker.get_timeline_status()}\")\n",
        "\n",
        "        if treatment_delay_critical:\n",
        "            state.warnings.append(f\"Treatment delay critical: {state.treatment_tracker.days_remaining_or_delayed} days past target\")\n",
        "\n",
        "    elif has_cancer_context or has_cancer_problems:\n",
        "        # Create new treatment tracker for cancer patients\n",
        "        target_treatment_date = (\n",
        "            datetime.datetime.strptime(state.note_date, \"%Y-%m-%d\") +\n",
        "            datetime.timedelta(days=30)\n",
        "        ).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        state.treatment_tracker = PatientTreatmentTracker(\n",
        "            patient_mrn=state.patient_mrn,\n",
        "            date_first_visit=state.note_date,\n",
        "            date_should_start_treatment=target_treatment_date,\n",
        "            patient_status=\"new\" if not state.previous_problems else \"regular\"\n",
        "        )\n",
        "\n",
        "        state.debug_logs.append(\"start_agent: Created new treatment tracker for cancer patient\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 5. DETERMINE PROCESSING MODE\n",
        "    # =============================================================================\n",
        "    # Priority order: emergency -> comprehensive -> quick\n",
        "\n",
        "    if (has_critical_findings or has_overdue_urgent_plans or\n",
        "        treatment_delay_critical or has_critical_patient_status):\n",
        "        state.processing_mode = \"emergency\"\n",
        "        state.debug_logs.append(\"start_agent: Processing mode: EMERGENCY - Critical medical situation detected\")\n",
        "\n",
        "        # Add emergency alert\n",
        "        emergency_reasons = []\n",
        "        if has_critical_findings:\n",
        "            emergency_reasons.append(\"critical findings in clinical note\")\n",
        "        if has_overdue_urgent_plans:\n",
        "            emergency_reasons.append(\"overdue urgent care plans\")\n",
        "        if treatment_delay_critical:\n",
        "            emergency_reasons.append(\"critical treatment delay\")\n",
        "        if has_critical_patient_status:\n",
        "            emergency_reasons.append(\"critical patient status\")\n",
        "\n",
        "        state.priority_alerts.append(f\"EMERGENCY: {', '.join(emergency_reasons)}\")\n",
        "\n",
        "    elif (has_cancer_context or has_cancer_problems or has_treatment_urgency or\n",
        "          note_length > 500 or previous_problems_count > 5 or previous_plans_count > 3):\n",
        "        state.processing_mode = \"comprehensive\"\n",
        "        state.debug_logs.append(\"start_agent: Processing mode: COMPREHENSIVE - Complex medical case\")\n",
        "\n",
        "    elif note_length < 200 and not state.previous_problems and not state.previous_care_plans:\n",
        "        state.processing_mode = \"quick\"\n",
        "        state.debug_logs.append(\"start_agent: Processing mode: QUICK - Simple case with no history\")\n",
        "\n",
        "    else:\n",
        "        state.processing_mode = \"comprehensive\"  # Default to comprehensive for safety\n",
        "        state.debug_logs.append(\"start_agent: Processing mode: COMPREHENSIVE - Default for medical safety\")\n",
        "\n",
        "    # =============================================================================\n",
        "    # 6. SET ROUTING AND PERFORMANCE EXPECTATIONS\n",
        "    # =============================================================================\n",
        "    # Set processing expectations based on mode\n",
        "    if state.processing_mode == \"emergency\":\n",
        "        state.max_extraction_attempts = 2  # Faster processing for emergencies\n",
        "        state.enable_caching = False  # Ensure fresh analysis for critical cases\n",
        "    elif state.processing_mode == \"comprehensive\":\n",
        "        state.max_extraction_attempts = 3  # Standard processing\n",
        "        state.enable_caching = True\n",
        "    else:  # quick mode\n",
        "        state.max_extraction_attempts = 1  # Minimal processing\n",
        "        state.enable_caching = True\n",
        "\n",
        "    # Set next routing step\n",
        "    state.current_step = \"problem_extraction\"\n",
        "    state.current_agent = None  # Reset for next agent\n",
        "\n",
        "    # =============================================================================\n",
        "    # 7. FINAL LOGGING AND METRICS\n",
        "    # =============================================================================\n",
        "    processing_summary = {\n",
        "        \"processing_mode\": state.processing_mode,\n",
        "        \"clinical_note_length\": note_length,\n",
        "        \"previous_problems_count\": previous_problems_count,\n",
        "        \"previous_care_plans_count\": previous_plans_count,\n",
        "        \"has_treatment_tracker\": state.treatment_tracker is not None,\n",
        "        \"emergency_indicators\": {\n",
        "            \"critical_findings\": has_critical_findings,\n",
        "            \"overdue_urgent_plans\": has_overdue_urgent_plans,\n",
        "            \"treatment_delay_critical\": treatment_delay_critical,\n",
        "            \"critical_patient_status\": has_critical_patient_status\n",
        "        }\n",
        "    }\n",
        "\n",
        "    state.processing_metrics[\"start_agent_summary\"] = processing_summary\n",
        "\n",
        "    completion_message = (f\"start_agent completed: Mode={state.processing_mode}, \"\n",
        "                         f\"Next=problem_extraction, Patient={state.patient_mrn}\")\n",
        "\n",
        "    state.agent_history.append(completion_message)\n",
        "    logging.info(completion_message)\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… Enhanced start_agent function defined with:\")\n",
        "print(\"  - Comprehensive input validation\")\n",
        "print(\"  - Medical context analysis\")\n",
        "print(\"  - Treatment tracker integration\")\n",
        "print(\"  - Emergency detection logic\")\n",
        "print(\"  - Intelligent processing mode determination\")\n",
        "print(\"  - Performance optimization settings\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXAMPLE USAGE AND TESTING\n",
        "# =============================================================================\n",
        "\n",
        "def test_start_agent():\n",
        "    \"\"\"Test the enhanced start_agent with various scenarios.\"\"\"\n",
        "    print(\"\\nðŸ§ª Testing start_agent scenarios...\")\n",
        "\n",
        "    # Test Case 1: Emergency scenario\n",
        "    emergency_state = MedicalAgentState(\n",
        "        clinical_note=\"Patient presents with critical findings: rapid disease progression and concerning metastatic lesions\",\n",
        "        patient_mrn=\"EMR001\",\n",
        "        note_date=\"2024-01-15\"\n",
        "    )\n",
        "\n",
        "    result1 = start_agent(emergency_state)\n",
        "    print(f\"Test 1 - Emergency: {result1.processing_mode} (Expected: emergency)\")\n",
        "\n",
        "    # Test Case 2: Cancer patient - comprehensive\n",
        "    cancer_state = MedicalAgentState(\n",
        "        clinical_note=\"Follow-up visit for breast cancer patient undergoing chemotherapy. Reports mild fatigue and neuropathy.\",\n",
        "        patient_mrn=\"CAN002\",\n",
        "        note_date=\"2024-01-15\"\n",
        "    )\n",
        "\n",
        "    result2 = start_agent(cancer_state)\n",
        "    print(f\"Test 2 - Cancer: {result2.processing_mode} (Expected: comprehensive)\")\n",
        "    print(f\"         Treatment tracker created: {result2.treatment_tracker is not None}\")\n",
        "\n",
        "    # Test Case 3: Simple note - quick mode\n",
        "    simple_state = MedicalAgentState(\n",
        "        clinical_note=\"Routine follow-up. Patient feeling well.\",\n",
        "        patient_mrn=\"SIM003\",\n",
        "        note_date=\"2024-01-15\"\n",
        "    )\n",
        "\n",
        "    result3 = start_agent(simple_state)\n",
        "    print(f\"Test 3 - Simple: {result3.processing_mode} (Expected: quick)\")\n",
        "\n",
        "    print(\"âœ… Start agent testing completed\")\n",
        "\n",
        "# Uncomment to run tests\n",
        "test_start_agent()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Enhanced start_agent function defined with:\n",
            "  - Comprehensive input validation\n",
            "  - Medical context analysis\n",
            "  - Treatment tracker integration\n",
            "  - Emergency detection logic\n",
            "  - Intelligent processing mode determination\n",
            "  - Performance optimization settings\n",
            "\n",
            "ðŸ§ª Testing start_agent scenarios...\n",
            "Test 1 - Emergency: emergency (Expected: emergency)\n",
            "Test 2 - Cancer: comprehensive (Expected: comprehensive)\n",
            "         Treatment tracker created: True\n",
            "Test 3 - Simple: quick (Expected: quick)\n",
            "âœ… Start agent testing completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example start node"
      ],
      "metadata": {
        "id": "BF14qktu8otx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Start Agent Example - Full State Activation and Display\n",
        "# Execute this cell to see the complete workflow with sample data\n",
        "\n",
        "import datetime\n",
        "import logging\n",
        "import json\n",
        "from typing import List, Optional\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Configure logging to see agent execution\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "\n",
        "print(\"ðŸš€ STARTING COMPLETE MEDICAL AGENT WORKFLOW EXAMPLE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: CREATE SAMPLE INPUT DATA\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nðŸ“ Step 1: Creating sample input data...\")\n",
        "\n",
        "# Sample clinical note (realistic oncology scenario)\n",
        "sample_clinical_note = \"\"\"\n",
        "Patient: Jane Smith\n",
        "MRN: ONC12345\n",
        "Date: 2024-01-15\n",
        "Provider: Dr. Sarah Johnson, Oncology\n",
        "\n",
        "CHIEF COMPLAINT: Follow-up for breast cancer treatment, reports worsening fatigue\n",
        "\n",
        "HISTORY OF PRESENT ILLNESS:\n",
        "Patient is a 58-year-old female with Stage II invasive ductal carcinoma of the left breast,\n",
        "ER+/PR+, HER2-. Currently on cycle 4 of 6 planned cycles of AC-T chemotherapy regimen.\n",
        "Patient reports significant worsening of fatigue over the past week, affecting daily activities.\n",
        "Also experiencing grade 2 peripheral neuropathy in fingers and toes since starting taxol.\n",
        "Patient expresses anxiety about treatment completion and prognosis.\n",
        "\n",
        "REVIEW OF SYSTEMS:\n",
        "- Constitutional: Fatigue, no fever, slight weight loss (3 lbs)\n",
        "- Neurologic: Peripheral neuropathy, no headaches\n",
        "- Psychiatric: Anxiety about treatment, trouble sleeping\n",
        "\n",
        "PHYSICAL EXAM:\n",
        "Vitals stable. Performance status ECOG 1. Port site clean and patent.\n",
        "Neurologic exam shows decreased sensation in fingertips bilaterally.\n",
        "\n",
        "ASSESSMENT & PLAN:\n",
        "1. Stage II breast cancer - on active treatment, responding well per imaging\n",
        "2. Chemotherapy-induced fatigue - will refer to supportive care\n",
        "3. Chemotherapy-induced peripheral neuropathy - consider dose reduction if worsens\n",
        "4. Treatment-related anxiety - continue supportive counseling, consider referral to psychiatry\n",
        "5. Continue planned chemotherapy, cycle 5 scheduled for next week\n",
        "6. Labs prior to next cycle to check counts\n",
        "7. Follow-up in clinic in 1 week\n",
        "\n",
        "Patient counseled on side effect management and when to call with concerns.\n",
        "\"\"\"\n",
        "\n",
        "# Create sample previous problems (from patient's medical history)\n",
        "previous_problems = [\n",
        "    MedicalProblem(\n",
        "        problem_name=\"Stage II Invasive Ductal Carcinoma\",\n",
        "        patient_mrn=\"ONC12345\",\n",
        "        priority_flag=\"critical\",\n",
        "        severity_level=\"moderate\",\n",
        "        is_cancer_related=True,\n",
        "        evidence=\"Pathology report from initial biopsy\",\n",
        "        date_identified=\"2023-11-15\",\n",
        "        note_source=\"Initial oncology consultation\",\n",
        "        status=\"Active\"\n",
        "    ),\n",
        "    MedicalProblem(\n",
        "        problem_name=\"Hypertension\",\n",
        "        patient_mrn=\"ONC12345\",\n",
        "        priority_flag=\"regular\",\n",
        "        severity_level=\"mild\",\n",
        "        is_cancer_related=False,\n",
        "        evidence=\"Multiple BP readings >140/90\",\n",
        "        date_identified=\"2022-03-10\",\n",
        "        note_source=\"Primary care visit\",\n",
        "        status=\"Active\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create sample previous care plans (existing plans for this patient)\n",
        "previous_care_plans = [\n",
        "    CarePlan(\n",
        "        suggested_plan=\"Complete 6 cycles of AC-T chemotherapy\",\n",
        "        mrn=\"ONC12345\",\n",
        "        urgency_level=\"urgent\",\n",
        "        workflow_status=\"in-progress\",\n",
        "        date_due=\"2024-02-15\",\n",
        "        date_initiated=\"2023-12-01\",\n",
        "        patient_status=\"stable\",\n",
        "        action_type=\"treatment\",\n",
        "        critical_finding=True,\n",
        "        note_author=\"Dr. Sarah Johnson\"\n",
        "    ),\n",
        "    CarePlan(\n",
        "        suggested_plan=\"Monitor blood counts before each cycle\",\n",
        "        mrn=\"ONC12345\",\n",
        "        urgency_level=\"urgent\",\n",
        "        workflow_status=\"pending\",\n",
        "        date_due=\"2024-01-20\",\n",
        "        patient_status=\"stable\",\n",
        "        action_type=\"monitoring\",\n",
        "        note_author=\"Dr. Sarah Johnson\"\n",
        "    ),\n",
        "    CarePlan(\n",
        "        suggested_plan=\"Supportive care consultation for fatigue management\",\n",
        "        mrn=\"ONC12345\",\n",
        "        urgency_level=\"non-urgent\",\n",
        "        workflow_status=\"pending\",\n",
        "        date_due=\"2024-01-25\",\n",
        "        patient_status=\"stable\",\n",
        "        action_type=\"consultation\",\n",
        "        note_author=\"Dr. Sarah Johnson\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Create sample treatment tracker\n",
        "sample_treatment_tracker = PatientTreatmentTracker(\n",
        "    patient_mrn=\"ONC12345\",\n",
        "    date_first_visit=\"2023-11-15\",\n",
        "    date_biopsy_planned=\"2023-11-20\",\n",
        "    date_first_pathology_report=\"2023-11-25\",\n",
        "    pathology_needs_repeat=False,\n",
        "    date_first_radiology_report=\"2023-11-18\",\n",
        "    date_full_radiology_evaluation=\"2023-11-22\",\n",
        "    proposed_stage=\"Stage II (T2N1M0)\",\n",
        "    patient_status=\"regular\",  # Not new anymore, ongoing treatment\n",
        "    date_should_start_treatment=\"2023-12-15\",  # 1 month from first visit\n",
        "    first_therapy_type=\"chemotherapy\",\n",
        "    date_first_therapy_started=\"2023-12-01\",  # Treatment started on time\n",
        "    notes=\"Patient started treatment on schedule, responding well\"\n",
        ")\n",
        "\n",
        "# Update treatment tracker status\n",
        "sample_treatment_tracker.update_timeline_status(\"2024-01-15\")\n",
        "\n",
        "print(f\"âœ… Created clinical note ({len(sample_clinical_note.split())} words)\")\n",
        "print(f\"âœ… Created {len(previous_problems)} previous problems\")\n",
        "print(f\"âœ… Created {len(previous_care_plans)} previous care plans\")\n",
        "print(f\"âœ… Created treatment tracker (Status: {sample_treatment_tracker.get_timeline_status()})\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 2: CREATE INITIAL MEDICAL AGENT STATE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nðŸ—ï¸ Step 2: Creating initial MedicalAgentState...\")\n",
        "\n",
        "# Create the initial state that the start_agent will receive\n",
        "initial_state = MedicalAgentState(\n",
        "    # Required inputs for start_agent\n",
        "    clinical_note=sample_clinical_note,\n",
        "    patient_mrn=\"ONC12345\",\n",
        "    note_author=\"Dr. Sarah Johnson\",\n",
        "    note_date=\"2024-01-15\",\n",
        "\n",
        "    # Previous context (what start_agent receives)\n",
        "    previous_problems=previous_problems,\n",
        "    previous_care_plans=previous_care_plans,\n",
        "    treatment_tracker=sample_treatment_tracker,\n",
        "\n",
        "    # Initial processing settings\n",
        "    processing_mode=\"comprehensive\",  # Will be determined by start_agent\n",
        "    enable_caching=True,\n",
        "    enable_markdown_logging=False,\n",
        "    max_extraction_attempts=3\n",
        ")\n",
        "\n",
        "print(f\"âœ… Initial state created for patient: {initial_state.patient_mrn}\")\n",
        "print(f\"âœ… Clinical note date: {initial_state.note_date}\")\n",
        "print(f\"âœ… Note author: {initial_state.note_author}\")\n",
        "print(f\"âœ… Initial processing mode: {initial_state.processing_mode}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: EXECUTE START AGENT\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nðŸŽ¯ Step 3: Executing start_agent...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Run the start_agent function\n",
        "try:\n",
        "    processed_state = start_agent(initial_state)\n",
        "    print(\"âœ… start_agent execution completed successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during start_agent execution: {e}\")\n",
        "    processed_state = initial_state\n",
        "\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 4: DISPLAY COMPLETE STATE GRAPH\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\nðŸ“Š COMPLETE MEDICAL AGENT STATE AFTER START_AGENT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def print_state_section(title, data, max_items=None):\n",
        "    \"\"\"Helper function to print state sections nicely\"\"\"\n",
        "    print(f\"\\nðŸ”¹ {title}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    if isinstance(data, list):\n",
        "        if not data:\n",
        "            print(\"  (Empty)\")\n",
        "        else:\n",
        "            for i, item in enumerate(data[:max_items] if max_items else data):\n",
        "                if hasattr(item, 'model_dump'):\n",
        "                    # Pydantic object\n",
        "                    if hasattr(item, 'problem_name'):\n",
        "                        print(f\"  {i+1}. {item.problem_name} (Priority: {item.priority_flag}, Status: {item.status})\")\n",
        "                    elif hasattr(item, 'suggested_plan'):\n",
        "                        print(f\"  {i+1}. {item.suggested_plan} (Urgency: {item.urgency_level}, Status: {item.workflow_status})\")\n",
        "                    else:\n",
        "                        print(f\"  {i+1}. {str(item)[:100]}...\")\n",
        "                else:\n",
        "                    # String or other\n",
        "                    print(f\"  {i+1}. {str(item)[:100]}...\")\n",
        "            if max_items and len(data) > max_items:\n",
        "                print(f\"  ... and {len(data) - max_items} more items\")\n",
        "    elif isinstance(data, dict):\n",
        "        if not data:\n",
        "            print(\"  (Empty)\")\n",
        "        else:\n",
        "            for key, value in data.items():\n",
        "                print(f\"  {key}: {str(value)[:80]}...\")\n",
        "    elif isinstance(data, str):\n",
        "        if not data:\n",
        "            print(\"  (Empty)\")\n",
        "        else:\n",
        "            # For long strings, show first few lines\n",
        "            lines = data.split('\\n')\n",
        "            for line in lines[:3]:\n",
        "                print(f\"  {line[:80]}...\")\n",
        "            if len(lines) > 3:\n",
        "                print(f\"  ... ({len(lines)-3} more lines)\")\n",
        "    elif hasattr(data, 'model_dump'):\n",
        "        # Single Pydantic object like treatment_tracker\n",
        "        if hasattr(data, 'get_timeline_status'):\n",
        "            print(f\"  Patient Status: {data.patient_status}\")\n",
        "            print(f\"  Timeline Status: {data.get_timeline_status()}\")\n",
        "            print(f\"  First Visit: {data.date_first_visit}\")\n",
        "            print(f\"  Target Treatment Date: {data.date_should_start_treatment}\")\n",
        "            if data.date_first_therapy_started:\n",
        "                print(f\"  Treatment Started: {data.date_first_therapy_started}\")\n",
        "            print(f\"  Proposed Stage: {data.proposed_stage}\")\n",
        "        else:\n",
        "            print(f\"  {str(data)[:200]}...\")\n",
        "    else:\n",
        "        print(f\"  {str(data)}\")\n",
        "\n",
        "# Display all state sections\n",
        "print_state_section(\"CORE INPUT DATA\", {\n",
        "    \"Patient MRN\": processed_state.patient_mrn,\n",
        "    \"Note Date\": processed_state.note_date,\n",
        "    \"Note Author\": processed_state.note_author,\n",
        "    \"Clinical Note Length\": f\"{len(processed_state.clinical_note.split())} words\"\n",
        "})\n",
        "\n",
        "print_state_section(\"PREVIOUS MEDICAL CONTEXT\", {\n",
        "    \"Previous Problems\": f\"{len(processed_state.previous_problems)} items\",\n",
        "    \"Previous Care Plans\": f\"{len(processed_state.previous_care_plans)} items\",\n",
        "    \"Treatment Tracker\": \"Present\" if processed_state.treatment_tracker else \"None\"\n",
        "})\n",
        "\n",
        "if processed_state.treatment_tracker:\n",
        "    print_state_section(\"TREATMENT TIMELINE TRACKER\", processed_state.treatment_tracker)\n",
        "\n",
        "print_state_section(\"PREVIOUS PROBLEMS\", processed_state.previous_problems, max_items=5)\n",
        "\n",
        "print_state_section(\"PREVIOUS CARE PLANS\", processed_state.previous_care_plans, max_items=5)\n",
        "\n",
        "print_state_section(\"PROCESSING CONTROL\", {\n",
        "    \"Current Step\": processed_state.current_step,\n",
        "    \"Current Agent\": processed_state.current_agent or \"None\",\n",
        "    \"Processing Mode\": processed_state.processing_mode,\n",
        "    \"Is Complete\": processed_state.is_complete,\n",
        "    \"Iterations\": processed_state.iterations,\n",
        "    \"Extraction Attempts\": processed_state.extraction_attempts\n",
        "})\n",
        "\n",
        "print_state_section(\"PROCESSING CONFIGURATION\", {\n",
        "    \"Max Extraction Attempts\": processed_state.max_extraction_attempts,\n",
        "    \"Enable Caching\": processed_state.enable_caching,\n",
        "    \"Enable Markdown Logging\": processed_state.enable_markdown_logging\n",
        "})\n",
        "\n",
        "print_state_section(\"TIMING INFORMATION\", {\n",
        "    \"Processing Start Time\": processed_state.processing_start_time,\n",
        "    \"Processing End Time\": processed_state.processing_end_time or \"Not completed\"\n",
        "})\n",
        "\n",
        "print_state_section(\"AGENT EXECUTION HISTORY\", processed_state.agent_history, max_items=10)\n",
        "\n",
        "print_state_section(\"DEBUG LOGS\", processed_state.debug_logs, max_items=10)\n",
        "\n",
        "print_state_section(\"PRIORITY ALERTS\", processed_state.priority_alerts)\n",
        "\n",
        "print_state_section(\"WARNINGS\", processed_state.warnings)\n",
        "\n",
        "print_state_section(\"ERRORS\", processed_state.errors)\n",
        "\n",
        "print_state_section(\"PROCESSING METRICS\", processed_state.processing_metrics)\n",
        "\n",
        "# Display extracted data (will be empty until extraction agents run)\n",
        "print_state_section(\"EXTRACTED PROBLEMS\", processed_state.extracted_problems)\n",
        "print_state_section(\"EXTRACTED CARE PLANS\", processed_state.extracted_care_plans)\n",
        "\n",
        "# Display tool call results (will be empty until agents run)\n",
        "print_state_section(\"VALIDATION RESULTS\", processed_state.validation_results or {})\n",
        "print_state_section(\"ANALYSIS RESULTS\", processed_state.analysis_results or {})\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ðŸ“‹ STATE SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Patient: {processed_state.patient_mrn}\")\n",
        "print(f\"Processing Mode: {processed_state.processing_mode}\")\n",
        "print(f\"Current Step: {processed_state.current_step}\")\n",
        "print(f\"Ready for Next Agent: {'problem_extraction_agent' if processed_state.current_step == 'problem_extraction' else 'Unknown'}\")\n",
        "print(f\"Emergency Mode: {'YES' if processed_state.processing_mode == 'emergency' else 'NO'}\")\n",
        "print(f\"Treatment Timeline: {processed_state.treatment_tracker.get_timeline_status() if processed_state.treatment_tracker else 'No tracker'}\")\n",
        "print(f\"Total Agent History Items: {len(processed_state.agent_history)}\")\n",
        "print(f\"Total Debug Logs: {len(processed_state.debug_logs)}\")\n",
        "print(f\"Errors: {len(processed_state.errors)}\")\n",
        "print(f\"Priority Alerts: {len(processed_state.priority_alerts)}\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ NEXT STEPS:\")\n",
        "print(\"1. The state is now ready for the problem_extraction_agent\")\n",
        "print(\"2. The start_agent determined the processing mode based on clinical context\")\n",
        "print(\"3. Treatment tracker has been updated with current timeline status\")\n",
        "print(\"4. Emergency detection has been performed\")\n",
        "print(\"5. All debugging and performance tracking is initialized\")\n",
        "\n",
        "print(\"\\nâœ… COMPLETE STATE ACTIVATION SUCCESSFUL!\")\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtclcg_k8oK_",
        "outputId": "dfd871a5-dff5-4335-84dc-4cebe121294b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ STARTING COMPLETE MEDICAL AGENT WORKFLOW EXAMPLE\n",
            "======================================================================\n",
            "\n",
            "ðŸ“ Step 1: Creating sample input data...\n",
            "âœ… Created clinical note (220 words)\n",
            "âœ… Created 2 previous problems\n",
            "âœ… Created 3 previous care plans\n",
            "âœ… Created treatment tracker (Status: Treatment started on time (started 14 days early))\n",
            "\n",
            "ðŸ—ï¸ Step 2: Creating initial MedicalAgentState...\n",
            "âœ… Initial state created for patient: ONC12345\n",
            "âœ… Clinical note date: 2024-01-15\n",
            "âœ… Note author: Dr. Sarah Johnson\n",
            "âœ… Initial processing mode: comprehensive\n",
            "\n",
            "ðŸŽ¯ Step 3: Executing start_agent...\n",
            "--------------------------------------------------\n",
            "âœ… start_agent execution completed successfully\n",
            "--------------------------------------------------\n",
            "\n",
            "ðŸ“Š COMPLETE MEDICAL AGENT STATE AFTER START_AGENT\n",
            "======================================================================\n",
            "\n",
            "ðŸ”¹ CORE INPUT DATA\n",
            "----------------------------------------\n",
            "  Patient MRN: ONC12345...\n",
            "  Note Date: 2024-01-15...\n",
            "  Note Author: Dr. Sarah Johnson...\n",
            "  Clinical Note Length: 220 words...\n",
            "\n",
            "ðŸ”¹ PREVIOUS MEDICAL CONTEXT\n",
            "----------------------------------------\n",
            "  Previous Problems: 2 items...\n",
            "  Previous Care Plans: 3 items...\n",
            "  Treatment Tracker: Present...\n",
            "\n",
            "ðŸ”¹ TREATMENT TIMELINE TRACKER\n",
            "----------------------------------------\n",
            "  Patient Status: regular\n",
            "  Timeline Status: Treatment started on time (started 14 days early)\n",
            "  First Visit: 2023-11-15\n",
            "  Target Treatment Date: 2023-12-15\n",
            "  Treatment Started: 2023-12-01\n",
            "  Proposed Stage: Stage II (T2N1M0)\n",
            "\n",
            "ðŸ”¹ PREVIOUS PROBLEMS\n",
            "----------------------------------------\n",
            "  1. Stage II Invasive Ductal Carcinoma (Priority: critical, Status: Active)\n",
            "  2. Hypertension (Priority: regular, Status: Active)\n",
            "\n",
            "ðŸ”¹ PREVIOUS CARE PLANS\n",
            "----------------------------------------\n",
            "  1. Complete 6 cycles of AC-T chemotherapy (Urgency: urgent, Status: in-progress)\n",
            "  2. Monitor blood counts before each cycle (Urgency: urgent, Status: pending)\n",
            "  3. Supportive care consultation for fatigue management (Urgency: non-urgent, Status: pending)\n",
            "\n",
            "ðŸ”¹ PROCESSING CONTROL\n",
            "----------------------------------------\n",
            "  Current Step: problem_extraction...\n",
            "  Current Agent: None...\n",
            "  Processing Mode: emergency...\n",
            "  Is Complete: False...\n",
            "  Iterations: 1...\n",
            "  Extraction Attempts: 0...\n",
            "\n",
            "ðŸ”¹ PROCESSING CONFIGURATION\n",
            "----------------------------------------\n",
            "  Max Extraction Attempts: 2...\n",
            "  Enable Caching: False...\n",
            "  Enable Markdown Logging: False...\n",
            "\n",
            "ðŸ”¹ TIMING INFORMATION\n",
            "----------------------------------------\n",
            "  Processing Start Time: 2025-09-09T19:27:50.760931...\n",
            "  Processing End Time: Not completed...\n",
            "\n",
            "ðŸ”¹ AGENT EXECUTION HISTORY\n",
            "----------------------------------------\n",
            "  1. start_agent: Initializing medical information processing....\n",
            "  2. start_agent completed: Mode=emergency, Next=problem_extraction, Patient=ONC12345...\n",
            "\n",
            "ðŸ”¹ DEBUG LOGS\n",
            "----------------------------------------\n",
            "  1. start_agent: Input validation successful....\n",
            "  2. start_agent: Clinical note length: 220 words...\n",
            "  3. start_agent: Previous problems: 2...\n",
            "  4. start_agent: Previous care plans: 3...\n",
            "  5. start_agent: Clinical context analysis - Critical findings: True, Cancer context: True...\n",
            "  6. start_agent: Treatment tracker updated - Status: Treatment started on time (started 14 days early)...\n",
            "  7. start_agent: Processing mode: EMERGENCY - Critical medical situation detected...\n",
            "\n",
            "ðŸ”¹ PRIORITY ALERTS\n",
            "----------------------------------------\n",
            "  1. EMERGENCY: critical findings in clinical note...\n",
            "\n",
            "ðŸ”¹ WARNINGS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "ðŸ”¹ ERRORS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "ðŸ”¹ PROCESSING METRICS\n",
            "----------------------------------------\n",
            "  start_agent_summary: {'processing_mode': 'emergency', 'clinical_note_length': 220, 'previous_problems...\n",
            "\n",
            "ðŸ”¹ EXTRACTED PROBLEMS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "ðŸ”¹ EXTRACTED CARE PLANS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "ðŸ”¹ VALIDATION RESULTS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "ðŸ”¹ ANALYSIS RESULTS\n",
            "----------------------------------------\n",
            "  (Empty)\n",
            "\n",
            "======================================================================\n",
            "ðŸ“‹ STATE SUMMARY\n",
            "======================================================================\n",
            "Patient: ONC12345\n",
            "Processing Mode: emergency\n",
            "Current Step: problem_extraction\n",
            "Ready for Next Agent: problem_extraction_agent\n",
            "Emergency Mode: YES\n",
            "Treatment Timeline: Treatment started on time (started 14 days early)\n",
            "Total Agent History Items: 2\n",
            "Total Debug Logs: 7\n",
            "Errors: 0\n",
            "Priority Alerts: 1\n",
            "\n",
            "ðŸŽ¯ NEXT STEPS:\n",
            "1. The state is now ready for the problem_extraction_agent\n",
            "2. The start_agent determined the processing mode based on clinical context\n",
            "3. Treatment tracker has been updated with current timeline status\n",
            "4. Emergency detection has been performed\n",
            "5. All debugging and performance tracking is initialized\n",
            "\n",
            "âœ… COMPLETE STATE ACTIVATION SUCCESSFUL!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "126d6256",
        "outputId": "0a083e3d-fdf6-47e4-a41d-ca2c6494a700"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, MedicalProblem, PriorityClassifier are defined in previous cells\n",
        "\n",
        "def problem_extraction_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that extracts medical problems from the clinical note.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with extracted problems.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing problem_extraction_agent...\")\n",
        "    state.agent_history.append(\"problem_extraction_agent: Extracting medical problems.\")\n",
        "    state.current_agent = \"problem_extraction_agent\"\n",
        "    state.extraction_attempts += 1\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # Define the extraction prompt\n",
        "    problem_extraction_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a highly skilled medical AI assistant specialized in extracting key medical problems from clinical notes.\n",
        "         Your goal is to identify significant, clinically relevant problems and represent them in a structured JSON format.\n",
        "         Focus on primary diagnoses, significant complications, treatment side effects, and psychosocial concerns.\n",
        "         CONSOLIDATION: Group related symptoms into a single problem. Use standard medical terminology where possible. Avoid listing minor or transient issues unless they are significant in context.\n",
        "         Consider the patient's existing problems to identify new developments or changes.\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the output as a JSON array of objects, where each object represents a medical problem.\n",
        "         The JSON array MUST conform to the following structure:\n",
        "         [\n",
        "           {{\n",
        "             \"problem_name\": \"string (Name of the medical problem)\",\n",
        "             \"status\": \"string (['Active'|'Inactive'] based on the note)\",\n",
        "             \"evidence\": \"string (Relevant text snippet from the note)\",\n",
        "             \"is_cancer_related\": \"boolean (True if related to cancer diagnosis or treatment)\",\n",
        "             \"is_treatment_related\": \"boolean (True if a side effect or complication of treatment)\",\n",
        "             \"is_psychosocial\": \"boolean (True if related to mental health, social issues, or emotional distress)\",\n",
        "             \"date_identified\": \"string (YYYY-MM-DD format, date mentioned in note or note date if not specified)\"\n",
        "           }},\n",
        "           ...\n",
        "         ]\n",
        "         Ensure the JSON is valid and contains ONLY the JSON array. Do not include any introductory or concluding text outside the JSON.\n",
        "         If no significant problems are found, return an empty JSON array [].\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Extract significant medical problems from clinical note for patient MRN: {mrn}.\n",
        "         Clinical Note: {clinical_note}\n",
        "         Consider existing problems: {previous_problems}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = problem_extraction_prompt | llm\n",
        "\n",
        "    try:\n",
        "        # Format previous problems for inclusion in the prompt\n",
        "        previous_problems_str = json.dumps([p.model_dump() for p in state.previous_problems], indent=2)\n",
        "\n",
        "        # Invoke the LLM\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"clinical_note\": state.clinical_note,\n",
        "            \"previous_problems\": previous_problems_str\n",
        "        })\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        logging.debug(f\"Raw extraction response: {response.content}\")\n",
        "        extracted_data = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(extracted_data, list):\n",
        "             raise ValueError(\"Expected JSON array, but received a different structure.\")\n",
        "\n",
        "        newly_extracted_problems: List[MedicalProblem] = []\n",
        "        for item in extracted_data:\n",
        "            try:\n",
        "                # Create MedicalProblem object\n",
        "                problem = MedicalProblem(\n",
        "                    # Use UUID default or potentially a hash for stability if needed later\n",
        "                    # problem_id=str(uuid.uuid4()), # Let Pydantic handle default\n",
        "                    problem_name=item.get(\"problem_name\", \"Unknown Problem\"),\n",
        "                    patient_mrn=state.patient_mrn,\n",
        "                    status=item.get(\"status\", \"Active\"), # Default to Active if not provided\n",
        "                    evidence=item.get(\"evidence\"),\n",
        "                    is_cancer_related=item.get(\"is_cancer_related\", False),\n",
        "                    is_treatment_related=item.get(\"is_treatment_related\", False),\n",
        "                    is_psychosocial=item.get(\"is_psychosocial\", False),\n",
        "                    date_identified=item.get(\"date_identified\", state.note_date) # Default to note date\n",
        "                    # priority_flag and severity_level will be set below or by other agents\n",
        "                )\n",
        "\n",
        "                # Automatically classify priority based on problem name and note context\n",
        "                problem.priority_flag = PriorityClassifier.classify_problem_priority(\n",
        "                    problem_name=problem.problem_name,\n",
        "                    clinical_context=state.clinical_note # Use full note for context\n",
        "                    # patient_status could be added if available in state\n",
        "                )\n",
        "\n",
        "                # Basic validation check (more robust validation can be a separate agent)\n",
        "                if not problem.problem_name or problem.problem_name.strip() == \"Unknown Problem\":\n",
        "                    state.warnings.append(f\"Extracted problem with missing or generic name: {item}\")\n",
        "                    continue # Skip adding this problem\n",
        "\n",
        "                newly_extracted_problems.append(problem)\n",
        "                state.debug_logs.append(f\"Extracted and validated problem: {problem.problem_name} (Priority: {problem.priority_flag})\")\n",
        "\n",
        "            except ValidationError as e:\n",
        "                state.errors.append(f\"Validation error creating MedicalProblem from extracted data: {item} - {e}\")\n",
        "                logging.error(f\"Validation error: {e}\")\n",
        "            except Exception as e:\n",
        "                 state.errors.append(f\"Unexpected error processing extracted problem item: {item} - {e}\")\n",
        "                 logging.error(f\"Error processing item: {item}, error: {e}\")\n",
        "\n",
        "\n",
        "        state.extracted_problems = newly_extracted_problems\n",
        "        state.debug_logs.append(f\"problem_extraction_agent: Successfully extracted {len(state.extracted_problems)} problems.\")\n",
        "        logging.info(f\"Successfully extracted {len(state.extracted_problems)} problems.\")\n",
        "\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"problem_extraction_agent JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.warnings.append(\"Failed to parse JSON from extraction agent. This might require re-extraction or manual review.\")\n",
        "        logging.error(error_msg)\n",
        "        # Depending on strategy, you might increment a failure counter or retry.\n",
        "        # For now, just log the error and move on with no new problems.\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"problem_extraction_agent unexpected error during extraction: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    # This agent is done with extraction, the graph will decide where to go next\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    logging.info(\"problem_extraction_agent completed.\")\n",
        "    state.agent_history.append(f\"problem_extraction_agent: Finished extraction. Extracted {len(state.extracted_problems)} problems.\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… problem_extraction_agent function defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… problem_extraction_agent function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Real Care Plan Extraction Agent Test - Using Actual LLM\n",
        "# Execute this cell to test care_plan_extraction_agent with real LLM calls\n",
        "\n",
        "import logging\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "print(\"REAL CARE PLAN EXTRACTION AGENT TEST\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# =============================================================================\n",
        "# SETUP: Real LLM Configuration (if not already defined)\n",
        "# =============================================================================\n",
        "\n",
        "def get_llm():\n",
        "    \"\"\"Get real LLM instance for testing.\"\"\"\n",
        "    try:\n",
        "        return ChatOpenAI(\n",
        "            model_name=\"gpt-4o-mini\",\n",
        "            temperature=0.1,\n",
        "            api_key=userdata.get('OPENAI_API_KEY')  # From Colab secrets\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up LLM: {e}\")\n",
        "        print(\"Make sure OPENAI_API_KEY is set in Colab secrets\")\n",
        "        raise\n",
        "\n",
        "print(\"Setting up real LLM connection...\")\n",
        "try:\n",
        "    test_llm = get_llm()\n",
        "    print(\"âœ… LLM connection successful\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ LLM setup failed: {e}\")\n",
        "    print(\"Please ensure your OpenAI API key is configured in Colab secrets\")\n",
        "\n",
        "# =============================================================================\n",
        "# PRE-EXTRACTION STATE ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nCURRENT STATE (after problem extraction):\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Patient MRN: {processed_state.patient_mrn}\")\n",
        "print(f\"Current Step: {processed_state.current_step}\")\n",
        "print(f\"Processing Mode: {processed_state.processing_mode}\")\n",
        "print(f\"Extraction Attempts: {processed_state.extraction_attempts}\")\n",
        "print(f\"Previous Care Plans: {len(processed_state.previous_care_plans)}\")\n",
        "print(f\"Extracted Care Plans: {len(processed_state.extracted_care_plans)}\")\n",
        "\n",
        "print(f\"\\nEXISTING CARE PLANS ({len(processed_state.previous_care_plans)}):\")\n",
        "for i, plan in enumerate(processed_state.previous_care_plans, 1):\n",
        "    print(f\"  {i}. {plan.suggested_plan}\")\n",
        "    print(f\"     Urgency: {plan.urgency_level} | Action: {plan.action_type}\")\n",
        "    print(f\"     Due: {plan.date_due} | Status: {getattr(plan, 'workflow_status', 'N/A')}\")\n",
        "\n",
        "print(f\"\\nEXTRACTED PROBLEMS ({len(processed_state.extracted_problems)}):\")\n",
        "for i, problem in enumerate(processed_state.extracted_problems, 1):\n",
        "    print(f\"  {i}. {problem.problem_name}\")\n",
        "    print(f\"     Priority: {problem.priority_flag} | Cancer: {problem.is_cancer_related}\")\n",
        "\n",
        "print(f\"\\nCLINICAL NOTE PREVIEW:\")\n",
        "note_lines = processed_state.clinical_note.split('\\n')[:5]\n",
        "for line in note_lines:\n",
        "    if line.strip():\n",
        "        print(f\"  {line.strip()}\")\n",
        "print(f\"  ... ({len(processed_state.clinical_note.split())} total words)\")\n",
        "\n",
        "# Treatment tracker context if available\n",
        "if hasattr(processed_state, 'treatment_tracker') and processed_state.treatment_tracker:\n",
        "    print(f\"\\nTREATMENT TRACKER CONTEXT:\")\n",
        "    print(f\"  Patient Status: {processed_state.treatment_tracker.patient_status}\")\n",
        "    print(f\"  Proposed Stage: {processed_state.treatment_tracker.proposed_stage}\")\n",
        "    print(f\"  Timeline Status: {processed_state.treatment_tracker.get_timeline_status()}\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXECUTE REAL CARE PLAN EXTRACTION\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nðŸ”„ EXECUTING CARE PLAN EXTRACTION AGENT WITH REAL LLM...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Store pre-extraction counts for comparison\n",
        "pre_agent_history = len(processed_state.agent_history)\n",
        "pre_debug_logs = len(processed_state.debug_logs)\n",
        "pre_errors = len(processed_state.errors)\n",
        "pre_warnings = len(processed_state.warnings)\n",
        "pre_care_plans = len(processed_state.extracted_care_plans)\n",
        "pre_extraction_attempts = processed_state.extraction_attempts\n",
        "\n",
        "# Execute the real agent\n",
        "try:\n",
        "    print(\"ðŸ“ž Making LLM API call...\")\n",
        "    extracted_state = care_plan_extraction_agent(processed_state)\n",
        "    print(\"âœ… Care plan extraction completed successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during extraction: {e}\")\n",
        "    extracted_state = processed_state\n",
        "\n",
        "# =============================================================================\n",
        "# ANALYZE REAL EXTRACTION RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nðŸ“Š EXTRACTION RESULTS:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Basic metrics\n",
        "care_plans_found = len(extracted_state.extracted_care_plans)\n",
        "new_care_plans = care_plans_found - pre_care_plans\n",
        "new_errors = len(extracted_state.errors) - pre_errors\n",
        "new_warnings = len(extracted_state.warnings) - pre_warnings\n",
        "new_history = len(extracted_state.agent_history) - pre_agent_history\n",
        "new_debug = len(extracted_state.debug_logs) - pre_debug_logs\n",
        "extraction_attempts_increase = extracted_state.extraction_attempts - pre_extraction_attempts\n",
        "\n",
        "print(f\"Care Plans Extracted: {new_care_plans} (Total: {care_plans_found})\")\n",
        "print(f\"New Errors: {new_errors}\")\n",
        "print(f\"New Warnings: {new_warnings}\")\n",
        "print(f\"Agent History Entries: {new_history}\")\n",
        "print(f\"Debug Log Entries: {new_debug}\")\n",
        "print(f\"Extraction Attempts: {extracted_state.extraction_attempts} (+{extraction_attempts_increase})\")\n",
        "\n",
        "# Display newly extracted care plans\n",
        "if new_care_plans > 0:\n",
        "    print(f\"\\nðŸ¥ NEWLY EXTRACTED CARE PLANS ({new_care_plans}):\")\n",
        "    # Show only the newly extracted plans\n",
        "    new_plans = extracted_state.extracted_care_plans[pre_care_plans:]\n",
        "    for i, plan in enumerate(new_plans, 1):\n",
        "        # Create flag indicators\n",
        "        flags = []\n",
        "        if plan.critical_finding:\n",
        "            flags.append(\"ðŸ”´ Critical\")\n",
        "\n",
        "        # Urgency indicator\n",
        "        urgency_icon = {\"urgent\": \"ðŸ”¥\", \"non-urgent\": \"ðŸ“…\"}.get(plan.urgency_level, \"âšª\")\n",
        "\n",
        "        # Action type icon\n",
        "        action_icons = {\n",
        "            \"diagnostic\": \"ðŸ”¬\",\n",
        "            \"treatment\": \"ðŸ’Š\",\n",
        "            \"consultation\": \"ðŸ‘©â€âš•ï¸\",\n",
        "            \"follow-up\": \"ðŸ“‹\",\n",
        "            \"monitoring\": \"ðŸ“Š\",\n",
        "            \"medication\": \"ðŸ’‰\",\n",
        "            \"procedure\": \"âš•ï¸\"\n",
        "        }\n",
        "        action_icon = action_icons.get(plan.action_type, \"ðŸ“\")\n",
        "\n",
        "        print(f\"\\n  {i}. {plan.suggested_plan}\")\n",
        "        print(f\"     {urgency_icon} Urgency: {plan.urgency_level}\")\n",
        "        print(f\"     {action_icon} Action Type: {plan.action_type}\")\n",
        "        print(f\"     ðŸ“… Due Date: {plan.date_due}\")\n",
        "        print(f\"     â±ï¸ Duration: {plan.estimated_duration or 'Not specified'}\")\n",
        "        print(f\"     ðŸ“Š Status: {getattr(plan, 'workflow_status', 'N/A')}\")\n",
        "        if hasattr(plan, 'days_overdue') and plan.days_overdue:\n",
        "            print(f\"     âš ï¸ Days Overdue: {plan.days_overdue}\")\n",
        "        if flags:\n",
        "            print(f\"     Flags: {' | '.join(flags)}\")\n",
        "        print(f\"     ðŸ“ Author: {plan.note_author}\")\n",
        "        print(f\"     ðŸ“† Note Date: {plan.note_date}\")\n",
        "else:\n",
        "    print(f\"\\nâŒ No new care plans were extracted\")\n",
        "\n",
        "# Show new agent history\n",
        "new_history_entries = extracted_state.agent_history[pre_agent_history:]\n",
        "if new_history_entries:\n",
        "    print(f\"\\nðŸ“ NEW AGENT HISTORY:\")\n",
        "    for entry in new_history_entries:\n",
        "        print(f\"  â€¢ {entry}\")\n",
        "\n",
        "# Show new debug logs\n",
        "new_debug_entries = extracted_state.debug_logs[pre_debug_logs:]\n",
        "if new_debug_entries:\n",
        "    print(f\"\\nðŸ” NEW DEBUG LOGS:\")\n",
        "    for entry in new_debug_entries[:5]:  # Show first 5\n",
        "        print(f\"  â€¢ {entry}\")\n",
        "    if len(new_debug_entries) > 5:\n",
        "        print(f\"  ... and {len(new_debug_entries) - 5} more debug entries\")\n",
        "\n",
        "# Show any errors or warnings\n",
        "if new_errors > 0:\n",
        "    print(f\"\\nâŒ NEW ERRORS:\")\n",
        "    for error in extracted_state.errors[pre_errors:]:\n",
        "        print(f\"  â€¢ {error}\")\n",
        "\n",
        "if new_warnings > 0:\n",
        "    print(f\"\\nâš ï¸ NEW WARNINGS:\")\n",
        "    for warning in extracted_state.warnings[pre_warnings:]:\n",
        "        print(f\"  â€¢ {warning}\")\n",
        "\n",
        "# =============================================================================\n",
        "# CARE PLAN ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "if new_care_plans > 0:\n",
        "    print(f\"\\nðŸ©º CARE PLAN ANALYSIS:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    new_plans = extracted_state.extracted_care_plans[pre_care_plans:]\n",
        "\n",
        "    # Count urgency levels\n",
        "    urgent_count = sum(1 for p in new_plans if p.urgency_level == \"urgent\")\n",
        "    non_urgent_count = sum(1 for p in new_plans if p.urgency_level == \"non-urgent\")\n",
        "\n",
        "    # Count action types\n",
        "    action_types = {}\n",
        "    for plan in new_plans:\n",
        "        action_types[plan.action_type] = action_types.get(plan.action_type, 0) + 1\n",
        "\n",
        "    # Count critical findings\n",
        "    critical_count = sum(1 for p in new_plans if p.critical_finding)\n",
        "\n",
        "    # Count workflow statuses\n",
        "    workflow_statuses = {}\n",
        "    for plan in new_plans:\n",
        "        status = getattr(plan, 'workflow_status', 'unknown')\n",
        "        workflow_statuses[status] = workflow_statuses.get(status, 0) + 1\n",
        "\n",
        "    print(f\"Urgency Distribution:\")\n",
        "    print(f\"  ðŸ”¥ Urgent: {urgent_count}\")\n",
        "    print(f\"  ðŸ“… Non-urgent: {non_urgent_count}\")\n",
        "\n",
        "    print(f\"\\nAction Type Breakdown:\")\n",
        "    for action_type, count in sorted(action_types.items()):\n",
        "        icon = action_icons.get(action_type, \"ðŸ“\")\n",
        "        print(f\"  {icon} {action_type.title()}: {count}\")\n",
        "\n",
        "    print(f\"\\nCritical Findings:\")\n",
        "    print(f\"  ðŸ”´ Critical: {critical_count}/{new_care_plans}\")\n",
        "\n",
        "    print(f\"\\nWorkflow Status:\")\n",
        "    for status, count in sorted(workflow_statuses.items()):\n",
        "        print(f\"  ðŸ“Š {status.title()}: {count}\")\n",
        "\n",
        "    # Quality check\n",
        "    complete_plans = sum(1 for p in new_plans\n",
        "                        if p.suggested_plan and p.date_due and p.action_type)\n",
        "    print(f\"\\nData Quality:\")\n",
        "    print(f\"  Complete plans: {complete_plans}/{new_care_plans}\")\n",
        "\n",
        "    # Date analysis\n",
        "    from datetime import datetime, date\n",
        "    future_plans = 0\n",
        "    past_due_plans = 0\n",
        "    today = date.today()\n",
        "\n",
        "    for plan in new_plans:\n",
        "        try:\n",
        "            due_date = datetime.strptime(plan.date_due, \"%Y-%m-%d\").date()\n",
        "            if due_date > today:\n",
        "                future_plans += 1\n",
        "            elif due_date < today:\n",
        "                past_due_plans += 1\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(f\"  Future due dates: {future_plans}\")\n",
        "    print(f\"  Past due dates: {past_due_plans}\")\n",
        "\n",
        "# =============================================================================\n",
        "# WORKFLOW STATUS\n",
        "# =============================================================================\n",
        "\n",
        "print(f\"\\nðŸ”„ WORKFLOW STATUS:\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Current Agent: {extracted_state.current_agent or 'None (ready for next)'}\")\n",
        "print(f\"Current Step: {extracted_state.current_step}\")\n",
        "print(f\"Processing Complete: {extracted_state.is_complete}\")\n",
        "\n",
        "# Total care plan count\n",
        "total_care_plans = len(extracted_state.extracted_care_plans)\n",
        "total_previous_plans = len(extracted_state.previous_care_plans)\n",
        "print(f\"\\nCare Plan Summary:\")\n",
        "print(f\"  Previous: {total_previous_plans}\")\n",
        "print(f\"  Newly Extracted: {new_care_plans}\")\n",
        "print(f\"  Total Active: {total_care_plans}\")\n",
        "\n",
        "# Show relationship to extracted problems\n",
        "print(f\"\\nContext Summary:\")\n",
        "print(f\"  Problems identified: {len(extracted_state.extracted_problems)}\")\n",
        "print(f\"  Care plans created: {new_care_plans}\")\n",
        "print(f\"  Plans per problem: {new_care_plans / len(extracted_state.extracted_problems) if extracted_state.extracted_problems else 0:.1f}\")\n",
        "\n",
        "print(f\"\\nâœ… State ready for next agent or completion\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHdQKVP__PgJ",
        "outputId": "5ed58193-3072-424f-cf8a-36e9ec1420d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REAL CARE PLAN EXTRACTION AGENT TEST\n",
            "==================================================\n",
            "Setting up real LLM connection...\n",
            "âœ… LLM connection successful\n",
            "\n",
            "CURRENT STATE (after problem extraction):\n",
            "------------------------------\n",
            "Patient MRN: ONC12345\n",
            "Current Step: problem_extraction\n",
            "Processing Mode: emergency\n",
            "Extraction Attempts: 1\n",
            "Previous Care Plans: 3\n",
            "Extracted Care Plans: 0\n",
            "\n",
            "EXISTING CARE PLANS (3):\n",
            "  1. Complete 6 cycles of AC-T chemotherapy\n",
            "     Urgency: urgent | Action: treatment\n",
            "     Due: 2024-02-15 | Status: in-progress\n",
            "  2. Monitor blood counts before each cycle\n",
            "     Urgency: urgent | Action: monitoring\n",
            "     Due: 2024-01-20 | Status: pending\n",
            "  3. Supportive care consultation for fatigue management\n",
            "     Urgency: non-urgent | Action: consultation\n",
            "     Due: 2024-01-25 | Status: pending\n",
            "\n",
            "EXTRACTED PROBLEMS (3):\n",
            "  1. Worsening Fatigue\n",
            "     Priority: important | Cancer: True\n",
            "  2. Chemotherapy-Induced Peripheral Neuropathy\n",
            "     Priority: important | Cancer: True\n",
            "  3. Treatment-Related Anxiety\n",
            "     Priority: important | Cancer: True\n",
            "\n",
            "CLINICAL NOTE PREVIEW:\n",
            "  Patient: Jane Smith\n",
            "  MRN: ONC12345\n",
            "  Date: 2024-01-15\n",
            "  Provider: Dr. Sarah Johnson, Oncology\n",
            "  ... (220 total words)\n",
            "\n",
            "TREATMENT TRACKER CONTEXT:\n",
            "  Patient Status: regular\n",
            "  Proposed Stage: Stage II (T2N1M0)\n",
            "  Timeline Status: Treatment started on time (started 14 days early)\n",
            "\n",
            "ðŸ”„ EXECUTING CARE PLAN EXTRACTION AGENT WITH REAL LLM...\n",
            "--------------------------------------------------\n",
            "ðŸ“ž Making LLM API call...\n",
            "âœ… Care plan extraction completed successfully\n",
            "\n",
            "ðŸ“Š EXTRACTION RESULTS:\n",
            "------------------------------\n",
            "Care Plans Extracted: 5 (Total: 5)\n",
            "New Errors: 0\n",
            "New Warnings: 0\n",
            "Agent History Entries: 2\n",
            "Debug Log Entries: 6\n",
            "Extraction Attempts: 2 (+1)\n",
            "\n",
            "ðŸ¥ NEWLY EXTRACTED CARE PLANS (5):\n",
            "\n",
            "  1. Refer to supportive care for chemotherapy-induced fatigue management\n",
            "     ðŸ“… Urgency: non-urgent\n",
            "     ðŸ‘©â€âš•ï¸ Action Type: consultation\n",
            "     ðŸ“… Due Date: 2024-01-20\n",
            "     â±ï¸ Duration: 1 hour\n",
            "     ðŸ“Š Status: pending\n",
            "     ðŸ“ Author: Dr. Sarah Johnson\n",
            "     ðŸ“† Note Date: 2024-01-15\n",
            "\n",
            "  2. Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen\n",
            "     ðŸ“… Urgency: non-urgent\n",
            "     ðŸ’Š Action Type: treatment\n",
            "     ðŸ“… Due Date: 2024-02-15\n",
            "     â±ï¸ Duration: ongoing\n",
            "     ðŸ“Š Status: pending\n",
            "     ðŸ“ Author: Dr. Sarah Johnson\n",
            "     ðŸ“† Note Date: 2024-01-15\n",
            "\n",
            "  3. Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry\n",
            "     ðŸ“… Urgency: non-urgent\n",
            "     ðŸ‘©â€âš•ï¸ Action Type: consultation\n",
            "     ðŸ“… Due Date: 2024-02-15\n",
            "     â±ï¸ Duration: ongoing\n",
            "     ðŸ“Š Status: pending\n",
            "     ðŸ“ Author: Dr. Sarah Johnson\n",
            "     ðŸ“† Note Date: 2024-01-15\n",
            "\n",
            "  4. Complete labs prior to next chemotherapy cycle to check blood counts\n",
            "     ðŸ“… Urgency: non-urgent\n",
            "     ðŸ”¬ Action Type: diagnostic\n",
            "     ðŸ“… Due Date: 2024-01-20\n",
            "     â±ï¸ Duration: 1 day\n",
            "     ðŸ“Š Status: pending\n",
            "     ðŸ“ Author: Dr. Sarah Johnson\n",
            "     ðŸ“† Note Date: 2024-01-15\n",
            "\n",
            "  5. Follow-up in clinic in 1 week\n",
            "     ðŸ“… Urgency: non-urgent\n",
            "     ðŸ“‹ Action Type: follow-up\n",
            "     ðŸ“… Due Date: 2024-01-22\n",
            "     â±ï¸ Duration: 1 hour\n",
            "     ðŸ“Š Status: pending\n",
            "     ðŸ“ Author: Dr. Sarah Johnson\n",
            "     ðŸ“† Note Date: 2024-01-15\n",
            "\n",
            "ðŸ“ NEW AGENT HISTORY:\n",
            "  â€¢ care_plan_extraction_agent: Extracting care plans.\n",
            "  â€¢ care_plan_extraction_agent: Finished extraction. Extracted 5 care plans.\n",
            "\n",
            "ðŸ” NEW DEBUG LOGS:\n",
            "  â€¢ Extracted and validated care plan: Refer to supportive care for chemotherapy-induced fatigue management (Urgency: non-urgent, Status: pending)\n",
            "  â€¢ Extracted and validated care plan: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Urgency: non-urgent, Status: pending)\n",
            "  â€¢ Extracted and validated care plan: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Urgency: non-urgent, Status: pending)\n",
            "  â€¢ Extracted and validated care plan: Complete labs prior to next chemotherapy cycle to check blood counts (Urgency: non-urgent, Status: pending)\n",
            "  â€¢ Extracted and validated care plan: Follow-up in clinic in 1 week (Urgency: non-urgent, Status: pending)\n",
            "  ... and 1 more debug entries\n",
            "\n",
            "ðŸ©º CARE PLAN ANALYSIS:\n",
            "------------------------------\n",
            "Urgency Distribution:\n",
            "  ðŸ”¥ Urgent: 0\n",
            "  ðŸ“… Non-urgent: 5\n",
            "\n",
            "Action Type Breakdown:\n",
            "  ðŸ‘©â€âš•ï¸ Consultation: 2\n",
            "  ðŸ”¬ Diagnostic: 1\n",
            "  ðŸ“‹ Follow-Up: 1\n",
            "  ðŸ’Š Treatment: 1\n",
            "\n",
            "Critical Findings:\n",
            "  ðŸ”´ Critical: 0/5\n",
            "\n",
            "Workflow Status:\n",
            "  ðŸ“Š Pending: 5\n",
            "\n",
            "Data Quality:\n",
            "  Complete plans: 5/5\n",
            "  Future due dates: 0\n",
            "  Past due dates: 5\n",
            "\n",
            "ðŸ”„ WORKFLOW STATUS:\n",
            "------------------------------\n",
            "Current Agent: None (ready for next)\n",
            "Current Step: problem_extraction\n",
            "Processing Complete: False\n",
            "\n",
            "Care Plan Summary:\n",
            "  Previous: 3\n",
            "  Newly Extracted: 5\n",
            "  Total Active: 5\n",
            "\n",
            "Context Summary:\n",
            "  Problems identified: 3\n",
            "  Care plans created: 5\n",
            "  Plans per problem: 1.7\n",
            "\n",
            "âœ… State ready for next agent or completion\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcda3060",
        "outputId": "81c0d2e4-8bfb-4114-86a3-2801e33cd1b9"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, CarePlan, PriorityClassifier, WorkflowCalculator are defined previously\n",
        "\n",
        "def care_plan_extraction_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that extracts actionable care plans from the clinical note.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with extracted care plans.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing care_plan_extraction_agent...\")\n",
        "    state.agent_history.append(\"care_plan_extraction_agent: Extracting care plans.\")\n",
        "    state.current_agent = \"care_plan_extraction_agent\"\n",
        "    state.extraction_attempts += 1 # Can track extraction attempts for both problem and care plans\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # Define the extraction prompt\n",
        "    care_plan_extraction_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a highly skilled medical AI assistant specialized in extracting actionable care plans from clinical notes.\n",
        "         Your goal is to identify clear, specific instructions or recommendations for patient care and represent them in a structured JSON format.\n",
        "         Focus on: diagnostic tests, treatments, consultations, follow-ups, monitoring, medication adjustments, or procedures.\n",
        "         Consider the patient's existing care plans to identify new, modified, or completed plans.\n",
        "\n",
        "         CLASSIFICATION INSTRUCTIONS:\n",
        "         - urgency_level: Classify as 'urgent' if the plan needs to be addressed within approximately 24-48 hours based on context, otherwise 'non-urgent' for routine scheduling.\n",
        "         - action_type: Classify the type of action required from the following list: 'diagnostic', 'treatment', 'consultation', 'follow-up', 'monitoring', 'medication', 'procedure'. Choose the most appropriate single type.\n",
        "         - critical_finding: Boolean flag, set to true if the plan is directly related to a critical or life-threatening finding mentioned in the note.\n",
        "         - date_due: Extract the specific date if mentioned (YYYY-MM-DD). If not mentioned, provide a reasonable default based on urgency (e.g., within a week for urgent, within a month for non-urgent), but prioritize extracting from the note.\n",
        "         - estimated_duration: Estimate the time required to complete the plan (e.g., \"1 hour\", \"3 days\", \"ongoing\").\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the output as a JSON array of objects, where each object represents a care plan.\n",
        "         The JSON array MUST conform to the following structure:\n",
        "         [\n",
        "           {{\n",
        "             \"suggested_plan\": \"string (Description of the care plan)\",\n",
        "             \"urgency_level\": \"string (['urgent'|'non-urgent'])\",\n",
        "             \"date_due\": \"string (YYYY-MM-DD, extracted or estimated)\",\n",
        "             \"action_type\": \"string (['diagnostic'|'treatment'|'consultation'|'follow-up'|'monitoring'|'medication'|'procedure'])\",\n",
        "             \"critical_finding\": \"boolean (True if related to critical finding)\",\n",
        "             \"estimated_duration\": \"string (Estimated time to complete)\"\n",
        "           }},\n",
        "           ...\n",
        "         ]\n",
        "         Ensure the JSON is valid and contains ONLY the JSON array. Do not include any introductory or concluding text outside the JSON.\n",
        "         If no actionable care plans are found, return an empty JSON array [].\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Extract actionable care plans from clinical note for patient MRN: {mrn}.\n",
        "         Clinical Note: {clinical_note}\n",
        "         Consider existing plans: {previous_care_plans}\n",
        "         Patient status context (from treatment tracker if available): {patient_status_context}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = care_plan_extraction_prompt | llm\n",
        "\n",
        "    try:\n",
        "        # Format previous plans for inclusion in the prompt\n",
        "        previous_care_plans_str = json.dumps([cp.model_dump() for cp in state.previous_care_plans], indent=2)\n",
        "\n",
        "        # Provide patient status context from treatment tracker if available\n",
        "        patient_status_context = \"N/A\"\n",
        "        if state.treatment_tracker:\n",
        "            patient_status_context = f\"Patient status: {state.treatment_tracker.patient_status}, Proposed stage: {state.treatment_tracker.proposed_stage or 'N/A'}, Treatment timeline status: {state.treatment_tracker.get_timeline_status()}\"\n",
        "\n",
        "        # Invoke the LLM\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"clinical_note\": state.clinical_note,\n",
        "            \"previous_care_plans\": previous_care_plans_str,\n",
        "            \"patient_status_context\": patient_status_context\n",
        "        })\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        logging.debug(f\"Raw care plan extraction response: {response.content}\")\n",
        "        extracted_data = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(extracted_data, list):\n",
        "             raise ValueError(\"Expected JSON array for care plans, but received a different structure.\")\n",
        "\n",
        "        newly_extracted_care_plans: List[CarePlan] = []\n",
        "        for item in extracted_data:\n",
        "            try:\n",
        "                # Create CarePlan object\n",
        "                # Use UUID default or potentially a hash for stability if needed later\n",
        "                # plan_id=str(uuid.uuid4()), # Let Pydantic handle default\n",
        "                suggested_plan = item.get(\"suggested_plan\", \"Unknown Plan\")\n",
        "                date_due_str = item.get(\"date_due\")\n",
        "\n",
        "                # Basic validation for required fields\n",
        "                if not suggested_plan or suggested_plan.strip() == \"Unknown Plan\":\n",
        "                    state.warnings.append(f\"Extracted care plan with missing or generic description: {item}\")\n",
        "                    continue # Skip adding this plan\n",
        "                if not date_due_str:\n",
        "                     state.warnings.append(f\"Extracted care plan missing date_due: {item}. Attempting to set default.\")\n",
        "                     # Attempt to set a default date_due if missing, e.g., 30 days from note date\n",
        "                     try:\n",
        "                         note_date_obj = datetime.datetime.strptime(state.note_date, \"%Y-%m-%d\").date()\n",
        "                         default_due_date = note_date_obj + datetime.timedelta(days=30)\n",
        "                         date_due_str = default_due_date.strftime(\"%Y-%m-%d\")\n",
        "                         state.warnings.append(f\"Set default date_due: {date_due_str} for plan: {suggested_plan}\")\n",
        "                     except ValueError:\n",
        "                          state.errors.append(f\"Could not parse note_date {state.note_date} to set default date_due for plan: {suggested_plan}\")\n",
        "                          continue # Skip if note_date is invalid\n",
        "\n",
        "                # Use PriorityClassifier for urgency_level based on plan description and note context\n",
        "                # Also consider patient status from treatment tracker if available\n",
        "                patient_status_for_urgency = state.treatment_tracker.patient_status if state.treatment_tracker else \"unknown\"\n",
        "                urgency_level = PriorityClassifier.classify_plan_urgency(\n",
        "                     plan_description=suggested_plan,\n",
        "                     patient_status=patient_status_for_urgency,\n",
        "                     critical_finding=item.get(\"critical_finding\", False) # Use extracted critical_finding\n",
        "                )\n",
        "\n",
        "                care_plan = CarePlan(\n",
        "                    suggested_plan=suggested_plan,\n",
        "                    mrn=state.patient_mrn,\n",
        "                    urgency_level=urgency_level, # Set based on classification\n",
        "                    date_due=date_due_str, # Use extracted or default date\n",
        "                    action_type=item.get(\"action_type\", \"follow-up\"), # Default action type\n",
        "                    critical_finding=item.get(\"critical_finding\", False), # Use extracted flag\n",
        "                    estimated_duration=item.get(\"estimated_duration\"),\n",
        "                    note_date=state.note_date,\n",
        "                    note_author=state.note_author,\n",
        "                    # workflow_status and days_overdue will be calculated below\n",
        "                )\n",
        "\n",
        "                # Calculate initial workflow status and days overdue\n",
        "                workflow_status, days_overdue = WorkflowCalculator.calculate_workflow_status(\n",
        "                    date_due=care_plan.date_due,\n",
        "                    current_date=state.note_date # Use note date as current date for initial extraction\n",
        "                )\n",
        "                care_plan.workflow_status = workflow_status\n",
        "                care_plan.days_overdue = days_overdue\n",
        "\n",
        "                newly_extracted_care_plans.append(care_plan)\n",
        "                state.debug_logs.append(f\"Extracted and validated care plan: {care_plan.suggested_plan} (Urgency: {care_plan.urgency_level}, Status: {care_plan.workflow_status})\")\n",
        "\n",
        "            except ValidationError as e:\n",
        "                state.errors.append(f\"Validation error creating CarePlan from extracted data: {item} - {e}\")\n",
        "                logging.error(f\"Validation error: {e}\")\n",
        "            except Exception as e:\n",
        "                 state.errors.append(f\"Unexpected error processing extracted care plan item: {item} - {e}\")\n",
        "                 logging.error(f\"Error processing item: {item}, error: {e}\")\n",
        "\n",
        "\n",
        "        state.extracted_care_plans = newly_extracted_care_plans\n",
        "        state.debug_logs.append(f\"care_plan_extraction_agent: Successfully extracted {len(state.extracted_care_plans)} care plans.\")\n",
        "        logging.info(f\"Successfully extracted {len(state.extracted_care_plans)} care plans.\")\n",
        "\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"care_plan_extraction_agent JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.warnings.append(\"Failed to parse JSON from care plan extraction agent. This might require re-extraction or manual review.\")\n",
        "        logging.error(error_msg)\n",
        "        # Depending on strategy, you might increment a failure counter or retry.\n",
        "        # For now, just log the error and move on with no new plans.\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"care_plan_extraction_agent unexpected error during extraction: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    logging.info(\"care_plan_extraction_agent completed.\")\n",
        "    state.agent_history.append(f\"care_plan_extraction_agent: Finished extraction. Extracted {len(state.extracted_care_plans)} care plans.\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… care_plan_extraction_agent function defined.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… care_plan_extraction_agent function defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "universal node testing\n"
      ],
      "metadata": {
        "id": "_ERGKMzMEBlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Universal LangGraph Node Testing Framework\n",
        "# Works with any LangGraph node regardless of domain or state structure\n",
        "\n",
        "import logging\n",
        "import json\n",
        "import datetime\n",
        "import inspect\n",
        "from typing import Callable, Dict, Any, Optional, Union\n",
        "from copy import deepcopy\n",
        "import sys\n",
        "\n",
        "# =============================================================================\n",
        "# UNIVERSAL LANGGRAPH NODE TESTING FRAMEWORK\n",
        "# =============================================================================\n",
        "\n",
        "def test_node(node_function: Callable,\n",
        "              state: Optional[Any] = None,\n",
        "              state_source: str = \"processed_state\",\n",
        "              display_results: bool = True,\n",
        "              save_backup: bool = True,\n",
        "              analyze_changes: bool = True,\n",
        "              show_pre_state: bool = True,\n",
        "              max_display_items: int = 5) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Universal function to test any LangGraph node with real execution.\n",
        "\n",
        "    Args:\n",
        "        node_function: Any LangGraph node function to test\n",
        "        state: State object to use (if None, tries to find from globals)\n",
        "        state_source: Name of global state variable to use if state is None\n",
        "        display_results: Whether to show detailed output\n",
        "        save_backup: Whether to backup state before testing\n",
        "        analyze_changes: Whether to analyze what changed\n",
        "        show_pre_state: Whether to show state before execution\n",
        "        max_display_items: Max items to display in lists\n",
        "\n",
        "    Returns:\n",
        "        Dict with test results and metrics\n",
        "    \"\"\"\n",
        "\n",
        "    node_name = node_function.__name__\n",
        "\n",
        "    print(f\"ðŸ§ª TESTING LANGGRAPH NODE: {node_name.upper()}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Get state if not provided\n",
        "    if state is None:\n",
        "        state = get_state_from_globals(state_source)\n",
        "        if state is None:\n",
        "            return {\"success\": False, \"error\": f\"Could not find state variable '{state_source}'\"}\n",
        "\n",
        "    # Analyze function signature\n",
        "    signature_info = analyze_function_signature(node_function)\n",
        "    if display_results:\n",
        "        print(f\"ðŸ“‹ Node Info: {signature_info['description']}\")\n",
        "\n",
        "    # Backup current state\n",
        "    backup_data = create_universal_backup(state) if save_backup else {}\n",
        "\n",
        "    # Display pre-test state\n",
        "    if show_pre_state and display_results:\n",
        "        display_universal_pre_state(state, node_name)\n",
        "\n",
        "    # Record execution metrics\n",
        "    start_time = datetime.datetime.now()\n",
        "\n",
        "    try:\n",
        "        print(f\"\\nðŸ”„ EXECUTING {node_name.upper()}...\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Execute the node with appropriate arguments\n",
        "        result_state = execute_node_safely(node_function, state, signature_info)\n",
        "\n",
        "        end_time = datetime.datetime.now()\n",
        "        execution_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "        print(f\"âœ… {node_name} completed successfully in {execution_time:.2f} seconds\")\n",
        "\n",
        "        # Analyze what changed\n",
        "        changes = analyze_universal_changes(result_state, backup_data) if analyze_changes else {}\n",
        "\n",
        "        # Create results summary\n",
        "        results = {\n",
        "            \"success\": True,\n",
        "            \"node_name\": node_name,\n",
        "            \"execution_time\": execution_time,\n",
        "            \"timestamp\": datetime.datetime.now().isoformat(),\n",
        "            \"changes\": changes,\n",
        "            \"signature_info\": signature_info\n",
        "        }\n",
        "\n",
        "        if display_results:\n",
        "            display_universal_results(result_state, backup_data, changes, node_name, max_display_items)\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        end_time = datetime.datetime.now()\n",
        "        execution_time = (end_time - start_time).total_seconds()\n",
        "\n",
        "        print(f\"âŒ {node_name} failed after {execution_time:.2f} seconds\")\n",
        "        print(f\"   Error: {e}\")\n",
        "        print(f\"   Error Type: {type(e).__name__}\")\n",
        "\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": str(e),\n",
        "            \"error_type\": type(e).__name__,\n",
        "            \"execution_time\": execution_time,\n",
        "            \"node_name\": node_name,\n",
        "            \"backup_data\": backup_data\n",
        "        }\n",
        "\n",
        "# =============================================================================\n",
        "# UNIVERSAL HELPER FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def get_state_from_globals(state_var_name: str) -> Any:\n",
        "    \"\"\"Try to get state from global variables.\"\"\"\n",
        "    try:\n",
        "        # Check in current frame globals\n",
        "        frame = sys._getframe(1)\n",
        "        if state_var_name in frame.f_globals:\n",
        "            return frame.f_globals[state_var_name]\n",
        "\n",
        "        # Check common global names\n",
        "        common_names = [state_var_name, 'state', 'current_state', 'processed_state', 'app_state']\n",
        "        for name in common_names:\n",
        "            if name in frame.f_globals:\n",
        "                print(f\"ðŸ’¡ Using state from global variable: {name}\")\n",
        "                return frame.f_globals[name]\n",
        "\n",
        "        return None\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def analyze_function_signature(func: Callable) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze the function signature to understand how to call it.\"\"\"\n",
        "    try:\n",
        "        sig = inspect.signature(func)\n",
        "        params = list(sig.parameters.keys())\n",
        "\n",
        "        # Determine calling pattern\n",
        "        if len(params) == 1:\n",
        "            call_pattern = \"single_arg\"\n",
        "            description = f\"Single argument function: {func.__name__}({params[0]})\"\n",
        "        elif len(params) == 2:\n",
        "            call_pattern = \"two_args\"\n",
        "            description = f\"Two argument function: {func.__name__}({', '.join(params)})\"\n",
        "        else:\n",
        "            call_pattern = \"multi_args\"\n",
        "            description = f\"Multi argument function: {func.__name__}({', '.join(params)})\"\n",
        "\n",
        "        return {\n",
        "            \"parameters\": params,\n",
        "            \"param_count\": len(params),\n",
        "            \"call_pattern\": call_pattern,\n",
        "            \"description\": description,\n",
        "            \"signature\": str(sig)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"parameters\": [],\n",
        "            \"param_count\": 0,\n",
        "            \"call_pattern\": \"unknown\",\n",
        "            \"description\": f\"Could not analyze signature: {e}\",\n",
        "            \"signature\": \"unknown\"\n",
        "        }\n",
        "\n",
        "def execute_node_safely(node_function: Callable, state: Any, signature_info: Dict) -> Any:\n",
        "    \"\"\"Execute the node function with appropriate arguments based on signature.\"\"\"\n",
        "    param_count = signature_info[\"param_count\"]\n",
        "\n",
        "    if param_count == 0:\n",
        "        return node_function()\n",
        "    elif param_count == 1:\n",
        "        return node_function(state)\n",
        "    elif param_count == 2:\n",
        "        # Common LangGraph pattern: node(state, config)\n",
        "        return node_function(state, {})\n",
        "    else:\n",
        "        # Try with just state first\n",
        "        try:\n",
        "            return node_function(state)\n",
        "        except TypeError:\n",
        "            # If that fails, try with state and empty config\n",
        "            return node_function(state, {})\n",
        "\n",
        "def create_universal_backup(state: Any) -> Dict[str, Any]:\n",
        "    \"\"\"Create a universal backup of any state object.\"\"\"\n",
        "    backup = {\n",
        "        \"state_type\": type(state).__name__,\n",
        "        \"timestamp\": datetime.datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Try to get all attributes\n",
        "        if hasattr(state, '__dict__'):\n",
        "            backup[\"attributes\"] = {}\n",
        "            for key, value in state.__dict__.items():\n",
        "                try:\n",
        "                    # Try to backup the value\n",
        "                    if isinstance(value, (list, dict)):\n",
        "                        backup[\"attributes\"][key] = deepcopy(value)\n",
        "                    elif isinstance(value, (str, int, float, bool, type(None))):\n",
        "                        backup[\"attributes\"][key] = value\n",
        "                    else:\n",
        "                        backup[\"attributes\"][key] = str(value)  # Fallback to string representation\n",
        "                except:\n",
        "                    backup[\"attributes\"][key] = f\"<Could not backup {type(value).__name__}>\"\n",
        "\n",
        "        # Try to backup as dict if it's dict-like\n",
        "        elif hasattr(state, 'keys'):\n",
        "            backup[\"dict_content\"] = dict(state)\n",
        "\n",
        "        # Store string representation as fallback\n",
        "        backup[\"string_repr\"] = str(state)\n",
        "\n",
        "    except Exception as e:\n",
        "        backup[\"backup_error\"] = str(e)\n",
        "        backup[\"string_repr\"] = str(state)\n",
        "\n",
        "    return backup\n",
        "\n",
        "def display_universal_pre_state(state: Any, node_name: str):\n",
        "    \"\"\"Display current state before testing - works with any state structure.\"\"\"\n",
        "    print(f\"\\nCURRENT STATE (before {node_name}):\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    state_type = type(state).__name__\n",
        "    print(f\"State Type: {state_type}\")\n",
        "\n",
        "    # Try to show basic info about the state\n",
        "    try:\n",
        "        if hasattr(state, '__dict__'):\n",
        "            attrs = state.__dict__\n",
        "            print(f\"Attributes: {len(attrs)}\")\n",
        "\n",
        "            # Show key attributes\n",
        "            for key, value in list(attrs.items())[:10]:  # Show first 10 attributes\n",
        "                if isinstance(value, (list, tuple)):\n",
        "                    print(f\"  {key}: {type(value).__name__} ({len(value)} items)\")\n",
        "                elif isinstance(value, dict):\n",
        "                    print(f\"  {key}: dict ({len(value)} keys)\")\n",
        "                elif isinstance(value, str) and len(value) > 50:\n",
        "                    print(f\"  {key}: '{value[:50]}...'\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            if len(attrs) > 10:\n",
        "                print(f\"  ... and {len(attrs) - 10} more attributes\")\n",
        "\n",
        "        elif hasattr(state, 'keys'):\n",
        "            print(f\"Dict-like object with {len(state)} keys\")\n",
        "            for key in list(state.keys())[:5]:\n",
        "                print(f\"  {key}: {type(state[key]).__name__}\")\n",
        "\n",
        "        else:\n",
        "            print(f\"State value: {str(state)[:200]}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Could not display state details: {e}\")\n",
        "\n",
        "def analyze_universal_changes(new_state: Any, backup_data: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze what changed in the state - works with any state structure.\"\"\"\n",
        "    changes = {\n",
        "        \"analysis_time\": datetime.datetime.now().isoformat(),\n",
        "        \"changes_detected\": False,\n",
        "        \"attribute_changes\": {},\n",
        "        \"new_attributes\": [],\n",
        "        \"modified_attributes\": [],\n",
        "        \"summary\": \"\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        if \"attributes\" in backup_data and hasattr(new_state, '__dict__'):\n",
        "            old_attrs = backup_data[\"attributes\"]\n",
        "            new_attrs = new_state.__dict__\n",
        "\n",
        "            # Check for new attributes\n",
        "            for key in new_attrs:\n",
        "                if key not in old_attrs:\n",
        "                    changes[\"new_attributes\"].append(key)\n",
        "                    changes[\"changes_detected\"] = True\n",
        "\n",
        "            # Check for modified attributes\n",
        "            for key in old_attrs:\n",
        "                if key in new_attrs:\n",
        "                    old_val = old_attrs[key]\n",
        "                    new_val = new_attrs[key]\n",
        "\n",
        "                    # Compare values\n",
        "                    if str(old_val) != str(new_val):\n",
        "                        changes[\"modified_attributes\"].append(key)\n",
        "                        changes[\"changes_detected\"] = True\n",
        "\n",
        "                        # Record specific changes for lists\n",
        "                        if isinstance(old_val, list) and isinstance(new_val, list):\n",
        "                            changes[\"attribute_changes\"][key] = {\n",
        "                                \"type\": \"list\",\n",
        "                                \"old_count\": len(old_val),\n",
        "                                \"new_count\": len(new_val),\n",
        "                                \"items_added\": len(new_val) - len(old_val)\n",
        "                            }\n",
        "                        else:\n",
        "                            changes[\"attribute_changes\"][key] = {\n",
        "                                \"type\": \"value\",\n",
        "                                \"old\": str(old_val)[:100],\n",
        "                                \"new\": str(new_val)[:100]\n",
        "                            }\n",
        "\n",
        "        # Create summary\n",
        "        total_changes = len(changes[\"new_attributes\"]) + len(changes[\"modified_attributes\"])\n",
        "        if total_changes > 0:\n",
        "            changes[\"summary\"] = f\"{total_changes} attributes changed\"\n",
        "        else:\n",
        "            changes[\"summary\"] = \"No changes detected\"\n",
        "\n",
        "    except Exception as e:\n",
        "        changes[\"analysis_error\"] = str(e)\n",
        "        changes[\"summary\"] = f\"Could not analyze changes: {e}\"\n",
        "\n",
        "    return changes\n",
        "\n",
        "def display_universal_results(new_state: Any, backup_data: Dict, changes: Dict, node_name: str, max_items: int = 5):\n",
        "    \"\"\"Display results in a universal format.\"\"\"\n",
        "    print(f\"\\nðŸ“Š EXECUTION RESULTS:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    # Show change summary\n",
        "    if changes.get(\"changes_detected\"):\n",
        "        print(f\"âœ… Changes detected: {changes['summary']}\")\n",
        "\n",
        "        if changes[\"new_attributes\"]:\n",
        "            print(f\"\\nðŸ†• New attributes ({len(changes['new_attributes'])}):\")\n",
        "            for attr in changes[\"new_attributes\"][:max_items]:\n",
        "                print(f\"  + {attr}\")\n",
        "            if len(changes[\"new_attributes\"]) > max_items:\n",
        "                print(f\"  ... and {len(changes['new_attributes']) - max_items} more\")\n",
        "\n",
        "        if changes[\"modified_attributes\"]:\n",
        "            print(f\"\\nðŸ”„ Modified attributes ({len(changes['modified_attributes'])}):\")\n",
        "            for attr in changes[\"modified_attributes\"][:max_items]:\n",
        "                if attr in changes[\"attribute_changes\"]:\n",
        "                    change_info = changes[\"attribute_changes\"][attr]\n",
        "                    if change_info[\"type\"] == \"list\":\n",
        "                        print(f\"  ~ {attr}: {change_info['old_count']} â†’ {change_info['new_count']} items\")\n",
        "                    else:\n",
        "                        print(f\"  ~ {attr}: value changed\")\n",
        "                else:\n",
        "                    print(f\"  ~ {attr}\")\n",
        "            if len(changes[\"modified_attributes\"]) > max_items:\n",
        "                print(f\"  ... and {len(changes['modified_attributes']) - max_items} more\")\n",
        "    else:\n",
        "        print(\"â„¹ï¸ No changes detected in state\")\n",
        "\n",
        "    # Show current state summary\n",
        "    print(f\"\\nðŸ“‹ FINAL STATE:\")\n",
        "    print(\"-\" * 20)\n",
        "    try:\n",
        "        if hasattr(new_state, '__dict__'):\n",
        "            attrs = new_state.__dict__\n",
        "            print(f\"Total attributes: {len(attrs)}\")\n",
        "\n",
        "            # Show some current values\n",
        "            for key, value in list(attrs.items())[:max_items]:\n",
        "                if isinstance(value, (list, tuple)):\n",
        "                    print(f\"  {key}: {len(value)} items\")\n",
        "                elif isinstance(value, dict):\n",
        "                    print(f\"  {key}: {len(value)} keys\")\n",
        "                elif isinstance(value, str) and len(value) > 50:\n",
        "                    print(f\"  {key}: {len(value)} chars\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "        else:\n",
        "            print(f\"State: {str(new_state)[:200]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not display final state: {e}\")\n",
        "\n",
        "# =============================================================================\n",
        "# QUICK TEST UTILITIES\n",
        "# =============================================================================\n",
        "\n",
        "def quick_test(node_function: Callable, **kwargs) -> Dict[str, Any]:\n",
        "    \"\"\"Quick test with minimal output.\"\"\"\n",
        "    return test_node(node_function, display_results=False, **kwargs)\n",
        "\n",
        "def verbose_test(node_function: Callable, **kwargs) -> Dict[str, Any]:\n",
        "    \"\"\"Verbose test with maximum output.\"\"\"\n",
        "    return test_node(node_function,\n",
        "                    display_results=True,\n",
        "                    save_backup=True,\n",
        "                    analyze_changes=True,\n",
        "                    show_pre_state=True,\n",
        "                    **kwargs)\n",
        "\n",
        "def batch_test_nodes(node_functions: list, **kwargs) -> Dict[str, Dict]:\n",
        "    \"\"\"Test multiple nodes in sequence.\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    print(f\"ðŸ§ª BATCH TESTING {len(node_functions)} NODES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, node_func in enumerate(node_functions, 1):\n",
        "        print(f\"\\nðŸ“ Test {i}/{len(node_functions)}\")\n",
        "        results[node_func.__name__] = test_node(node_func, **kwargs)\n",
        "\n",
        "        if not results[node_func.__name__][\"success\"]:\n",
        "            print(f\"âŒ Stopping batch test due to failure in {node_func.__name__}\")\n",
        "            break\n",
        "\n",
        "    return results\n",
        "\n",
        "def compare_node_performance(node_function: Callable, iterations: int = 3) -> Dict[str, Any]:\n",
        "    \"\"\"Run multiple iterations to compare performance.\"\"\"\n",
        "    print(f\"â±ï¸ PERFORMANCE TEST: {node_function.__name__} ({iterations} iterations)\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    times = []\n",
        "    successes = 0\n",
        "\n",
        "    for i in range(iterations):\n",
        "        print(f\"Run {i+1}/{iterations}...\")\n",
        "        result = quick_test(node_function)\n",
        "\n",
        "        if result[\"success\"]:\n",
        "            times.append(result[\"execution_time\"])\n",
        "            successes += 1\n",
        "        else:\n",
        "            print(f\"âŒ Run {i+1} failed: {result['error']}\")\n",
        "\n",
        "    if times:\n",
        "        avg_time = sum(times) / len(times)\n",
        "        min_time = min(times)\n",
        "        max_time = max(times)\n",
        "\n",
        "        print(f\"\\nðŸ“Š Performance Summary:\")\n",
        "        print(f\"  Successful runs: {successes}/{iterations}\")\n",
        "        print(f\"  Average time: {avg_time:.3f}s\")\n",
        "        print(f\"  Min time: {min_time:.3f}s\")\n",
        "        print(f\"  Max time: {max_time:.3f}s\")\n",
        "\n",
        "        return {\n",
        "            \"success_rate\": successes / iterations,\n",
        "            \"avg_time\": avg_time,\n",
        "            \"min_time\": min_time,\n",
        "            \"max_time\": max_time,\n",
        "            \"all_times\": times\n",
        "        }\n",
        "    else:\n",
        "        print(\"âŒ All runs failed\")\n",
        "        return {\"success_rate\": 0, \"error\": \"All iterations failed\"}\n",
        "\n",
        "# =============================================================================\n",
        "# USAGE EXAMPLES AND HELP\n",
        "# =============================================================================\n",
        "\n",
        "def show_universal_usage():\n",
        "    \"\"\"Show how to use the universal testing framework.\"\"\"\n",
        "    print(\"\"\"\n",
        "ðŸ§ª UNIVERSAL LANGGRAPH NODE TESTING FRAMEWORK\n",
        "\n",
        "# Basic usage - test any node:\n",
        "test_node(your_node_function)\n",
        "\n",
        "# Test with custom state:\n",
        "test_node(your_node_function, state=custom_state)\n",
        "\n",
        "# Test with options:\n",
        "test_node(your_node_function,\n",
        "          display_results=True,      # Show detailed output\n",
        "          save_backup=True,          # Backup state before test\n",
        "          analyze_changes=True,      # Analyze what changed\n",
        "          show_pre_state=True)       # Show state before execution\n",
        "\n",
        "# Quick test (minimal output):\n",
        "quick_test(your_node_function)\n",
        "\n",
        "# Verbose test (maximum output):\n",
        "verbose_test(your_node_function)\n",
        "\n",
        "# Test multiple nodes:\n",
        "batch_test_nodes([node1, node2, node3])\n",
        "\n",
        "# Performance testing:\n",
        "compare_node_performance(your_node_function, iterations=5)\n",
        "\n",
        "# Use different state source:\n",
        "test_node(your_node_function, state_source=\"my_state_variable\")\n",
        "\"\"\")\n",
        "\n",
        "print(\"âœ… Universal LangGraph Node Testing Framework loaded!\")\n",
        "print(\"ðŸ”§ Works with ANY LangGraph node regardless of domain or state structure\")\n",
        "print(\"ðŸ“š Run show_universal_usage() to see examples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HaiLIOJEGfL",
        "outputId": "05a81f86-dc20-4c1c-8c08-e13649ef3418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Universal LangGraph Node Testing Framework loaded!\n",
            "ðŸ”§ Works with ANY LangGraph node regardless of domain or state structure\n",
            "ðŸ“š Run show_universal_usage() to see examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_node(care_plan_extraction_agent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kECaks17EY1-",
        "outputId": "fb34f7c4-697e-440e-bb62-66592a8178f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª TESTING LANGGRAPH NODE: CARE_PLAN_EXTRACTION_AGENT\n",
            "============================================================\n",
            "ðŸ“‹ Node Info: Single argument function: care_plan_extraction_agent(state)\n",
            "\n",
            "CURRENT STATE (before care_plan_extraction_agent):\n",
            "------------------------------\n",
            "State Type: MedicalAgentState\n",
            "Attributes: 39\n",
            "  clinical_note: '\n",
            "Patient: Jane Smith\n",
            "MRN: ONC12345  \n",
            "Date: 2024-01...'\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: list (2 items)\n",
            "  previous_care_plans: list (3 items)\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2025-09-09' notes='Patient started treatment on schedule, responding well'\n",
            "  extracted_problems: list (3 items)\n",
            "  extracted_care_plans: list (5 items)\n",
            "  final_problems: list (0 items)\n",
            "  ... and 29 more attributes\n",
            "\n",
            "ðŸ”„ EXECUTING CARE_PLAN_EXTRACTION_AGENT...\n",
            "--------------------------------------------------\n",
            "âœ… care_plan_extraction_agent completed successfully in 7.37 seconds\n",
            "\n",
            "ðŸ“Š EXECUTION RESULTS:\n",
            "------------------------------\n",
            "âœ… Changes detected: 4 attributes changed\n",
            "\n",
            "ðŸ”„ Modified attributes (4):\n",
            "  ~ extracted_care_plans: 5 â†’ 5 items\n",
            "  ~ extraction_attempts: value changed\n",
            "  ~ debug_logs: 17 â†’ 23 items\n",
            "  ~ agent_history: 6 â†’ 8 items\n",
            "\n",
            "ðŸ“‹ FINAL STATE:\n",
            "--------------------\n",
            "Total attributes: 39\n",
            "  clinical_note: 1544 chars\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: 2 items\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'node_name': 'care_plan_extraction_agent',\n",
              " 'execution_time': 7.373978,\n",
              " 'timestamp': '2025-09-09T20:01:31.610379',\n",
              " 'changes': {'analysis_time': '2025-09-09T20:01:31.609781',\n",
              "  'changes_detected': True,\n",
              "  'attribute_changes': {'extracted_care_plans': {'type': 'list',\n",
              "    'old_count': 5,\n",
              "    'new_count': 5,\n",
              "    'items_added': 0},\n",
              "   'extraction_attempts': {'type': 'value', 'old': '2', 'new': '3'},\n",
              "   'debug_logs': {'type': 'list',\n",
              "    'old_count': 17,\n",
              "    'new_count': 23,\n",
              "    'items_added': 6},\n",
              "   'agent_history': {'type': 'list',\n",
              "    'old_count': 6,\n",
              "    'new_count': 8,\n",
              "    'items_added': 2}},\n",
              "  'new_attributes': [],\n",
              "  'modified_attributes': ['extracted_care_plans',\n",
              "   'extraction_attempts',\n",
              "   'debug_logs',\n",
              "   'agent_history'],\n",
              "  'summary': '4 attributes changed'},\n",
              " 'signature_info': {'parameters': ['state'],\n",
              "  'param_count': 1,\n",
              "  'call_pattern': 'single_arg',\n",
              "  'description': 'Single argument function: care_plan_extraction_agent(state)',\n",
              "  'signature': '(state: __main__.MedicalAgentState) -> __main__.MedicalAgentState'}}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acb56a8",
        "outputId": "d79b4405-a80c-4b79-a6af-0e05af823fa0"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, PatientTreatmentTracker, CarePlan are defined previously\n",
        "\n",
        "def treatment_timeline_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that manages the oncology treatment timeline based on clinical notes.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with treatment timeline information.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing treatment_timeline_agent...\")\n",
        "    state.agent_history.append(\"treatment_timeline_agent: Managing oncology timeline.\")\n",
        "    state.current_agent = \"treatment_timeline_agent\"\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # Ensure a treatment tracker exists, create if necessary\n",
        "    if not state.treatment_tracker:\n",
        "        # If no tracker, assume this is the first oncology note for a new patient\n",
        "        # Set target treatment date 1 month from the current note date\n",
        "        try:\n",
        "            note_date_obj = datetime.datetime.strptime(state.note_date, \"%Y-%m-%d\").date()\n",
        "            target_treatment_date = (note_date_obj + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            state.treatment_tracker = PatientTreatmentTracker(\n",
        "                patient_mrn=state.patient_mrn,\n",
        "                date_first_visit=state.note_date, # Assume note date is first visit if no tracker\n",
        "                date_should_start_treatment=target_treatment_date,\n",
        "                patient_status=\"new\" # Assume new patient if no tracker\n",
        "            )\n",
        "            state.debug_logs.append(\"treatment_timeline_agent: Created new PatientTreatmentTracker.\")\n",
        "            logging.info(\"Created new PatientTreatmentTracker.\")\n",
        "\n",
        "        except ValueError:\n",
        "            error_msg = f\"treatment_timeline_agent: Could not parse note_date {state.note_date} to create treatment tracker.\"\n",
        "            state.errors.append(error_msg)\n",
        "            logging.error(error_msg)\n",
        "            state.current_agent = None\n",
        "            state.agent_history.append(\"treatment_timeline_agent: Failed to create tracker due to date error.\")\n",
        "            return state # Cannot proceed without a valid date\n",
        "\n",
        "    # Define the extraction prompt for timeline updates\n",
        "    timeline_extraction_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a medical AI assistant focused on extracting and updating oncology treatment timelines from clinical notes.\n",
        "         Your task is to analyze the provided clinical note and the current treatment tracker state to identify updates to key timeline milestones.\n",
        "         Extract specific dates and relevant boolean flags if they are explicitly mentioned or strongly implied in the note.\n",
        "         Focus on information regarding:\n",
        "         - Biopsy planning/completion dates\n",
        "         - Pathology report dates (especially the first KHCC report)\n",
        "         - Radiology report dates (first report, full evaluation completion)\n",
        "         - Proposed cancer staging\n",
        "         - Whether pathology needs to be repeated\n",
        "         - Type of first therapy planned or started\n",
        "         - Actual date the first therapy was started\n",
        "         - Any notes or comments specifically about the treatment timeline or potential delays.\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the extracted/updated information as a JSON object. Only include fields for which you found relevant, *specific* updates in the clinical note. Do not include fields if the note does not provide new information for them.\n",
        "         If no updates are found, return an empty JSON object {{}}.\n",
        "         The JSON object MUST conform to the following structure, but only include keys with updates:\n",
        "         {{\n",
        "           \"date_biopsy_planned\": \"string (YYYY-MM-DD, if mentioned)\",\n",
        "           \"date_first_pathology_report\": \"string (YYYY-MM-DD, if mentioned)\",\n",
        "           \"pathology_needs_repeat\": \"boolean (True or False, if explicitly stated)\",\n",
        "           \"date_first_radiology_report\": \"string (YYYY-MM-DD, if mentioned)\",\n",
        "           \"date_full_radiology_evaluation\": \"string (YYYY-MM-DD, if mentioned)\",\n",
        "           \"proposed_stage\": \"string (e.g., 'Stage II', 'T2N1M0', if mentioned)\",\n",
        "           \"first_therapy_type\": \"string (['chemotherapy'|'radiotherapy'|'surgery'|'other'], if therapy type is planned/mentioned)\",\n",
        "           \"date_first_therapy_started\": \"string (YYYY-MM-DD, if treatment start date is mentioned)\",\n",
        "           \"notes\": \"string (Relevant notes about timeline/delays, if mentioned)\"\n",
        "         }}\n",
        "         Ensure the JSON is valid and contains ONLY the JSON object. Do not include any introductory or concluding text outside the JSON.\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Analyze the following clinical note and current treatment tracker to extract timeline updates for patient MRN: {mrn}.\n",
        "         Clinical Note: {clinical_note}\n",
        "         Current Treatment Tracker State (for context, only update fields found in note):\n",
        "         {current_tracker_state}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = timeline_extraction_prompt | llm\n",
        "\n",
        "    try:\n",
        "        # Provide current tracker state for LLM context\n",
        "        current_tracker_state_str = state.treatment_tracker.model_dump_json(indent=2) if state.treatment_tracker else \"{}\"\n",
        "\n",
        "        # Invoke the LLM\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"clinical_note\": state.clinical_note,\n",
        "            \"current_tracker_state\": current_tracker_state_str\n",
        "        })\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        logging.debug(f\"Raw timeline extraction response: {response.content}\")\n",
        "        extracted_updates_dict = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(extracted_updates_dict, dict):\n",
        "             raise ValueError(\"Expected JSON object for timeline updates, but received a different structure.\")\n",
        "\n",
        "        # Apply updates to the existing treatment tracker\n",
        "        if state.treatment_tracker:\n",
        "            updated_fields = []\n",
        "            for field, value in extracted_updates_dict.items():\n",
        "                 if hasattr(state.treatment_tracker, field):\n",
        "                     # Basic validation (Pydantic validation happens on model update)\n",
        "                     # More robust validation could be added here if needed\n",
        "                     setattr(state.treatment_tracker, field, value)\n",
        "                     updated_fields.append(field)\n",
        "                     state.debug_logs.append(f\"treatment_timeline_agent: Updated tracker field '{field}' to '{value}'.\")\n",
        "                 else:\n",
        "                      state.warnings.append(f\"Extracted unknown field '{field}' for treatment tracker.\")\n",
        "\n",
        "            state.debug_logs.append(f\"treatment_timeline_agent: Applied {len(updated_fields)} updates to treatment tracker.\")\n",
        "            logging.info(f\"Applied {len(updated_fields)} updates to treatment tracker.\")\n",
        "\n",
        "            # Recalculate timeline status after applying updates using the note date as the current date\n",
        "            state.treatment_tracker.update_timeline_status(current_date=state.note_date)\n",
        "            state.debug_logs.append(f\"treatment_timeline_agent: Recalculated timeline status: {state.treatment_tracker.get_timeline_status()}\")\n",
        "\n",
        "            # Check for treatment delay alerts\n",
        "            if state.treatment_tracker.days_remaining_or_delayed > 7 and not state.treatment_tracker.date_first_therapy_started:\n",
        "                 delay_alert = f\"Treatment Delay Alert: Patient {state.patient_mrn} is delayed by {state.treatment_tracker.days_remaining_or_delayed} days from target treatment start date ({state.treatment_tracker.date_should_start_treatment}).\"\n",
        "                 state.workflow_alerts.append(delay_alert)\n",
        "                 state.warnings.append(delay_alert)\n",
        "                 logging.warning(delay_alert)\n",
        "\n",
        "\n",
        "        else:\n",
        "             state.warnings.append(\"treatment_timeline_agent: Treatment tracker was none after initial check, cannot apply updates.\")\n",
        "\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"treatment_timeline_agent JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.warnings.append(\"Failed to parse JSON from timeline extraction agent.\")\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"treatment_timeline_agent unexpected error during extraction/update: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    # Integrate with existing care plans (optional, but good for consistency)\n",
        "    # Check if any extracted or previous care plans are related to treatment initiation\n",
        "    # This could be a separate agent or done here. For simplicity, adding a check here.\n",
        "    treatment_plan_keywords = [\"start treatment\", \"initiate therapy\", \"chemotherapy\", \"radiotherapy\", \"surgery date\"]\n",
        "    for care_plan in state.extracted_care_plans + state.previous_care_plans:\n",
        "         if care_plan.action_type in [\"treatment\", \"procedure\"] or any(keyword in care_plan.suggested_plan.lower() for keyword in treatment_plan_keywords):\n",
        "              # Ensure plan urgency reflects critical delay if tracker shows one\n",
        "              if state.treatment_tracker and state.treatment_tracker.days_remaining_or_delayed > 14 and care_plan.urgency_level != \"urgent\":\n",
        "                   care_plan.urgency_level = \"urgent\" # Elevate urgency\n",
        "                   state.warnings.append(f\"Elevated urgency of care plan '{care_plan.suggested_plan}' due to critical treatment delay.\")\n",
        "                   state.workflow_alerts.append(f\"Care Plan Urgency Elevated: '{care_plan.suggested_plan}' for Patient {state.patient_mrn} marked urgent due to treatment timeline delay.\")\n",
        "\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    logging.info(\"treatment_timeline_agent completed.\")\n",
        "    state.agent_history.append(\"treatment_timeline_agent: Finished timeline management.\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… treatment_timeline_agent function defined.\")\n",
        "test_node(treatment_timeline_agent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… treatment_timeline_agent function defined.\n",
            "ðŸ§ª TESTING LANGGRAPH NODE: TREATMENT_TIMELINE_AGENT\n",
            "============================================================\n",
            "ðŸ“‹ Node Info: Single argument function: treatment_timeline_agent(state)\n",
            "\n",
            "CURRENT STATE (before treatment_timeline_agent):\n",
            "------------------------------\n",
            "State Type: MedicalAgentState\n",
            "Attributes: 39\n",
            "  clinical_note: '\n",
            "Patient: Jane Smith\n",
            "MRN: ONC12345  \n",
            "Date: 2024-01...'\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: list (2 items)\n",
            "  previous_care_plans: list (3 items)\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2025-09-09' notes='Patient started treatment on schedule, responding well'\n",
            "  extracted_problems: list (3 items)\n",
            "  extracted_care_plans: list (5 items)\n",
            "  final_problems: list (0 items)\n",
            "  ... and 29 more attributes\n",
            "\n",
            "ðŸ”„ EXECUTING TREATMENT_TIMELINE_AGENT...\n",
            "--------------------------------------------------\n",
            "âœ… treatment_timeline_agent completed successfully in 2.67 seconds\n",
            "\n",
            "ðŸ“Š EXECUTION RESULTS:\n",
            "------------------------------\n",
            "âœ… Changes detected: 3 attributes changed\n",
            "\n",
            "ðŸ”„ Modified attributes (3):\n",
            "  ~ treatment_tracker: value changed\n",
            "  ~ debug_logs: 23 â†’ 28 items\n",
            "  ~ agent_history: 8 â†’ 10 items\n",
            "\n",
            "ðŸ“‹ FINAL STATE:\n",
            "--------------------\n",
            "Total attributes: 39\n",
            "  clinical_note: 1544 chars\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: 2 items\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'node_name': 'treatment_timeline_agent',\n",
              " 'execution_time': 2.674876,\n",
              " 'timestamp': '2025-09-09T20:04:29.071538',\n",
              " 'changes': {'analysis_time': '2025-09-09T20:04:29.070900',\n",
              "  'changes_detected': True,\n",
              "  'attribute_changes': {'treatment_tracker': {'type': 'value',\n",
              "    'old': \"tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-1\",\n",
              "    'new': \"tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-1\"},\n",
              "   'debug_logs': {'type': 'list',\n",
              "    'old_count': 23,\n",
              "    'new_count': 28,\n",
              "    'items_added': 5},\n",
              "   'agent_history': {'type': 'list',\n",
              "    'old_count': 8,\n",
              "    'new_count': 10,\n",
              "    'items_added': 2}},\n",
              "  'new_attributes': [],\n",
              "  'modified_attributes': ['treatment_tracker', 'debug_logs', 'agent_history'],\n",
              "  'summary': '3 attributes changed'},\n",
              " 'signature_info': {'parameters': ['state'],\n",
              "  'param_count': 1,\n",
              "  'call_pattern': 'single_arg',\n",
              "  'description': 'Single argument function: treatment_timeline_agent(state)',\n",
              "  'signature': '(state: __main__.MedicalAgentState) -> __main__.MedicalAgentState'}}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f445bd9",
        "outputId": "888cebe8-0c8c-42c5-db2e-24c1b955d8dd"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "from difflib import SequenceMatcher # Useful for comparing text snippets\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker are defined previously\n",
        "\n",
        "def medical_validator_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that validates extracted medical data against clinical standards.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with validation results and confidence score.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing medical_validator_agent...\")\n",
        "    state.agent_history.append(\"medical_validator_agent: Validating extracted data.\")\n",
        "    state.current_agent = \"medical_validator_agent\"\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # Prepare data for the LLM prompt\n",
        "    extracted_problems_str = json.dumps([p.model_dump() for p in state.extracted_problems], indent=2)\n",
        "    extracted_care_plans_str = json.dumps([cp.model_dump() for cp in state.extracted_care_plans], indent=2)\n",
        "    treatment_tracker_str = state.treatment_tracker.model_dump_json(indent=2) if state.treatment_tracker else \"{}\"\n",
        "\n",
        "    # Define the validation prompt\n",
        "    validation_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a highly skilled medical AI assistant specialized in validating extracted medical information against clinical standards and consistency rules.\n",
        "         Your task is to review the provided extracted problems, care plans, and treatment timeline information from a clinical note for patient MRN: {mrn}.\n",
        "         Evaluate the extracted data based on the following validation rules and clinical consistency checks:\n",
        "\n",
        "         VALIDATION RULES:\n",
        "         1. Cancer diagnoses (identified by `is_cancer_related=true`) should typically have a `priority_flag` of 'critical' or 'important'. Flag if 'regular'.\n",
        "         2. Problems identified as potential treatment side effects (`is_treatment_related=true`) should be flagged if their `status` is 'Inactive' without clear evidence of resolution.\n",
        "         3. Care plans with `urgency_level='urgent'` should have a `date_due` within the next 48 hours (relative to the note date: {note_date}). Flag if the date_due is further out.\n",
        "         4. Care plans with `urgency_level='non-urgent'` should not have a `date_due` within the next 48 hours. Flag if they do.\n",
        "         5. If a `treatment_tracker` exists and indicates a `days_remaining_or_delayed` greater than 30, trigger an escalation issue.\n",
        "         6. Care plans related to a `critical_finding=true` should have `urgency_level='urgent'` and `plan_urgency` set to 'immediate' or 'same-day'. Flag if not.\n",
        "         7. If the `treatment_tracker`'s `patient_status` is 'declining' or 'critical', the urgency of related care plans (especially treatment/diagnostic) should be escalated to 'urgent' or 'immediate'. Flag plans that aren't.\n",
        "\n",
        "         CROSS-VALIDATION & CONSISTENCY CHECKS:\n",
        "         8. Check if problems flagged as `critical` have corresponding care plans with `urgency_level='urgent'`. Note inconsistencies.\n",
        "         9. Check if care plans related to diagnostic tests (action_type='diagnostic') for suspected cancer align with the `treatment_tracker`'s `date_biopsy_planned` or `date_first_pathology_report`. Note inconsistencies.\n",
        "         10. Check for consistency between problems and care plans (e.g., a treatment plan for a problem that isn't listed). Use problem names and plan descriptions for matching.\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the output as a JSON object with the following keys:\n",
        "         - `is_valid`: boolean (True if no major issues found, False otherwise)\n",
        "         - `issues`: A JSON array of objects, each representing a validation issue. Include:\n",
        "           - `item_id`: string (The ID of the problem or care plan, or 'treatment_tracker' for timeline issues)\n",
        "           - `item_type`: string ('problem', 'care_plan', or 'treatment_tracker')\n",
        "           - `issue_type`: string (e.g., 'priority_mismatch', 'date_urgency_mismatch', 'delay_escalation', 'consistency_check_failed')\n",
        "           - `issue`: string (Description of the issue)\n",
        "           - `suggested_fix`: string (Recommended correction or action)\n",
        "         - `confidence_score`: float (A score from 0.0 to 1.0 indicating confidence in the extracted data's accuracy and completeness based on validation results. Higher is better.)\n",
        "         - `validation_summary`: string (A brief summary of the validation outcome.)\n",
        "\n",
        "         Ensure the JSON is valid and contains ONLY the JSON object. Do not include any introductory or concluding text outside the JSON.\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Validate the following extracted medical information for patient MRN: {mrn} based on the clinical note date {note_date}.\n",
        "         Extracted Problems: {extracted_problems}\n",
        "         Extracted Care Plans: {extracted_care_plans}\n",
        "         Treatment Timeline: {treatment_tracker}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = validation_prompt | llm\n",
        "\n",
        "    validation_results: Dict[str, Any] = {\n",
        "        \"is_valid\": True,\n",
        "        \"issues\": [],\n",
        "        \"confidence_score\": 1.0, # Start with high confidence, reduce based on issues\n",
        "        \"validation_summary\": \"Validation pending.\"\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Invoke the LLM for initial validation\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"note_date\": state.note_date,\n",
        "            \"extracted_problems\": extracted_problems_str,\n",
        "            \"extracted_care_plans\": extracted_care_plans_str,\n",
        "            \"treatment_tracker\": treatment_tracker_str\n",
        "        })\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        logging.debug(f\"Raw validation response: {response.content}\")\n",
        "        llm_validation_output = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(llm_validation_output, dict):\n",
        "             raise ValueError(\"Expected JSON object for validation results, but received a different structure.\")\n",
        "\n",
        "        # Update state with LLM's validation output\n",
        "        validation_results[\"is_valid\"] = llm_validation_output.get(\"is_valid\", False) # Assume invalid if not specified\n",
        "        validation_results[\"issues\"] = llm_validation_output.get(\"issues\", [])\n",
        "        validation_results[\"confidence_score\"] = llm_validation_output.get(\"confidence_score\", 0.0)\n",
        "        validation_results[\"validation_summary\"] = llm_validation_output.get(\"validation_summary\", \"Validation completed.\")\n",
        "\n",
        "        state.debug_logs.append(f\"medical_validator_agent: LLM validation output: {json.dumps(validation_results['issues'])}\")\n",
        "\n",
        "        # =====================================================================\n",
        "        # Automatic Correction Application (Basic Example)\n",
        "        # =====================================================================\n",
        "        corrected_items = 0\n",
        "        for issue in validation_results[\"issues\"]:\n",
        "             try:\n",
        "                 item_id = issue.get(\"item_id\")\n",
        "                 item_type = issue.get(\"item_type\")\n",
        "                 suggested_fix = issue.get(\"suggested_fix\")\n",
        "\n",
        "                 if suggested_fix and item_id:\n",
        "                     logging.debug(f\"Attempting to apply suggested fix for {item_type} {item_id}: {suggested_fix}\")\n",
        "                     # This is a simplified example. A real system would need robust parsing\n",
        "                     # and application of suggested fixes based on issue_type and suggested_fix format.\n",
        "\n",
        "                     if item_type == \"problem\":\n",
        "                         for problem in state.extracted_problems:\n",
        "                             if problem.problem_id == item_id:\n",
        "                                 # Example: Fix priority flag if suggested\n",
        "                                 if \"set priority_flag\" in suggested_fix.lower():\n",
        "                                     try:\n",
        "                                         new_priority = suggested_fix.split(\"=\")[-1].strip().strip('\"').strip(\"'\")\n",
        "                                         if new_priority in [\"critical\", \"important\", \"regular\"]:\n",
        "                                             problem.priority_flag = new_priority\n",
        "                                             state.debug_logs.append(f\"Auto-corrected problem {item_id} priority_flag to {new_priority}.\")\n",
        "                                             corrected_items += 1\n",
        "                                     except Exception as fix_e:\n",
        "                                         state.warnings.append(f\"Failed to auto-correct problem {item_id} priority: {fix_e}\")\n",
        "\n",
        "                     elif item_type == \"care_plan\":\n",
        "                          for care_plan in state.extracted_care_plans:\n",
        "                             if care_plan.plan_id == item_id:\n",
        "                                 # Example: Fix urgency level if suggested\n",
        "                                 if \"set urgency_level\" in suggested_fix.lower():\n",
        "                                     try:\n",
        "                                         new_urgency = suggested_fix.split(\"=\")[-1].strip().strip('\"').strip(\"'\")\n",
        "                                         if new_urgency in [\"urgent\", \"non-urgent\"]:\n",
        "                                             care_plan.urgency_level = new_urgency\n",
        "                                             state.debug_logs.append(f\"Auto-corrected care plan {item_id} urgency_level to {new_urgency}.\")\n",
        "                                             corrected_items += 1\n",
        "                                     except Exception as fix_e:\n",
        "                                         state.warnings.append(f\"Failed to auto-correct care plan {item_id} urgency: {fix_e}\")\n",
        "                                 # Example: Fix workflow status if suggested\n",
        "                                 if \"set workflow_status\" in suggested_fix.lower():\n",
        "                                      try:\n",
        "                                         new_status = suggested_fix.split(\"=\")[-1].strip().strip('\"').strip(\"'\")\n",
        "                                         if new_status in [\"pending\", \"delayed\", \"overdue\", \"in-progress\", \"completed\", \"cancelled\"]:\n",
        "                                              care_plan.workflow_status = new_status\n",
        "                                              state.debug_logs.append(f\"Auto-corrected care plan {item_id} workflow_status to {new_status}.\")\n",
        "                                              corrected_items += 1\n",
        "                                      except Exception as fix_e:\n",
        "                                           state.warnings.append(f\"Failed to auto-correct care plan {item_id} workflow_status: {fix_e}\")\n",
        "\n",
        "\n",
        "                     elif item_type == \"treatment_tracker\" and state.treatment_tracker:\n",
        "                          # Example: Update a field in the treatment tracker if suggested\n",
        "                          if \"update treatment_tracker field\" in suggested_fix.lower():\n",
        "                               try:\n",
        "                                    parts = suggested_fix.split(\":\")\n",
        "                                    if len(parts) > 1:\n",
        "                                         field_value_str = parts[1].strip()\n",
        "                                         # This parsing is highly dependent on LLM output format\n",
        "                                         # Example: \"update treatment_tracker field: date_first_therapy_started = '2024-01-20'\"\n",
        "                                         if \"=\" in field_value_str:\n",
        "                                              field_name, value_str = field_value_str.split(\"=\", 1)\n",
        "                                              field_name = field_name.strip()\n",
        "                                              value = value_str.strip().strip('\"').strip(\"'\")\n",
        "                                              if hasattr(state.treatment_tracker, field_name):\n",
        "                                                   # Attempt type conversion based on model schema\n",
        "                                                   field_type = state.treatment_tracker.model_fields[field_name].annotation\n",
        "                                                   if field_type == bool:\n",
        "                                                        value = value.lower() == 'true'\n",
        "                                                   # Add other type conversions as needed (int, float, etc.)\n",
        "\n",
        "                                                   setattr(state.treatment_tracker, field_name, value)\n",
        "                                                   state.debug_logs.append(f\"Auto-corrected treatment_tracker field '{field_name}' to '{value}'.\")\n",
        "                                                   corrected_items += 1\n",
        "                                                   # Recalculate timeline status if date fields are updated\n",
        "                                                   if 'date_' in field_name or 'days_' in field_name:\n",
        "                                                        state.treatment_tracker.update_timeline_status(current_date=state.note_date)\n",
        "                                                        state.debug_logs.append(\"Recalculated treatment tracker timeline status after auto-correction.\")\n",
        "\n",
        "                               except Exception as fix_e:\n",
        "                                    state.warnings.append(f\"Failed to auto-correct treatment_tracker: {fix_e}\")\n",
        "\n",
        "             except Exception as issue_processing_e:\n",
        "                  state.warnings.append(f\"Error processing validation issue for auto-correction: {issue_processing_e}\")\n",
        "\n",
        "\n",
        "        if corrected_items > 0:\n",
        "             state.debug_logs.append(f\"medical_validator_agent: Successfully applied {corrected_items} automatic corrections.\")\n",
        "\n",
        "\n",
        "        # =====================================================================\n",
        "        # Manual Validation Checks and Escalation Triggers\n",
        "        # =====================================================================\n",
        "        manual_issues = []\n",
        "        escalation_needed = False\n",
        "\n",
        "        # Check Rule 3 & 4: Urgency vs Date_Due\n",
        "        note_date_obj = datetime.datetime.strptime(state.note_date, \"%Y-%m-%d\").date()\n",
        "        for cp in state.extracted_care_plans + state.previous_care_plans:\n",
        "             try:\n",
        "                 due_date_obj = datetime.datetime.strptime(cp.date_due, \"%Y-%m-%d\").date()\n",
        "                 days_until_due = (due_date_obj - note_date_obj).days\n",
        "\n",
        "                 if cp.urgency_level == 'urgent' and days_until_due > 2: # More than 48 hours\n",
        "                     manual_issues.append({\n",
        "                         \"item_id\": cp.plan_id,\n",
        "                         \"item_type\": \"care_plan\",\n",
        "                         \"issue_type\": \"date_urgency_mismatch\",\n",
        "                         \"issue\": f\"Urgent care plan has due date {cp.date_due} which is more than 48 hours from note date {state.note_date}.\",\n",
        "                         \"suggested_fix\": f\"Verify urgency or update date_due. Consider setting urgency_level to 'non-urgent' or date_due closer to {state.note_date} + 2 days.\"\n",
        "                     })\n",
        "                     validation_results[\"is_valid\"] = False # Flag as invalid\n",
        "                     validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.1) # Reduce confidence\n",
        "\n",
        "                 if cp.urgency_level == 'non-urgent' and days_until_due <= 2 and days_until_due >= 0: # Within 48 hours (and not past due)\n",
        "                      manual_issues.append({\n",
        "                         \"item_id\": cp.plan_id,\n",
        "                         \"item_type\": \"care_plan\",\n",
        "                         \"issue_type\": \"date_urgency_mismatch\",\n",
        "                         \"issue\": f\"Non-urgent care plan has due date {cp.date_due} which is within 48 hours of note date {state.note_date}.\",\n",
        "                         \"suggested_fix\": f\"Verify urgency or update date_due. Consider setting urgency_level to 'urgent' or date_due further out.\"\n",
        "                     })\n",
        "                      validation_results[\"is_valid\"] = False # Flag as invalid\n",
        "                      validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.05) # Reduce confidence\n",
        "\n",
        "             except ValueError:\n",
        "                 manual_issues.append({\n",
        "                     \"item_id\": cp.plan_id,\n",
        "                     \"item_type\": \"care_plan\",\n",
        "                     \"issue_type\": \"invalid_date_format\",\n",
        "                     \"issue\": f\"Care plan has invalid date_due format: {cp.date_due}\",\n",
        "                     \"suggested_fix\": \"Correct date_due to YYYY-MM-DD format.\"\n",
        "                 })\n",
        "                 validation_results[\"is_valid\"] = False\n",
        "                 validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.1)\n",
        "\n",
        "\n",
        "        # Check Rule 5: Treatment Delay Escalation\n",
        "        if state.treatment_tracker and state.treatment_tracker.days_remaining_or_delayed > 30 and not state.treatment_tracker.date_first_therapy_started:\n",
        "             manual_issues.append({\n",
        "                 \"item_id\": \"treatment_tracker\",\n",
        "                 \"item_type\": \"treatment_tracker\",\n",
        "                 \"issue_type\": \"critical_delay_escalation\",\n",
        "                 \"issue\": f\"Critical treatment delay detected: {state.treatment_tracker.days_remaining_or_delayed} days past target start date ({state.treatment_tracker.date_should_start_treatment}). Requires escalation.\",\n",
        "                 \"suggested_fix\": \"Escalate to clinical team for urgent review and intervention.\"\n",
        "             })\n",
        "             validation_results[\"is_valid\"] = False # Critical issue\n",
        "             validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.2) # Significant confidence reduction\n",
        "             escalation_needed = True # Trigger escalation flag\n",
        "\n",
        "        # Check Rule 6 & 7: Critical Finding/Patient Status vs Plan Urgency\n",
        "        critical_patient_status = state.treatment_tracker and state.treatment_tracker.patient_status in [\"critical\", \"declining\"]\n",
        "        for cp in state.extracted_care_plans + state.previous_care_plans:\n",
        "             if cp.critical_finding and cp.urgency_level != 'urgent':\n",
        "                  manual_issues.append({\n",
        "                      \"item_id\": cp.plan_id,\n",
        "                      \"item_type\": \"care_plan\",\n",
        "                      \"issue_type\": \"critical_finding_urgency_mismatch\",\n",
        "                      \"issue\": f\"Care plan related to critical finding is not marked as urgent: '{cp.suggested_plan}'.\",\n",
        "                      \"suggested_fix\": \"Set urgency_level to 'urgent' and plan_urgency to 'immediate' or 'same-day'.\"\n",
        "                  })\n",
        "                  validation_results[\"is_valid\"] = False\n",
        "                  validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.1)\n",
        "\n",
        "             if critical_patient_status and cp.action_type in [\"treatment\", \"diagnostic\"] and cp.urgency_level != 'urgent':\n",
        "                   manual_issues.append({\n",
        "                      \"item_id\": cp.plan_id,\n",
        "                      \"item_type\": \"care_plan\",\n",
        "                      \"issue_type\": \"patient_status_urgency_mismatch\",\n",
        "                      \"issue\": f\"Patient status is critical/declining, but treatment/diagnostic plan is not marked as urgent: '{cp.suggested_plan}'.\",\n",
        "                      \"suggested_fix\": \"Set urgency_level to 'urgent' and plan_urgency to 'immediate' or 'same-day'.\"\n",
        "                  })\n",
        "                   validation_results[\"is_valid\"] = False\n",
        "                   validation_results[\"confidence_score\"] = max(0.0, validation_results[\"confidence_score\"] - 0.1)\n",
        "\n",
        "\n",
        "        # Add manual issues to the main issues list\n",
        "        validation_results[\"issues\"].extend(manual_issues)\n",
        "\n",
        "        # Update overall validity based on manual checks\n",
        "        if manual_issues:\n",
        "             validation_results[\"is_valid\"] = False\n",
        "\n",
        "\n",
        "        state.validation_results = validation_results\n",
        "        state.validation_confidence = validation_results[\"confidence_score\"]\n",
        "        state.debug_logs.append(f\"medical_validator_agent: Final validation result - is_valid: {state.validation_results['is_valid']}, Confidence: {state.validation_confidence}\")\n",
        "        logging.info(f\"Validation completed. Is Valid: {state.validation_results['is_valid']}, Confidence: {state.validation_confidence}\")\n",
        "\n",
        "\n",
        "        # Trigger priority/workflow alerts based on validation issues\n",
        "        for issue in validation_results[\"issues\"]:\n",
        "             if issue[\"issue_type\"] in [\"critical_delay_escalation\", \"critical_finding_urgency_mismatch\", \"patient_status_urgency_mismatch\"]:\n",
        "                  state.priority_alerts.append(f\"Validation Alert: {issue['issue']}\")\n",
        "             elif issue[\"issue_type\"] in [\"date_urgency_mismatch\", \"invalid_date_format\"]:\n",
        "                  state.workflow_alerts.append(f\"Validation Warning: {issue['issue']}\")\n",
        "\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"medical_validator_agent JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.validation_results[\"validation_summary\"] = \"Validation failed due to JSON parsing error.\"\n",
        "        state.validation_confidence = 0.0 # Zero confidence on parsing failure\n",
        "        validation_results[\"is_valid\"] = False\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"medical_validator_agent unexpected error during validation: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.validation_results[\"validation_summary\"] = \"Validation failed due to unexpected error.\"\n",
        "        state.validation_confidence = 0.0 # Zero confidence on error\n",
        "        validation_results[\"is_valid\"] = False\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    logging.info(\"medical_validator_agent completed.\")\n",
        "    state.agent_history.append(f\"medical_validator_agent: Finished validation. Is Valid: {state.validation_results.get('is_valid', 'N/A')}\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… medical_validator_agent function defined.\")\n",
        "test_node(medical_validator_agent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… medical_validator_agent function defined.\n",
            "ðŸ§ª TESTING LANGGRAPH NODE: MEDICAL_VALIDATOR_AGENT\n",
            "============================================================\n",
            "ðŸ“‹ Node Info: Single argument function: medical_validator_agent(state)\n",
            "\n",
            "CURRENT STATE (before medical_validator_agent):\n",
            "------------------------------\n",
            "State Type: MedicalAgentState\n",
            "Attributes: 39\n",
            "  clinical_note: '\n",
            "Patient: Jane Smith\n",
            "MRN: ONC12345  \n",
            "Date: 2024-01...'\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: list (2 items)\n",
            "  previous_care_plans: list (3 items)\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2024-01-15' notes='Patient reports significant worsening of fatigue over the past week, affecting daily activities. Cycle 5 scheduled for next week.'\n",
            "  extracted_problems: list (3 items)\n",
            "  extracted_care_plans: list (5 items)\n",
            "  final_problems: list (0 items)\n",
            "  ... and 29 more attributes\n",
            "\n",
            "ðŸ”„ EXECUTING MEDICAL_VALIDATOR_AGENT...\n",
            "--------------------------------------------------\n",
            "âœ… medical_validator_agent completed successfully in 14.35 seconds\n",
            "\n",
            "ðŸ“Š EXECUTION RESULTS:\n",
            "------------------------------\n",
            "âœ… Changes detected: 5 attributes changed\n",
            "\n",
            "ðŸ”„ Modified attributes (5):\n",
            "  ~ validation_results: value changed\n",
            "  ~ workflow_alerts: 0 â†’ 4 items\n",
            "  ~ validation_confidence: value changed\n",
            "  ~ debug_logs: 28 â†’ 30 items\n",
            "  ~ agent_history: 10 â†’ 12 items\n",
            "\n",
            "ðŸ“‹ FINAL STATE:\n",
            "--------------------\n",
            "Total attributes: 39\n",
            "  clinical_note: 1544 chars\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: 2 items\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'node_name': 'medical_validator_agent',\n",
              " 'execution_time': 14.3477,\n",
              " 'timestamp': '2025-09-09T20:07:21.951368',\n",
              " 'changes': {'analysis_time': '2025-09-09T20:07:21.950583',\n",
              "  'changes_detected': True,\n",
              "  'attribute_changes': {'validation_results': {'type': 'value',\n",
              "    'old': 'None',\n",
              "    'new': \"{'is_valid': False, 'issues': [{'item_id': '5fb6987f-1a05-47bf-b685-6f08ac623fdf', 'item_type': 'pro\"},\n",
              "   'workflow_alerts': {'type': 'list',\n",
              "    'old_count': 0,\n",
              "    'new_count': 4,\n",
              "    'items_added': 4},\n",
              "   'validation_confidence': {'type': 'value', 'old': '0.0', 'new': '0.5'},\n",
              "   'debug_logs': {'type': 'list',\n",
              "    'old_count': 28,\n",
              "    'new_count': 30,\n",
              "    'items_added': 2},\n",
              "   'agent_history': {'type': 'list',\n",
              "    'old_count': 10,\n",
              "    'new_count': 12,\n",
              "    'items_added': 2}},\n",
              "  'new_attributes': [],\n",
              "  'modified_attributes': ['validation_results',\n",
              "   'workflow_alerts',\n",
              "   'validation_confidence',\n",
              "   'debug_logs',\n",
              "   'agent_history'],\n",
              "  'summary': '5 attributes changed'},\n",
              " 'signature_info': {'parameters': ['state'],\n",
              "  'param_count': 1,\n",
              "  'call_pattern': 'single_arg',\n",
              "  'description': 'Single argument function: medical_validator_agent(state)',\n",
              "  'signature': '(state: __main__.MedicalAgentState) -> __main__.MedicalAgentState'}}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "718f8dcd",
        "outputId": "8e5efe31-9b74-462f-aa95-eceec23ac150"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "from difflib import SequenceMatcher # Useful for comparing text snippets\n",
        "import re # For basic string cleaning\n",
        "\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, MedicalProblem, PriorityClassifier, PatientTreatmentTracker are defined previously\n",
        "\n",
        "# Placeholder for a more sophisticated medical concept normalizer (e.g., using UMLS, medical ontologies)\n",
        "class MedicalConceptNormalizer:\n",
        "    \"\"\"\n",
        "    Placeholder for normalizing medical concepts and finding synonyms.\n",
        "    In a real application, this would interface with a medical terminology service.\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def normalize(concept: str) -> str:\n",
        "        \"\"\"Basic cleaning and lowercasing.\"\"\"\n",
        "        return re.sub(r'[^a-z0-9\\s]', '', concept.lower()).strip()\n",
        "\n",
        "    @staticmethod\n",
        "    def are_synonyms(concept1: str, concept2: str) -> bool:\n",
        "        \"\"\"Basic check for exact match after normalization.\"\"\"\n",
        "        # In a real system, this would use a medical thesaurus/ontology\n",
        "        return MedicalConceptNormalizer.normalize(concept1) == MedicalConceptNormalizer.normalize(concept2)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_normalized_name(problem: MedicalProblem) -> str:\n",
        "         \"\"\"Get normalized name for a problem.\"\"\"\n",
        "         return MedicalConceptNormalizer.normalize(problem.problem_name)\n",
        "\n",
        "\n",
        "def problem_analyzer_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that analyzes and merges extracted medical problems with existing problems.\n",
        "\n",
        "    Handles duplicate detection, synonym matching, priority consolidation, and status merging.\n",
        "    Uses LLM for complex merging scenarios.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with the final merged list of problems.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing problem_analyzer_agent...\")\n",
        "    state.agent_history.append(\"problem_analyzer_agent: Analyzing and merging medical problems.\")\n",
        "    state.current_agent = \"problem_analyzer_agent\"\n",
        "\n",
        "    # Combine previous and newly extracted problems for merging\n",
        "    all_problems = state.previous_problems + state.extracted_problems\n",
        "    final_problems: List[MedicalProblem] = []\n",
        "    merge_actions = []\n",
        "    conflicts_resolved = []\n",
        "    changes_made = False\n",
        "\n",
        "    # =====================================================================\n",
        "    # Simple Merging Logic (for smaller lists or as a first pass)\n",
        "    # =====================================================================\n",
        "    if len(all_problems) <= 15: # Use simple logic for smaller lists\n",
        "        logging.info(f\"Using simple merging logic for {len(all_problems)} problems.\")\n",
        "        processed_indices = set()\n",
        "\n",
        "        for i in range(len(all_problems)):\n",
        "            if i in processed_indices:\n",
        "                continue\n",
        "\n",
        "            current_problem = all_problems[i]\n",
        "            matching_problems = [current_problem]\n",
        "            processed_indices.add(i)\n",
        "\n",
        "            for j in range(i + 1, len(all_problems)):\n",
        "                if j in processed_indices:\n",
        "                    continue\n",
        "\n",
        "                compare_problem = all_problems[j]\n",
        "\n",
        "                # Check for similarity using SequenceMatcher and normalized names\n",
        "                name_similarity = SequenceMatcher(None, MedicalConceptNormalizer.get_normalized_name(current_problem), MedicalConceptNormalizer.get_normalized_name(compare_problem)).ratio()\n",
        "\n",
        "                # Check for synonymy (basic check)\n",
        "                is_synonym = MedicalConceptNormalizer.are_synonyms(current_problem.problem_name, compare_problem.problem_name)\n",
        "\n",
        "\n",
        "                # Consider problems to be duplicates/related if names are very similar OR they are synonyms\n",
        "                if name_similarity >= 0.8 or is_synonym:\n",
        "                    # Add to matching problems and mark as processed\n",
        "                    matching_problems.append(compare_problem)\n",
        "                    processed_indices.add(j)\n",
        "                    state.debug_logs.append(f\"Simple Merge: Found potential match between '{current_problem.problem_name}' and '{compare_problem.problem_name}' (Similarity: {name_similarity:.2f}, Synonym: {is_synonym}).\")\n",
        "\n",
        "\n",
        "            # Merge matching problems into a single representative problem\n",
        "            if len(matching_problems) > 1:\n",
        "                changes_made = True\n",
        "                # Create a merged problem - prioritize information from the latest note if available\n",
        "                # Simple merge strategy: keep the problem from the latest note or the first one\n",
        "                representative_problem = matching_problems[0] # Start with the first one\n",
        "                merge_source_notes = [p.note_source for p in matching_problems if p.note_source]\n",
        "                merge_evidence = [p.evidence for p in matching_problems if p.evidence]\n",
        "                merge_details = [p.additional_details for p in matching_problems if p.additional_details]\n",
        "                merge_significance = [p.clinical_significance for p in matching_problems if p.clinical_significance]\n",
        "\n",
        "                # Consolidate fields\n",
        "                representative_problem.evidence = \"|\".join(filter(None, merge_evidence))\n",
        "                representative_problem.additional_details = \"|\".join(filter(None, merge_details))\n",
        "                representative_problem.clinical_significance = \"|\".join(filter(None, merge_significance))\n",
        "                representative_problem.note_source = \"|\".join(filter(None, merge_source_notes))\n",
        "\n",
        "                # Priority consolidation: keep the highest priority\n",
        "                priorities = [p.priority_flag for p in matching_problems]\n",
        "                if \"critical\" in priorities:\n",
        "                    representative_problem.priority_flag = \"critical\"\n",
        "                elif \"important\" in priorities:\n",
        "                    representative_problem.priority_flag = \"important\"\n",
        "                # If neither, it remains 'regular' (default)\n",
        "\n",
        "                # Status merging: Active takes precedence\n",
        "                statuses = [p.status for p in matching_problems]\n",
        "                if \"Active\" in statuses:\n",
        "                    representative_problem.status = \"Active\"\n",
        "                else:\n",
        "                    representative_problem.status = \"Inactive\" # If all are inactive\n",
        "\n",
        "                # Boolean flags: OR logic (True if any is True)\n",
        "                representative_problem.is_cancer_related = any(p.is_cancer_related for p in matching_problems)\n",
        "                representative_problem.is_treatment_related = any(p.is_treatment_related for p in matching_problems)\n",
        "                representative_problem.is_psychosocial = any(p.is_psychosocial for p in matching_problems)\n",
        "                representative_problem.requires_immediate_attention = any(p.requires_immediate_attention for p in matching_problems)\n",
        "\n",
        "                # Update last_updated timestamp to the latest among merged problems\n",
        "                latest_update_date = state.note_date # Start with current note date\n",
        "                try:\n",
        "                     problem_dates = [datetime.datetime.strptime(p.last_updated, \"%Y-%m-%d\").date() for p in matching_problems if p.last_updated]\n",
        "                     if problem_dates:\n",
        "                          latest_update_date_obj = max(problem_dates)\n",
        "                          latest_update_date = latest_update_date_obj.strftime(\"%Y-%m-%d\")\n",
        "                except ValueError:\n",
        "                     state.warnings.append(\"Could not parse date during problem merging.\")\n",
        "\n",
        "                representative_problem.last_updated = latest_update_date\n",
        "\n",
        "\n",
        "                # Track merge action\n",
        "                merge_actions.append({\n",
        "                    \"action\": \"merged\",\n",
        "                    \"target_problem_id\": representative_problem.problem_id,\n",
        "                    \"merged_problem_ids\": [p.problem_id for p in matching_problems],\n",
        "                    \"representative_name\": representative_problem.problem_name,\n",
        "                    \"details\": f\"Merged {len(matching_problems)} problems into one.\"\n",
        "                })\n",
        "                state.debug_logs.append(f\"Simple Merge: Merged {len(matching_problems)} problems into '{representative_problem.problem_name}'.\")\n",
        "\n",
        "                final_problems.append(representative_problem)\n",
        "\n",
        "            else:\n",
        "                # No matches, add the problem as is\n",
        "                final_problems.append(current_problem)\n",
        "\n",
        "        state.debug_logs.append(f\"Simple Merge: Final problems after simple merge: {len(final_problems)}\")\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # LLM-based Merging Logic (for more complex scenarios)\n",
        "    # =====================================================================\n",
        "    else: # Use LLM for complex merging if more than 15 problems\n",
        "        logging.info(f\"Using LLM-based merging logic for {len(all_problems)} problems.\")\n",
        "        llm = get_llm()\n",
        "\n",
        "        merge_prompt = ChatPromptTemplate.from_messages([\n",
        "            (\"system\", \"\"\"You are a medical AI assistant specialized in merging lists of medical problems from different sources (previous records and current clinical notes).\n",
        "             Your task is to intelligently consolidate these lists, identifying and merging duplicate or highly related problems, while preserving unique and important information.\n",
        "             Adhere to the following rules:\n",
        "             1. Preserve the `problem_id` for existing problems from the `previous_problems` list if they are kept in the `final_problems` list. Newly extracted problems will have their own `problem_id`.\n",
        "             2. Merge `evidence` strings using a '|' separator if multiple sources provide evidence for the same problem.\n",
        "             3. Use OR logic for boolean flags (`is_cancer_related`, `is_treatment_related`, `is_psychosocial`, `requires_immediate_attention`): if the flag is true for any of the merged problems, it should be true in the final merged problem.\n",
        "             4. For `priority_flag`, keep the highest priority among the merged problems ('critical' > 'important' > 'regular').\n",
        "             5. For `status`, 'Active' takes precedence over 'Inactive'. If any merged problem is 'Active', the final status is 'Active'.\n",
        "             6. Update the `last_updated` timestamp to the latest date among the merged problems. Use the current note date ({note_date}) as a potential latest date if applicable.\n",
        "             7. Identify and report any significant conflicts or ambiguities encountered during merging that require human review.\n",
        "             8. Track which problems were merged and which were kept as unique.\n",
        "\n",
        "             OUTPUT INSTRUCTIONS:\n",
        "             Provide the output as a JSON object with the following keys:\n",
        "             - `final_problems`: A JSON array of objects, representing the final, merged list of medical problems. Each object MUST conform to the `MedicalProblem` schema (problem_id, problem_name, status, priority_flag, etc.). Ensure problem_ids are preserved for previous problems.\n",
        "             - `merge_actions`: A JSON array detailing the merge operations performed (e.g., problems merged, problems kept unique).\n",
        "             - `conflicts_resolved`: A JSON array listing any conflicts encountered and how they were resolved.\n",
        "\n",
        "             Ensure the JSON is valid and contains ONLY the JSON object. Do not include any introductory or concluding text outside the JSON.\n",
        "             \"\"\"),\n",
        "            (\"human\", \"\"\"Intelligently merge the following lists of medical problems for patient MRN: {mrn}. The current clinical note date is {note_date}.\n",
        "             Previous Problems: {previous_problems}\n",
        "             Newly Extracted Problems: {extracted_problems}\n",
        "             \"\"\")\n",
        "        ])\n",
        "\n",
        "        chain = merge_prompt | llm\n",
        "\n",
        "        try:\n",
        "            previous_problems_str = json.dumps([p.model_dump() for p in state.previous_problems], indent=2)\n",
        "            extracted_problems_str = json.dumps([p.model_dump() for p in state.extracted_problems], indent=2)\n",
        "\n",
        "            response = chain.invoke({\n",
        "                \"mrn\": state.patient_mrn,\n",
        "                \"note_date\": state.note_date,\n",
        "                \"previous_problems\": previous_problems_str,\n",
        "                \"extracted_problems\": extracted_problems_str\n",
        "            })\n",
        "\n",
        "            logging.debug(f\"Raw LLM merge response: {response.content}\")\n",
        "            llm_merge_output = json.loads(response.content)\n",
        "\n",
        "            if not isinstance(llm_merge_output, dict) or \"final_problems\" not in llm_merge_output:\n",
        "                 raise ValueError(\"Expected JSON object with 'final_problems' key from LLM merge.\")\n",
        "\n",
        "            # Validate and populate final_problems from LLM output\n",
        "            llm_final_problems_data = llm_merge_output.get(\"final_problems\", [])\n",
        "            llm_merge_actions = llm_merge_output.get(\"merge_actions\", [])\n",
        "            llm_conflicts_resolved = llm_merge_output.get(\"conflicts_resolved\", [])\n",
        "\n",
        "            temp_final_problems: List[MedicalProblem] = []\n",
        "            for item in llm_final_problems_data:\n",
        "                try:\n",
        "                    # Use the problem_id from the LLM output (should preserve existing ones)\n",
        "                    problem_id = item.get(\"problem_id\", str(uuid.uuid4()))\n",
        "                    # Ensure MRN is correct\n",
        "                    item[\"patient_mrn\"] = state.patient_mrn\n",
        "\n",
        "                    problem = MedicalProblem(**item) # Validate using Pydantic model\n",
        "                    temp_final_problems.append(problem)\n",
        "                except ValidationError as e:\n",
        "                    state.errors.append(f\"Validation error creating MedicalProblem from LLM merge output: {item} - {e}\")\n",
        "                    logging.error(f\"Validation error in LLM merge output: {e}\")\n",
        "                except Exception as e:\n",
        "                     state.errors.append(f\"Unexpected error processing LLM merged problem item: {item} - {e}\")\n",
        "                     logging.error(f\"Error processing LLM item: {item}, error: {e}\")\n",
        "\n",
        "            final_problems = temp_final_problems\n",
        "            merge_actions.extend(llm_merge_actions)\n",
        "            conflicts_resolved.extend(llm_conflicts_resolved)\n",
        "            changes_made = True if llm_merge_actions or llm_conflicts_resolved else False # Assume changes if LLM provided actions/conflicts\n",
        "\n",
        "            state.debug_logs.append(f\"LLM Merge: Final problems after LLM merge: {len(final_problems)}\")\n",
        "            state.debug_logs.append(f\"LLM Merge Actions: {json.dumps(merge_actions)}\")\n",
        "            state.debug_logs.append(f\"LLM Conflicts Resolved: {json.dumps(conflicts_resolved)}\")\n",
        "\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            error_msg = f\"problem_analyzer_agent LLM JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "            state.errors.append(error_msg)\n",
        "            state.warnings.append(\"Failed to parse JSON from LLM merge agent. Using raw extracted problems as final.\")\n",
        "            logging.error(error_msg)\n",
        "            # Fallback: If LLM merge fails, use the raw extracted problems and previous problems\n",
        "            final_problems = state.previous_problems + state.extracted_problems # Simple concatenation as fallback\n",
        "            merge_actions.append({\"action\": \"fallback_merge\", \"details\": \"LLM merge failed, used simple concatenation.\"})\n",
        "            changes_made = True # Fallback is a change\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"problem_analyzer_agent unexpected error during LLM merge: {e}\"\n",
        "            state.errors.append(error_msg)\n",
        "            state.warnings.append(\"Unexpected error during LLM merge. Using raw extracted problems as final.\")\n",
        "            logging.error(error_msg)\n",
        "            # Fallback: If LLM merge fails, use the raw extracted problems and previous problems\n",
        "            final_problems = state.previous_problems + state.extracted_problems # Simple concatenation as fallback\n",
        "            merge_actions.append({\"action\": \"fallback_merge\", \"details\": \"LLM merge failed, used simple concatenation.\"})\n",
        "            changes_made = True # Fallback is a change\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # Post-Merge Processing and Integration\n",
        "    # =====================================================================\n",
        "    state.final_problems = final_problems\n",
        "    state.merge_results = {\n",
        "        \"problem_merge_actions\": merge_actions,\n",
        "        \"problem_conflicts_resolved\": conflicts_resolved,\n",
        "        \"total_final_problems\": len(state.final_problems)\n",
        "    }\n",
        "\n",
        "    # Integration with treatment timeline for cancer-related problems\n",
        "    if state.treatment_tracker:\n",
        "         cancer_problems = [p for p in state.final_problems if p.is_cancer_related]\n",
        "         if cancer_problems:\n",
        "              # Update treatment tracker based on the latest cancer problem info if needed\n",
        "              # This could involve updating proposed_stage, dates related to diagnosis, etc.\n",
        "              # For simplicity, we'll just log that cancer problems exist\n",
        "              state.debug_logs.append(f\"problem_analyzer_agent: Identified {len(cancer_problems)} cancer-related problems in final list.\")\n",
        "              # More sophisticated logic could update tracker fields here\n",
        "\n",
        "\n",
        "    logging.info(f\"problem_analyzer_agent completed. Final problems count: {len(state.final_problems)}. Changes made: {changes_made}\")\n",
        "    state.agent_history.append(f\"problem_analyzer_agent: Finished merging. Final problems: {len(state.final_problems)}. Changes made: {changes_made}.\")\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… problem_analyzer_agent function defined.\")\n",
        "print(\"Note: MedicalConceptNormalizer is a placeholder and needs a real medical terminology service for production use.\")\n",
        "test_node(problem_analyzer_agent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… problem_analyzer_agent function defined.\n",
            "Note: MedicalConceptNormalizer is a placeholder and needs a real medical terminology service for production use.\n",
            "ðŸ§ª TESTING LANGGRAPH NODE: PROBLEM_ANALYZER_AGENT\n",
            "============================================================\n",
            "ðŸ“‹ Node Info: Single argument function: problem_analyzer_agent(state)\n",
            "\n",
            "CURRENT STATE (before problem_analyzer_agent):\n",
            "------------------------------\n",
            "State Type: MedicalAgentState\n",
            "Attributes: 39\n",
            "  clinical_note: '\n",
            "Patient: Jane Smith\n",
            "MRN: ONC12345  \n",
            "Date: 2024-01...'\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: list (2 items)\n",
            "  previous_care_plans: list (3 items)\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2024-01-15' notes='Patient reports significant worsening of fatigue over the past week, affecting daily activities. Cycle 5 scheduled for next week.'\n",
            "  extracted_problems: list (3 items)\n",
            "  extracted_care_plans: list (5 items)\n",
            "  final_problems: list (0 items)\n",
            "  ... and 29 more attributes\n",
            "\n",
            "ðŸ”„ EXECUTING PROBLEM_ANALYZER_AGENT...\n",
            "--------------------------------------------------\n",
            "âœ… problem_analyzer_agent completed successfully in 0.00 seconds\n",
            "\n",
            "ðŸ“Š EXECUTION RESULTS:\n",
            "------------------------------\n",
            "âœ… Changes detected: 4 attributes changed\n",
            "\n",
            "ðŸ”„ Modified attributes (4):\n",
            "  ~ final_problems: 0 â†’ 5 items\n",
            "  ~ merge_results: value changed\n",
            "  ~ debug_logs: 30 â†’ 32 items\n",
            "  ~ agent_history: 12 â†’ 14 items\n",
            "\n",
            "ðŸ“‹ FINAL STATE:\n",
            "--------------------\n",
            "Total attributes: 39\n",
            "  clinical_note: 1544 chars\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: 2 items\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'node_name': 'problem_analyzer_agent',\n",
              " 'execution_time': 0.00168,\n",
              " 'timestamp': '2025-09-09T20:10:15.483300',\n",
              " 'changes': {'analysis_time': '2025-09-09T20:10:15.482212',\n",
              "  'changes_detected': True,\n",
              "  'attribute_changes': {'final_problems': {'type': 'list',\n",
              "    'old_count': 0,\n",
              "    'new_count': 5,\n",
              "    'items_added': 5},\n",
              "   'merge_results': {'type': 'value',\n",
              "    'old': 'None',\n",
              "    'new': \"{'problem_merge_actions': [], 'problem_conflicts_resolved': [], 'total_final_problems': 5}\"},\n",
              "   'debug_logs': {'type': 'list',\n",
              "    'old_count': 30,\n",
              "    'new_count': 32,\n",
              "    'items_added': 2},\n",
              "   'agent_history': {'type': 'list',\n",
              "    'old_count': 12,\n",
              "    'new_count': 14,\n",
              "    'items_added': 2}},\n",
              "  'new_attributes': [],\n",
              "  'modified_attributes': ['final_problems',\n",
              "   'merge_results',\n",
              "   'debug_logs',\n",
              "   'agent_history'],\n",
              "  'summary': '4 attributes changed'},\n",
              " 'signature_info': {'parameters': ['state'],\n",
              "  'param_count': 1,\n",
              "  'call_pattern': 'single_arg',\n",
              "  'description': 'Single argument function: problem_analyzer_agent(state)',\n",
              "  'signature': '(state: __main__.MedicalAgentState) -> __main__.MedicalAgentState'}}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bd6539f",
        "outputId": "487f59ef-8066-4c8f-d8c8-a1a3313f9414"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, CarePlan, WorkflowCalculator, PatientTreatmentTracker are defined previously\n",
        "\n",
        "def care_plan_workflow_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that manages the workflow status of care plans and identifies potential delays or conflicts.\n",
        "\n",
        "    Calculates workflow status, updates overdue flags, integrates with treatment timeline,\n",
        "    and uses LLM for complex analysis and recommendations.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with workflow analysis results and alerts.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing care_plan_workflow_agent...\")\n",
        "    state.agent_history.append(\"care_plan_workflow_agent: Managing care plan workflow.\")\n",
        "    state.current_agent = \"care_plan_workflow_agent\"\n",
        "\n",
        "    # Use the current date for workflow calculations\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    state.debug_logs.append(f\"care_plan_workflow_agent: Workflow analysis based on current date: {current_date}\")\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # 1. Calculate and Update Workflow Status and Overdue Days\n",
        "    # =====================================================================\n",
        "    workflow_updates = []\n",
        "    overdue_plans = []\n",
        "    critical_delayed_plans = []\n",
        "\n",
        "    all_care_plans = state.previous_care_plans + state.extracted_care_plans # Consider all plans\n",
        "\n",
        "    for cp in all_care_plans:\n",
        "        try:\n",
        "            old_status = cp.workflow_status\n",
        "            old_days_overdue = cp.days_overdue\n",
        "\n",
        "            # Calculate new status and days overdue based on the current date\n",
        "            new_status, new_days_overdue = WorkflowCalculator.calculate_workflow_status(\n",
        "                date_due=cp.date_due,\n",
        "                date_initiated=cp.date_initiated,\n",
        "                date_completed=cp.date_completed,\n",
        "                current_date=current_date # Use current date for real-time status\n",
        "            )\n",
        "\n",
        "            # Update the care plan object\n",
        "            cp.workflow_status = new_status\n",
        "            cp.days_overdue = new_days_overdue\n",
        "\n",
        "            if new_status != old_status or new_days_overdue != old_days_overdue:\n",
        "                 workflow_updates.append({\n",
        "                     \"plan_id\": cp.plan_id,\n",
        "                     \"plan_description\": cp.suggested_plan,\n",
        "                     \"old_status\": old_status,\n",
        "                     \"new_status\": new_status,\n",
        "                     \"old_days_overdue\": old_days_overdue,\n",
        "                     \"new_days_overdue\": new_days_overdue\n",
        "                 })\n",
        "                 state.debug_logs.append(f\"care_plan_workflow_agent: Updated plan {cp.plan_id} status: {old_status} -> {new_status}, days overdue: {old_days_overdue} -> {new_days_overdue}\")\n",
        "\n",
        "\n",
        "            # Flag overdue plans\n",
        "            if new_status in [\"overdue\", \"delayed\"]:\n",
        "                overdue_plans.append(cp)\n",
        "                state.workflow_alerts.append(f\"Care Plan Overdue/Delayed: '{cp.suggested_plan}' is {new_status} by {new_days_overdue} days (Due: {cp.date_due}).\")\n",
        "                state.warnings.append(f\"Care Plan {new_status}: {cp.suggested_plan} (Due: {cp.date_due})\")\n",
        "\n",
        "            # Flag critical delayed urgent plans (> 3 days overdue for urgent)\n",
        "            if new_status in [\"overdue\", \"delayed\"] and cp.urgency_level == 'urgent' and new_days_overdue > 3:\n",
        "                 critical_delayed_plans.append(cp)\n",
        "                 state.priority_alerts.append(f\"CRITICAL Workflow Delay: Urgent Care Plan '{cp.suggested_plan}' is {new_status} by {new_days_overdue} days. Requires immediate attention.\")\n",
        "                 state.errors.append(f\"CRITICAL Workflow Delay: Urgent plan {cp.suggested_plan} overdue by {new_days_overdue} days.\") # Add to errors for critical issues\n",
        "\n",
        "\n",
        "        except ValueError:\n",
        "            error_msg = f\"care_plan_workflow_agent: Could not calculate workflow status for plan {cp.plan_id} due to invalid date format.\"\n",
        "            state.errors.append(error_msg)\n",
        "            logging.error(error_msg)\n",
        "        except Exception as e:\n",
        "             error_msg = f\"care_plan_workflow_agent: Unexpected error processing care plan {cp.plan_id} for workflow: {e}\"\n",
        "             state.errors.append(error_msg)\n",
        "             logging.error(error_msg)\n",
        "\n",
        "\n",
        "    state.debug_logs.append(f\"care_plan_workflow_agent: Processed {len(all_care_plans)} care plans. {len(overdue_plans)} overdue/delayed plans.\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 2. Integrate with Treatment Timeline (for therapy-related plans)\n",
        "    # =====================================================================\n",
        "    if state.treatment_tracker:\n",
        "         logging.info(\"Integrating care plan workflow with treatment timeline.\")\n",
        "         state.treatment_tracker.update_timeline_status(current_date=current_date) # Ensure tracker is up-to-date\n",
        "\n",
        "         # Check for therapy initiation plans that are delayed\n",
        "         therapy_initiation_plans = [\n",
        "             cp for cp in all_care_plans\n",
        "             if cp.action_type in [\"treatment\", \"procedure\"] or any(keyword in cp.suggested_plan.lower() for keyword in [\"start therapy\", \"initiate treatment\"])\n",
        "         ]\n",
        "\n",
        "         for cp in therapy_initiation_plans:\n",
        "              if cp.workflow_status in [\"delayed\", \"overdue\"] and state.treatment_tracker.date_first_therapy_started is None:\n",
        "                   delay_match_alert = f\"Therapy Initiation Plan Delayed: Care Plan '{cp.suggested_plan}' is delayed/overdue, and treatment has not yet started per tracker. Patient MRN: {state.patient_mrn}.\"\n",
        "                   state.workflow_alerts.append(delay_match_alert)\n",
        "                   state.warnings.append(delay_match_alert)\n",
        "                   logging.warning(delay_match_alert)\n",
        "\n",
        "         # Check if any plans are blocking the treatment timeline (e.g., required diagnostics)\n",
        "         # This would require more sophisticated dependency tracking, but we can use LLM assist\n",
        "         blocking_plans_identified = False # Placeholder flag\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # 3. LLM Analysis for Complex Workflow Issues and Recommendations\n",
        "    # =====================================================================\n",
        "    llm = get_llm()\n",
        "\n",
        "    workflow_analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a medical AI assistant specialized in analyzing care plan workflows and identifying potential issues, risks, and recommendations.\n",
        "         Review the provided care plans, current date, and treatment timeline information. Your task is to:\n",
        "         - Identify critical workflow delays or bottlenecks.\n",
        "         - Assess potential resource conflicts (though specific resource data is not provided, infer from multiple urgent/overdue plans).\n",
        "         - Analyze timeline risks, especially in the context of the patient's treatment timeline.\n",
        "         - Propose scheduling recommendations or actions to mitigate delays.\n",
        "         - Determine if escalation is needed for specific issues (e.g., critical delays, unaddressed urgent plans).\n",
        "         - Consider the patient's status (from treatment tracker if available) to prioritize urgent needs.\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the analysis and recommendations as a JSON object with the following keys:\n",
        "         - `workflow_summary`: string (Brief summary of workflow status)\n",
        "         - `priority_alerts`: list of strings (Alerts for critical delays or urgent items needing immediate attention)\n",
        "         - `scheduling_recommendations`: list of strings (Suggestions for scheduling or re-prioritizing plans)\n",
        "         - `resource_considerations`: string (Notes on potential resource needs or conflicts)\n",
        "         - `escalation_required`: boolean (True if critical issues requiring human escalation are found)\n",
        "         - `risks_identified`: list of strings (Potential risks to patient care or timeline identified)\n",
        "         - `workflow_metrics`: dict (Any quantifiable metrics derived, like total overdue days across plans)\n",
        "\n",
        "         Ensure the JSON is valid and contains ONLY the JSON object. Do not include any introductory or concluding text outside the JSON.\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Analyze the care plan workflow for patient MRN: {mrn}.\n",
        "         Current Date: {current_date}\n",
        "         Care Plans: {all_care_plans_json}\n",
        "         Treatment Timeline: {treatment_tracker_json}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = workflow_analysis_prompt | llm\n",
        "\n",
        "    workflow_analysis_results: Dict[str, Any] = {}\n",
        "\n",
        "    try:\n",
        "        all_care_plans_json = json.dumps([cp.model_dump() for cp in all_care_plans], indent=2)\n",
        "        treatment_tracker_json = state.treatment_tracker.model_dump_json(indent=2) if state.treatment_tracker else \"{}\"\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"current_date\": current_date,\n",
        "            \"all_care_plans_json\": all_care_plans_json,\n",
        "            \"treatment_tracker_json\": treatment_tracker_json\n",
        "        })\n",
        "\n",
        "        logging.debug(f\"Raw LLM workflow analysis response: {response.content}\")\n",
        "        llm_analysis_output = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(llm_analysis_output, dict):\n",
        "             raise ValueError(\"Expected JSON object for workflow analysis, but received a different structure.\")\n",
        "\n",
        "        workflow_analysis_results = llm_analysis_output\n",
        "\n",
        "        # Update state with LLM's analysis and alerts\n",
        "        state.workflow_analysis = workflow_analysis_results\n",
        "\n",
        "        # Append LLM-identified alerts/risks to state\n",
        "        state.priority_alerts.extend(workflow_analysis_results.get(\"priority_alerts\", []))\n",
        "        state.workflow_alerts.extend(workflow_analysis_results.get(\"risks_identified\", []))\n",
        "        state.workflow_alerts.extend([f\"Recommendation: {rec}\" for rec in workflow_analysis_results.get(\"scheduling_recommendations\", [])])\n",
        "\n",
        "        if workflow_analysis_results.get(\"escalation_required\"):\n",
        "             state.priority_alerts.append(f\"ESCALATION REQUIRED: Workflow analysis indicates issues requiring human intervention.\")\n",
        "             state.errors.append(\"Workflow analysis indicates escalation is required.\") # Critical issue\n",
        "\n",
        "        state.debug_logs.append(f\"care_plan_workflow_agent: LLM workflow analysis completed. Escalation needed: {workflow_analysis_results.get('escalation_required', False)}\")\n",
        "        logging.info(\"LLM workflow analysis completed.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"care_plan_workflow_agent LLM JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.workflow_analysis = {\"error\": \"JSON parsing failed\", \"details\": str(e)}\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"care_plan_workflow_agent unexpected error during LLM analysis: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.workflow_analysis = {\"error\": \"Unexpected error during analysis\", \"details\": str(e)}\n",
        "        logging.error(error_msg)\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # 4. Final State Update and Routing\n",
        "    # =====================================================================\n",
        "    # Re-assign combined care plans (in case LLM modified them - although prompt doesn't ask for that)\n",
        "    # If LLM was meant to return modified plans, we'd parse them here.\n",
        "    # Assuming LLM output is just analysis/recommendations for now.\n",
        "    state.final_care_plans = all_care_plans # Keep the updated list with calculated statuses\n",
        "\n",
        "\n",
        "    logging.info(\"care_plan_workflow_agent completed.\")\n",
        "    state.agent_history.append(f\"care_plan_workflow_agent: Finished workflow management. Processed {len(state.final_care_plans)} plans.\")\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… care_plan_workflow_agent function defined.\")\n",
        "test_node(  care_plan_workflow_agent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… care_plan_workflow_agent function defined.\n",
            "ðŸ§ª TESTING LANGGRAPH NODE: CARE_PLAN_WORKFLOW_AGENT\n",
            "============================================================\n",
            "ðŸ“‹ Node Info: Single argument function: care_plan_workflow_agent(state)\n",
            "\n",
            "CURRENT STATE (before care_plan_workflow_agent):\n",
            "------------------------------\n",
            "State Type: MedicalAgentState\n",
            "Attributes: 39\n",
            "  clinical_note: '\n",
            "Patient: Jane Smith\n",
            "MRN: ONC12345  \n",
            "Date: 2024-01...'\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: list (2 items)\n",
            "  previous_care_plans: list (3 items)\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2025-09-09' notes='Patient reports significant worsening of fatigue over the past week, affecting daily activities. Cycle 5 scheduled for next week.'\n",
            "  extracted_problems: list (3 items)\n",
            "  extracted_care_plans: list (5 items)\n",
            "  final_problems: list (5 items)\n",
            "  ... and 29 more attributes\n",
            "\n",
            "ðŸ”„ EXECUTING CARE_PLAN_WORKFLOW_AGENT...\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:care_plan_workflow_agent LLM JSON parsing error: Expecting ',' delimiter: line 23 column 31 (char 1516). Raw response: {\n",
            "  \"workflow_summary\": \"Multiple care plans for patient ONC12345 are overdue, with critical findings and urgent needs unaddressed, particularly regarding chemotherapy cycles and monitoring.\",\n",
            "  \"priority_alerts\": [\n",
            "    \"Plan for 6 cycles of AC-T chemotherapy is overdue by 572 days and marked as critical.\",\n",
            "    \"Monitoring blood counts before each cycle is overdue by 598 days and marked as urgent.\",\n",
            "    \"Supportive care consultation for fatigue management is overdue by 593 days.\",\n",
            "    \"Labs prior to next chemotherapy cycle are overdue by 598 days.\"\n",
            "  ],\n",
            "  \"scheduling_recommendations\": [\n",
            "    \"Prioritize scheduling the overdue chemotherapy cycles immediately to avoid further delays.\",\n",
            "    \"Arrange for urgent blood count monitoring before the next chemotherapy cycle.\",\n",
            "    \"Schedule supportive care consultations to address fatigue management as soon as possible.\",\n",
            "    \"Ensure follow-up appointments are set to monitor the patient's status regularly.\"\n",
            "  ],\n",
            "  \"resource_considerations\": \"There may be conflicts in scheduling due to multiple overdue plans requiring immediate attention, particularly in chemotherapy and supportive care resources.\",\n",
            "  \"escalation_required\": true,\n",
            "  \"risks_identified\": [\n",
            "    \"Significant delays in chemotherapy could lead to disease progression.\",\n",
            "    \"Failure to monitor blood counts may result in undetected complications.\",\n",
            "    \"Unaddressed fatigue management could severely impact the patient's quality of life.\"\n",
            "  ],\n",
            "  \"workflow_metrics\": {\n",
            "    \"total_overdue_days\": 572 + 598 + 593 + 598 + 593 + 596,\n",
            "    \"total_overdue_plans\": 8\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… care_plan_workflow_agent completed successfully in 6.45 seconds\n",
            "\n",
            "ðŸ“Š EXECUTION RESULTS:\n",
            "------------------------------\n",
            "âœ… Changes detected: 7 attributes changed\n",
            "\n",
            "ðŸ”„ Modified attributes (7):\n",
            "  ~ workflow_analysis: value changed\n",
            "    Current content (workflow_analysis):\n",
            "      Dict with 2 keys:\n",
            "      error: JSON parsing failed\n",
            "      details: Expecting ',' delimiter: line 23 column 31 (char 1516)\n",
            "  ~ priority_alerts: 8 â†’ 10 items\n",
            "    Current content (priority_alerts):\n",
            "      List with 10 items:\n",
            "      [0] EMERGENCY: critical findings in clinical note\n",
            "      [1] CRITICAL Workflow Delay: Urgent Care Plan 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days. Requires immediate attention.\n",
            "      [2] CRITICAL Workflow Delay: Urgent Care Plan 'Monitor blood counts before each cycle' is overdue by 598 days. Requires immediate attention.\n",
            "      [3] Plan for 6 cycles of AC-T chemotherapy is overdue by 572 days and marked as critical.\n",
            "      [4] Monitoring blood counts before each cycle is overdue by 598 days and marked as urgent.\n",
            "      [5] Supportive care consultation for fatigue management is overdue by 593 days.\n",
            "      [6] Refer to supportive care for chemotherapy-induced fatigue management is overdue by 598 days.\n",
            "      [7] ESCALATION REQUIRED: Workflow analysis indicates issues requiring human intervention.\n",
            "      [8] CRITICAL Workflow Delay: Urgent Care Plan 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days. Requires immediate attention.\n",
            "      [9] CRITICAL Workflow Delay: Urgent Care Plan 'Monitor blood counts before each cycle' is overdue by 598 days. Requires immediate attention.\n",
            "    âž• Added items (2):\n",
            "      [8] CRITICAL Workflow Delay: Urgent Care Plan 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days. Requires immediate attention.\n",
            "      [9] CRITICAL Workflow Delay: Urgent Care Plan 'Monitor blood counts before each cycle' is overdue by 598 days. Requires immediate attention.\n",
            "  ~ workflow_alerts: 18 â†’ 26 items\n",
            "    Current content (workflow_alerts):\n",
            "      List with 26 items:\n",
            "      [0] Validation Warning: Non-urgent care plan 'Refer to supportive care for chemotherapy-induced fatigue management' has a date_due within the next 48 hour...\n",
            "      [1] Validation Warning: Non-urgent care plan 'Labs prior to next chemotherapy cycle to check blood counts' has a date_due within the next 48 hours.\n",
            "      [2] Validation Warning: Urgent care plan has due date 2024-02-15 which is more than 48 hours from note date 2024-01-15.\n",
            "      [3] Validation Warning: Urgent care plan has due date 2024-01-20 which is more than 48 hours from note date 2024-01-15.\n",
            "      [4] Care Plan Overdue/Delayed: 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days (Due: 2024-02-15).\n",
            "      [5] Care Plan Overdue/Delayed: 'Monitor blood counts before each cycle' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [6] Care Plan Overdue/Delayed: 'Supportive care consultation for fatigue management' is overdue by 593 days (Due: 2024-01-25).\n",
            "      [7] Care Plan Overdue/Delayed: 'Refer to supportive care for chemotherapy-induced fatigue management' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [8] Care Plan Overdue/Delayed: 'Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen' is overdue by 593 days (Due: 20...\n",
            "      [9] Care Plan Overdue/Delayed: 'Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry' is overdue by 593 days (...\n",
            "      [10] Care Plan Overdue/Delayed: 'Labs prior to next chemotherapy cycle to check blood counts' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [11] Care Plan Overdue/Delayed: 'Follow-up in clinic in 1 week' is overdue by 596 days (Due: 2024-01-22).\n",
            "      [12] Delays in chemotherapy could lead to disease progression.\n",
            "      [13] Failure to monitor blood counts may result in undetected complications.\n",
            "      [14] Unaddressed fatigue management could severely impact the patient's quality of life.\n",
            "      [15] Recommendation: Prioritize scheduling the overdue chemotherapy cycles immediately to prevent further delays.\n",
            "      [16] Recommendation: Arrange for blood count monitoring before the next chemotherapy cycle scheduled for next week.\n",
            "      [17] Recommendation: Schedule supportive care consultations for fatigue management as soon as possible.\n",
            "      [18] Care Plan Overdue/Delayed: 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days (Due: 2024-02-15).\n",
            "      [19] Care Plan Overdue/Delayed: 'Monitor blood counts before each cycle' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [20] Care Plan Overdue/Delayed: 'Supportive care consultation for fatigue management' is overdue by 593 days (Due: 2024-01-25).\n",
            "      [21] Care Plan Overdue/Delayed: 'Refer to supportive care for chemotherapy-induced fatigue management' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [22] Care Plan Overdue/Delayed: 'Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen' is overdue by 593 days (Due: 20...\n",
            "      [23] Care Plan Overdue/Delayed: 'Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry' is overdue by 593 days (...\n",
            "      [24] Care Plan Overdue/Delayed: 'Labs prior to next chemotherapy cycle to check blood counts' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [25] Care Plan Overdue/Delayed: 'Follow-up in clinic in 1 week' is overdue by 596 days (Due: 2024-01-22).\n",
            "    âž• Added items (8):\n",
            "      [18] Care Plan Overdue/Delayed: 'Complete 6 cycles of AC-T chemotherapy' is overdue by 572 days (Due: 2024-02-15).\n",
            "      [19] Care Plan Overdue/Delayed: 'Monitor blood counts before each cycle' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [20] Care Plan Overdue/Delayed: 'Supportive care consultation for fatigue management' is overdue by 593 days (Due: 2024-01-25).\n",
            "      [21] Care Plan Overdue/Delayed: 'Refer to supportive care for chemotherapy-induced fatigue management' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [22] Care Plan Overdue/Delayed: 'Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen' is overdue by 593 days (Due: 20...\n",
            "      [23] Care Plan Overdue/Delayed: 'Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry' is overdue by 593 days (...\n",
            "      [24] Care Plan Overdue/Delayed: 'Labs prior to next chemotherapy cycle to check blood counts' is overdue by 598 days (Due: 2024-01-20).\n",
            "      [25] Care Plan Overdue/Delayed: 'Follow-up in clinic in 1 week' is overdue by 596 days (Due: 2024-01-22).\n",
            "  ~ errors: 3 â†’ 6 items\n",
            "    Current content (errors):\n",
            "      List with 6 items:\n",
            "      [0] CRITICAL Workflow Delay: Urgent plan Complete 6 cycles of AC-T chemotherapy overdue by 572 days.\n",
            "      [1] CRITICAL Workflow Delay: Urgent plan Monitor blood counts before each cycle overdue by 598 days.\n",
            "      [2] Workflow analysis indicates escalation is required.\n",
            "      [3] CRITICAL Workflow Delay: Urgent plan Complete 6 cycles of AC-T chemotherapy overdue by 572 days.\n",
            "      [4] CRITICAL Workflow Delay: Urgent plan Monitor blood counts before each cycle overdue by 598 days.\n",
            "      [5] care_plan_workflow_agent LLM JSON parsing error: Expecting ',' delimiter: line 23 column 31 (char 1516). Raw response: {\n",
            "  \"workflow_summary\": \"Multip...\n",
            "    âž• Added items (3):\n",
            "      [3] CRITICAL Workflow Delay: Urgent plan Complete 6 cycles of AC-T chemotherapy overdue by 572 days.\n",
            "      [4] CRITICAL Workflow Delay: Urgent plan Monitor blood counts before each cycle overdue by 598 days.\n",
            "      [5] care_plan_workflow_agent LLM JSON parsing error: Expecting ',' delimiter: line 23 column 31 (char 1516). Raw response: {\n",
            "  \"workflow_summary\": \"Multip...\n",
            "  ~ warnings: 8 â†’ 16 items\n",
            "    Current content (warnings):\n",
            "      List with 16 items:\n",
            "      [0] Care Plan overdue: Complete 6 cycles of AC-T chemotherapy (Due: 2024-02-15)\n",
            "      [1] Care Plan overdue: Monitor blood counts before each cycle (Due: 2024-01-20)\n",
            "      [2] Care Plan overdue: Supportive care consultation for fatigue management (Due: 2024-01-25)\n",
            "      [3] Care Plan overdue: Refer to supportive care for chemotherapy-induced fatigue management (Due: 2024-01-20)\n",
            "      [4] Care Plan overdue: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Due: 2024-01-25)\n",
            "      [5] Care Plan overdue: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Due: 2024-01-25)\n",
            "      [6] Care Plan overdue: Labs prior to next chemotherapy cycle to check blood counts (Due: 2024-01-20)\n",
            "      [7] Care Plan overdue: Follow-up in clinic in 1 week (Due: 2024-01-22)\n",
            "      [8] Care Plan overdue: Complete 6 cycles of AC-T chemotherapy (Due: 2024-02-15)\n",
            "      [9] Care Plan overdue: Monitor blood counts before each cycle (Due: 2024-01-20)\n",
            "      [10] Care Plan overdue: Supportive care consultation for fatigue management (Due: 2024-01-25)\n",
            "      [11] Care Plan overdue: Refer to supportive care for chemotherapy-induced fatigue management (Due: 2024-01-20)\n",
            "      [12] Care Plan overdue: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Due: 2024-01-25)\n",
            "      [13] Care Plan overdue: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Due: 2024-01-25)\n",
            "      [14] Care Plan overdue: Labs prior to next chemotherapy cycle to check blood counts (Due: 2024-01-20)\n",
            "      [15] Care Plan overdue: Follow-up in clinic in 1 week (Due: 2024-01-22)\n",
            "    âž• Added items (8):\n",
            "      [8] Care Plan overdue: Complete 6 cycles of AC-T chemotherapy (Due: 2024-02-15)\n",
            "      [9] Care Plan overdue: Monitor blood counts before each cycle (Due: 2024-01-20)\n",
            "      [10] Care Plan overdue: Supportive care consultation for fatigue management (Due: 2024-01-25)\n",
            "      [11] Care Plan overdue: Refer to supportive care for chemotherapy-induced fatigue management (Due: 2024-01-20)\n",
            "      [12] Care Plan overdue: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Due: 2024-01-25)\n",
            "      [13] Care Plan overdue: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Due: 2024-01-25)\n",
            "      [14] Care Plan overdue: Labs prior to next chemotherapy cycle to check blood counts (Due: 2024-01-20)\n",
            "      [15] Care Plan overdue: Follow-up in clinic in 1 week (Due: 2024-01-22)\n",
            "  ~ debug_logs: 43 â†’ 45 items\n",
            "    Current content (debug_logs):\n",
            "      List with 45 items:\n",
            "      [0] start_agent: Input validation successful.\n",
            "      [1] start_agent: Clinical note length: 220 words\n",
            "      [2] start_agent: Previous problems: 2\n",
            "      [3] start_agent: Previous care plans: 3\n",
            "      [4] start_agent: Clinical context analysis - Critical findings: True, Cancer context: True\n",
            "      [5] start_agent: Treatment tracker updated - Status: Treatment started on time (started 14 days early)\n",
            "      [6] start_agent: Processing mode: EMERGENCY - Critical medical situation detected\n",
            "      [7] Extracted and validated problem: Worsening Fatigue (Priority: important)\n",
            "      [8] Extracted and validated problem: Chemotherapy-Induced Peripheral Neuropathy (Priority: important)\n",
            "      [9] Extracted and validated problem: Treatment-Related Anxiety (Priority: important)\n",
            "      [10] problem_extraction_agent: Successfully extracted 3 problems.\n",
            "      [11] Extracted and validated care plan: Refer to supportive care for chemotherapy-induced fatigue management (Urgency: non-urgent, Status: pending)\n",
            "      [12] Extracted and validated care plan: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Urgency: non-urgent, Sta...\n",
            "      [13] Extracted and validated care plan: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Urgency: non-urge...\n",
            "      [14] Extracted and validated care plan: Complete labs prior to next chemotherapy cycle to check blood counts (Urgency: non-urgent, Status: pending)\n",
            "      [15] Extracted and validated care plan: Follow-up in clinic in 1 week (Urgency: non-urgent, Status: pending)\n",
            "      [16] care_plan_extraction_agent: Successfully extracted 5 care plans.\n",
            "      [17] Extracted and validated care plan: Refer to supportive care for chemotherapy-induced fatigue management (Urgency: non-urgent, Status: pending)\n",
            "      [18] Extracted and validated care plan: Consider dose reduction for chemotherapy-induced peripheral neuropathy if symptoms worsen (Urgency: non-urgent, Sta...\n",
            "      [19] Extracted and validated care plan: Continue supportive counseling for treatment-related anxiety and consider referral to psychiatry (Urgency: non-urge...\n",
            "      [20] Extracted and validated care plan: Labs prior to next chemotherapy cycle to check blood counts (Urgency: non-urgent, Status: pending)\n",
            "      [21] Extracted and validated care plan: Follow-up in clinic in 1 week (Urgency: non-urgent, Status: pending)\n",
            "      [22] care_plan_extraction_agent: Successfully extracted 5 care plans.\n",
            "      [23] treatment_timeline_agent: Updated tracker field 'first_therapy_type' to 'chemotherapy'.\n",
            "      [24] treatment_timeline_agent: Updated tracker field 'date_first_therapy_started' to '2023-12-01'.\n",
            "      [25] treatment_timeline_agent: Updated tracker field 'notes' to 'Patient reports significant worsening of fatigue over the past week, affecting daily activ...\n",
            "      [26] treatment_timeline_agent: Applied 3 updates to treatment tracker.\n",
            "      [27] treatment_timeline_agent: Recalculated timeline status: Treatment started on time (started 14 days early)\n",
            "      [28] medical_validator_agent: LLM validation output: [{\"item_id\": \"5fb6987f-1a05-47bf-b685-6f08ac623fdf\", \"item_type\": \"problem\", \"issue_type\": \"priority_m...\n",
            "      [29] medical_validator_agent: Final validation result - is_valid: False, Confidence: 0.5\n",
            "      [30] Simple Merge: Final problems after simple merge: 5\n",
            "      [31] problem_analyzer_agent: Identified 4 cancer-related problems in final list.\n",
            "      [32] care_plan_workflow_agent: Workflow analysis based on current date: 2025-09-09\n",
            "      [33] care_plan_workflow_agent: Updated plan 1911164b-b598-44fc-adc1-56109329f387 status: in-progress -> overdue, days overdue: 0 -> 572\n",
            "      [34] care_plan_workflow_agent: Updated plan f04f1ffc-4f60-411b-9378-2cd3b0f244de status: pending -> overdue, days overdue: 0 -> 598\n",
            "      [35] care_plan_workflow_agent: Updated plan 2596047a-523f-4a80-a4ad-0f3182f183ef status: pending -> overdue, days overdue: 0 -> 593\n",
            "      [36] care_plan_workflow_agent: Updated plan 2b876b1f-0109-486e-9a02-32a4736b69f9 status: pending -> overdue, days overdue: 0 -> 598\n",
            "      [37] care_plan_workflow_agent: Updated plan 3b171a6b-2132-451f-a101-0f987f4e2e76 status: pending -> overdue, days overdue: 0 -> 593\n",
            "      [38] care_plan_workflow_agent: Updated plan c2d01059-03cc-45ad-a38b-9a624e0c4e3c status: pending -> overdue, days overdue: 0 -> 593\n",
            "      [39] care_plan_workflow_agent: Updated plan 4cb6225f-026c-402a-b8a5-b131830e573c status: pending -> overdue, days overdue: 0 -> 598\n",
            "      [40] care_plan_workflow_agent: Updated plan 66a29518-e69e-41b7-8422-96b18929ba12 status: pending -> overdue, days overdue: 0 -> 596\n",
            "      [41] care_plan_workflow_agent: Processed 8 care plans. 8 overdue/delayed plans.\n",
            "      [42] care_plan_workflow_agent: LLM workflow analysis completed. Escalation needed: True\n",
            "      [43] care_plan_workflow_agent: Workflow analysis based on current date: 2025-09-09\n",
            "      [44] care_plan_workflow_agent: Processed 8 care plans. 8 overdue/delayed plans.\n",
            "    âž• Added items (2):\n",
            "      [43] care_plan_workflow_agent: Workflow analysis based on current date: 2025-09-09\n",
            "      [44] care_plan_workflow_agent: Processed 8 care plans. 8 overdue/delayed plans.\n",
            "  ~ agent_history: 16 â†’ 18 items\n",
            "    Current content (agent_history):\n",
            "      List with 18 items:\n",
            "      [0] start_agent: Initializing medical information processing.\n",
            "      [1] start_agent completed: Mode=emergency, Next=problem_extraction, Patient=ONC12345\n",
            "      [2] problem_extraction_agent: Extracting medical problems.\n",
            "      [3] problem_extraction_agent: Finished extraction. Extracted 3 problems.\n",
            "      [4] care_plan_extraction_agent: Extracting care plans.\n",
            "      [5] care_plan_extraction_agent: Finished extraction. Extracted 5 care plans.\n",
            "      [6] care_plan_extraction_agent: Extracting care plans.\n",
            "      [7] care_plan_extraction_agent: Finished extraction. Extracted 5 care plans.\n",
            "      [8] treatment_timeline_agent: Managing oncology timeline.\n",
            "      [9] treatment_timeline_agent: Finished timeline management.\n",
            "      [10] medical_validator_agent: Validating extracted data.\n",
            "      [11] medical_validator_agent: Finished validation. Is Valid: False\n",
            "      [12] problem_analyzer_agent: Analyzing and merging medical problems.\n",
            "      [13] problem_analyzer_agent: Finished merging. Final problems: 5. Changes made: False.\n",
            "      [14] care_plan_workflow_agent: Managing care plan workflow.\n",
            "      [15] care_plan_workflow_agent: Finished workflow management. Processed 8 plans.\n",
            "      [16] care_plan_workflow_agent: Managing care plan workflow.\n",
            "      [17] care_plan_workflow_agent: Finished workflow management. Processed 8 plans.\n",
            "    âž• Added items (2):\n",
            "      [16] care_plan_workflow_agent: Managing care plan workflow.\n",
            "      [17] care_plan_workflow_agent: Finished workflow management. Processed 8 plans.\n",
            "\n",
            "ðŸ“‹ FINAL STATE OVERVIEW:\n",
            "--------------------\n",
            "Total attributes: 39\n",
            "  clinical_note: 1544 chars\n",
            "  patient_mrn: ONC12345\n",
            "  note_author: Dr. Sarah Johnson\n",
            "  note_date: 2024-01-15\n",
            "  previous_problems: 2 items\n",
            "  previous_care_plans: 3 items\n",
            "  treatment_tracker: tracker_id='116b3acc-1943-40cc-8a5b-481a32883972' patient_mrn='ONC12345' date_first_visit='2023-11-15' date_biopsy_planned='2023-11-20' date_first_pathology_report='2023-11-25' pathology_needs_repeat=False date_first_radiology_report='2023-11-18' date_full_radiology_evaluation='2023-11-22' proposed_stage='Stage II (T2N1M0)' patient_status='regular' date_should_start_treatment='2023-12-15' first_therapy_type='chemotherapy' date_first_therapy_started='2023-12-01' days_remaining_or_delayed=-14 created_date='2025-09-09' last_updated='2025-09-09' notes='Patient reports significant worsening of fatigue over the past week, affecting daily activities. Cycle 5 scheduled for next week.'\n",
            "  extracted_problems: 3 items\n",
            "  extracted_care_plans: 5 items\n",
            "  final_problems: 5 items\n",
            "  final_care_plans: 8 items\n",
            "  validation_results: 4 keys\n",
            "  analysis_results: None\n",
            "  merge_results: 3 keys\n",
            "  delay_analysis: None\n",
            "  priority_analysis: None\n",
            "  workflow_analysis: 2 keys\n",
            "  final_medical_summary: None\n",
            "  action_recommendations: 0 items\n",
            "  priority_alerts: 10 items\n",
            "  workflow_alerts: 26 items\n",
            "  processing_metrics: 1 keys\n",
            "  validation_confidence: 0.5\n",
            "  extraction_attempts: 3\n",
            "  errors: 6 items\n",
            "  warnings: 16 items\n",
            "  debug_logs: 45 items\n",
            "  agent_history: 18 items\n",
            "  tool_outputs: 0 items\n",
            "  current_step: problem_extraction\n",
            "  current_agent: None\n",
            "  is_complete: False\n",
            "  processing_mode: emergency\n",
            "  processing_start_time: 2025-09-09T19:27:50.760931\n",
            "  processing_end_time: None\n",
            "  iterations: 1\n",
            "  enable_caching: False\n",
            "  enable_markdown_logging: False\n",
            "  max_extraction_attempts: 2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'success': True,\n",
              " 'node_name': 'care_plan_workflow_agent',\n",
              " 'execution_time': 6.452608,\n",
              " 'timestamp': '2025-09-09T20:23:51.254844',\n",
              " 'changes': {'analysis_time': '2025-09-09T20:23:51.252967',\n",
              "  'changes_detected': True,\n",
              "  'attribute_changes': {'workflow_analysis': {'type': 'value',\n",
              "    'old': \"{'workflow_summary': 'Multiple care plans are overdue, with critical findings noted. The patient is \",\n",
              "    'new': '{\\'error\\': \\'JSON parsing failed\\', \\'details\\': \"Expecting \\',\\' delimiter: line 23 column 31 (char 1516)\"'},\n",
              "   'priority_alerts': {'type': 'list',\n",
              "    'old_count': 8,\n",
              "    'new_count': 10,\n",
              "    'items_added': 2},\n",
              "   'workflow_alerts': {'type': 'list',\n",
              "    'old_count': 18,\n",
              "    'new_count': 26,\n",
              "    'items_added': 8},\n",
              "   'errors': {'type': 'list',\n",
              "    'old_count': 3,\n",
              "    'new_count': 6,\n",
              "    'items_added': 3},\n",
              "   'warnings': {'type': 'list',\n",
              "    'old_count': 8,\n",
              "    'new_count': 16,\n",
              "    'items_added': 8},\n",
              "   'debug_logs': {'type': 'list',\n",
              "    'old_count': 43,\n",
              "    'new_count': 45,\n",
              "    'items_added': 2},\n",
              "   'agent_history': {'type': 'list',\n",
              "    'old_count': 16,\n",
              "    'new_count': 18,\n",
              "    'items_added': 2}},\n",
              "  'new_attributes': [],\n",
              "  'modified_attributes': ['workflow_analysis',\n",
              "   'priority_alerts',\n",
              "   'workflow_alerts',\n",
              "   'errors',\n",
              "   'warnings',\n",
              "   'debug_logs',\n",
              "   'agent_history'],\n",
              "  'summary': '7 attributes changed'},\n",
              " 'signature_info': {'parameters': ['state'],\n",
              "  'param_count': 1,\n",
              "  'call_pattern': 'single_arg',\n",
              "  'description': 'Single argument function: care_plan_workflow_agent(state)',\n",
              "  'signature': '(state: __main__.MedicalAgentState) -> __main__.MedicalAgentState'}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12a9a9ed"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker are defined previously\n",
        "\n",
        "def priority_management_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that analyzes and orchestrates priorities of medical problems and care plans.\n",
        "\n",
        "    Identifies priority conflicts, escalation needs, and generates action recommendations\n",
        "    based on a priority matrix and LLM analysis.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with priority analysis results and alerts.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing priority_management_agent...\")\n",
        "    state.agent_history.append(\"priority_management_agent: Orchestrating priorities.\")\n",
        "    state.current_agent = \"priority_management_agent\"\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # =====================================================================\n",
        "    # 1. Categorize Problems and Plans by Priority/Urgency\n",
        "    # =====================================================================\n",
        "    critical_problems = [p for p in state.final_problems if p.priority_flag == 'critical']\n",
        "    important_problems = [p for p in state.final_problems if p.priority_flag == 'important']\n",
        "    regular_problems = [p for p in state.final_problems if p.priority_flag == 'regular']\n",
        "\n",
        "    urgent_plans = [cp for cp in state.final_care_plans if cp.urgency_level == 'urgent']\n",
        "    non_urgent_plans = [cp for cp in state.final_care_plans if cp.urgency_level == 'non-urgent']\n",
        "\n",
        "    # Use current date for checking overdue status\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    overdue_plans = [cp for cp in state.final_care_plans if WorkflowCalculator.calculate_workflow_status(cp.date_due, cp.date_initiated, cp.date_completed, current_date)[0] in [\"overdue\", \"delayed\"]]\n",
        "\n",
        "    state.debug_logs.append(f\"Priority Management: Critical problems: {len(critical_problems)}, Urgent plans: {len(urgent_plans)}, Overdue plans: {len(overdue_plans)}\")\n",
        "\n",
        "    # =====================================================================\n",
        "    # 2. Apply Priority Matrix Rules (internal logic before LLM)\n",
        "    # =====================================================================\n",
        "    internal_priority_alerts = []\n",
        "    internal_action_recommendations = []\n",
        "    escalation_triggered = False\n",
        "\n",
        "    # Rule: Critical problems + Urgent plans = Immediate action\n",
        "    if critical_problems and urgent_plans:\n",
        "        internal_priority_alerts.append(\"IMMEDIATE ACTION REQUIRED: Encountered critical problems and urgent care plans.\")\n",
        "        internal_action_recommendations.append(\"Review all critical problems and urgent care plans immediately.\")\n",
        "        escalation_triggered = True\n",
        "\n",
        "    # Rule: Important problems + Overdue plans = Priority scheduling\n",
        "    if important_problems and overdue_plans:\n",
        "        internal_priority_alerts.append(\"PRIORITY SCHEDULING NEEDED: Important problems associated with overdue care plans.\")\n",
        "        internal_action_recommendations.append(\"Prioritize scheduling for overdue care plans related to important problems.\")\n",
        "\n",
        "    # Rule: Treatment delays + Critical findings = Automatic escalation\n",
        "    if state.treatment_tracker and state.treatment_tracker.days_remaining_or_delayed > 14: # Using a threshold > 14 days for significant delay\n",
        "         internal_priority_alerts.append(f\"TREATMENT DELAY ESCALATION: Patient's treatment is delayed by {state.treatment_tracker.days_remaining_or_delayed} days.\")\n",
        "         internal_action_recommendations.append(\"Escalate patient case for urgent review of treatment timeline.\")\n",
        "         escalation_triggered = True\n",
        "\n",
        "    # Also check for critical findings flag in problems/plans\n",
        "    has_critical_finding_flag = any(p.requires_immediate_attention for p in state.final_problems) or any(cp.critical_finding for cp in state.final_care_plans)\n",
        "    if has_critical_finding_flag:\n",
        "         internal_priority_alerts.append(\"CRITICAL FINDING DETECTED: Data contains items flagged with critical findings.\")\n",
        "         internal_action_recommendations.append(\"Review all problems/plans flagged as critical finding or requiring immediate attention.\")\n",
        "         escalation_triggered = True # Critical finding always triggers escalation potential\n",
        "\n",
        "    # Rule: Patient status critical/declining requires escalation regardless of individual items\n",
        "    if state.treatment_tracker and state.treatment_tracker.patient_status in [\"critical\", \"declining\"]:\n",
        "         internal_priority_alerts.append(f\"PATIENT STATUS CRITICAL: Patient status is {state.treatment_tracker.patient_status}.\")\n",
        "         internal_action_recommendations.append(\"Review all active problems and plans for this patient with heightened urgency.\")\n",
        "         escalation_triggered = True\n",
        "\n",
        "\n",
        "    state.debug_logs.extend(internal_priority_alerts)\n",
        "    state.debug_logs.extend(internal_action_recommendations)\n",
        "    if escalation_triggered:\n",
        "         state.debug_logs.append(\"Priority Management: Escalation triggered based on internal rules.\")\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # 3. LLM Analysis for Comprehensive Priority Orchestration\n",
        "    # =====================================================================\n",
        "    priority_analysis_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a medical AI assistant specialized in orchestrating patient care priorities based on clinical data and workflow status.\n",
        "         Analyze the provided lists of medical problems, care plans, and the treatment timeline. Your task is to:\n",
        "         - Create a prioritized action hierarchy considering problem severity, plan urgency, and workflow status.\n",
        "         - Identify potential resource constraints or conflicts based on the volume and urgency of plans.\n",
        "         - Provide specific, actionable scheduling and resource allocation suggestions.\n",
        "         - Highlight critical issues requiring immediate human escalation based on the presence of critical problems, urgent/overdue plans, treatment delays, or critical patient status.\n",
        "         - Incorporate knowledge of standard oncology workflows (e.g., biopsy results needed before staging, staging needed before treatment planning, target treatment start dates).\n",
        "\n",
        "         Consider the following inputs:\n",
        "         Critical Problems: {critical_problems_json}\n",
        "         Urgent Care Plans: {urgent_plans_json}\n",
        "         Overdue/Delayed Care Plans: {overdue_plans_json}\n",
        "         All Final Problems: {all_problems_json}\n",
        "         All Final Care Plans: {all_plans_json}\n",
        "         Treatment Timeline: {treatment_tracker_json}\n",
        "         Current Date: {current_date}\n",
        "         Existing Alerts/Recommendations (from previous agents):\n",
        "         Priority Alerts: {existing_priority_alerts}\n",
        "         Workflow Alerts: {existing_workflow_alerts}\n",
        "\n",
        "         OUTPUT INSTRUCTIONS:\n",
        "         Provide the analysis and recommendations as a JSON object with the following keys:\n",
        "         - `priority_analysis_summary`: string (Overall summary of priority situation)\n",
        "         - `priority_alerts`: list of strings (Concise list of top priority alerts)\n",
        "         - `action_timeline`: list of strings (Prioritized list of recommended actions/plans in suggested order)\n",
        "         - `resource_conflicts`: list of strings (Identified potential resource issues)\n",
        "         - `scheduling_recommendations`: list of strings (Specific scheduling suggestions)\n",
        "         - `escalation_triggers`: list of strings (Reasons why human escalation is required)\n",
        "         - `priority_metrics`: dict (Quantifiable priority metrics, e.g., count of critical items)\n",
        "\n",
        "         Ensure the JSON is valid and contains ONLY the JSON object. Do not include any introductory or concluding text outside the JSON.\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Perform a comprehensive priority analysis for patient MRN: {mrn}.\n",
        "         Analyze the following data:\n",
        "         Critical Problems: {critical_problems_json}\n",
        "         Urgent Care Plans: {urgent_plans_json}\n",
        "         Overdue/Delayed Care Plans: {overdue_plans_json}\n",
        "         All Final Problems: {all_problems_json}\n",
        "         All Final Care Plans: {all_plans_json}\n",
        "         Treatment Timeline: {treatment_tracker_json}\n",
        "         Current Date: {current_date}\n",
        "         Existing Priority Alerts: {existing_priority_alerts_str}\n",
        "         Existing Workflow Alerts: {existing_workflow_alerts_str}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = priority_analysis_prompt | llm\n",
        "\n",
        "    priority_analysis_results: Dict[str, Any] = {}\n",
        "\n",
        "    try:\n",
        "        critical_problems_json = json.dumps([p.model_dump() for p in critical_problems], indent=2)\n",
        "        urgent_plans_json = json.dumps([cp.model_dump() for cp in urgent_plans], indent=2)\n",
        "        overdue_plans_json = json.dumps([cp.model_dump() for cp in overdue_plans], indent=2)\n",
        "        all_problems_json = json.dumps([p.model_dump() for p in state.final_problems], indent=2)\n",
        "        all_plans_json = json.dumps([cp.model_dump() for cp in state.final_care_plans], indent=2)\n",
        "        treatment_tracker_json = state.treatment_tracker.model_dump_json(indent=2) if state.treatment_tracker else \"{}\"\n",
        "        existing_priority_alerts_str = json.dumps(state.priority_alerts)\n",
        "        existing_workflow_alerts_str = json.dumps(state.workflow_alerts)\n",
        "\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"critical_problems_json\": critical_problems_json,\n",
        "            \"urgent_plans_json\": urgent_plans_json,\n",
        "            \"overdue_plans_json\": overdue_plans_json,\n",
        "            \"all_problems_json\": all_problems_json,\n",
        "            \"all_plans_json\": all_plans_json,\n",
        "            \"treatment_tracker_json\": treatment_tracker_json,\n",
        "            \"current_date\": current_date,\n",
        "            \"existing_priority_alerts_str\": existing_priority_alerts_str,\n",
        "            \"existing_workflow_alerts_str\": existing_workflow_alerts_str\n",
        "        })\n",
        "\n",
        "        logging.debug(f\"Raw LLM priority analysis response: {response.content}\")\n",
        "        llm_analysis_output = json.loads(response.content)\n",
        "\n",
        "        if not isinstance(llm_analysis_output, dict):\n",
        "             raise ValueError(\"Expected JSON object for priority analysis, but received a different structure.\")\n",
        "\n",
        "        priority_analysis_results = llm_analysis_output\n",
        "\n",
        "        # Update state with LLM's analysis and alerts\n",
        "        state.priority_analysis = priority_analysis_results\n",
        "\n",
        "        # Consolidate priority alerts (LLM output + internal rules)\n",
        "        state.priority_alerts = list(set(state.priority_alerts + priority_analysis_results.get(\"priority_alerts\", [])))\n",
        "\n",
        "        # Add actions and recommendations\n",
        "        state.action_recommendations.extend(priority_analysis_results.get(\"action_timeline\", []))\n",
        "        state.action_recommendations.extend(priority_analysis_results.get(\"scheduling_recommendations\", []))\n",
        "        # Add resource conflicts as warnings or separate field if needed\n",
        "        state.warnings.extend(priority_analysis_results.get(\"resource_conflicts\", []))\n",
        "\n",
        "        # Trigger final escalation based on LLM analysis\n",
        "        if priority_analysis_results.get(\"escalation_triggers\") or escalation_triggered:\n",
        "             state.priority_alerts.append(f\"FINAL ESCALATION TRIGGERED: Review escalation triggers: {priority_analysis_results.get('escalation_triggers', []) + [msg for msg in internal_priority_alerts if 'ESCALATION' in msg or 'IMMEDIATE ACTION' in msg]}\")\n",
        "             state.errors.append(\"Priority analysis indicates final escalation is required.\") # Critical issue\n",
        "\n",
        "\n",
        "        state.debug_logs.append(f\"priority_management_agent: LLM priority analysis completed. Escalation triggered: {escalation_triggered or bool(priority_analysis_results.get('escalation_triggers'))}\")\n",
        "        logging.info(\"LLM priority analysis completed.\")\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"priority_management_agent LLM JSON parsing error: {e}. Raw response: {response.content}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.priority_analysis = {\"error\": \"JSON parsing failed\", \"details\": str(e)}\n",
        "        logging.error(error_msg)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"priority_management_agent unexpected error during LLM analysis: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.priority_analysis = {\"error\": \"Unexpected error during analysis\", \"details\": str(e)}\n",
        "        logging.error(error_msg)\n",
        "\n",
        "\n",
        "    # =====================================================================\n",
        "    # 4. Final State Update and Routing\n",
        "    # =====================================================================\n",
        "    logging.info(\"priority_management_agent completed.\")\n",
        "    state.agent_history.append(\"priority_management_agent: Finished priority orchestration.\")\n",
        "\n",
        "    # Determine next step (routing will be handled by the graph)\n",
        "    state.current_agent = None # Reset current agent\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… priority_management_agent function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "895f8fa8"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from pydantic import ValidationError\n",
        "import datetime\n",
        "\n",
        "# Assuming get_llm, MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker, WorkflowCalculator are defined previously\n",
        "\n",
        "def medical_summary_agent(state: MedicalAgentState) -> MedicalAgentState:\n",
        "    \"\"\"\n",
        "    Agent that generates a comprehensive medical summary report.\n",
        "\n",
        "    Args:\n",
        "        state: The current MedicalAgentState.\n",
        "\n",
        "    Returns:\n",
        "        The updated MedicalAgentState with the generated medical summary.\n",
        "    \"\"\"\n",
        "    logging.info(\"Executing medical_summary_agent...\")\n",
        "    state.agent_history.append(\"medical_summary_agent: Generating comprehensive medical summary.\")\n",
        "    state.current_agent = \"medical_summary_agent\"\n",
        "\n",
        "    llm = get_llm()\n",
        "\n",
        "    # Categorize problems and plans for the summary\n",
        "    critical_problems = [p for p in state.final_problems if p.priority_flag == 'critical']\n",
        "    important_problems = [p for p in state.final_problems if p.priority_flag == 'important']\n",
        "    regular_problems = [p for p in state.final_problems if p.priority_flag == 'regular']\n",
        "\n",
        "    urgent_plans = [cp for cp in state.final_care_plans if cp.urgency_level == 'urgent']\n",
        "    non_urgent_plans = [cp for cp in state.final_care_plans if cp.urgency_level == 'non-urgent']\n",
        "\n",
        "    # Separate overdue/delayed urgent plans for immediate action section\n",
        "    urgent_overdue_plans = [cp for cp in urgent_plans if cp.workflow_status in [\"overdue\", \"delayed\"]]\n",
        "\n",
        "    # Separate urgent pending/in-progress plans for priority items section\n",
        "    urgent_pending_plans = [cp for cp in urgent_plans if cp.workflow_status in [\"pending\", \"in-progress\"]]\n",
        "\n",
        "    # Get treatment timeline status\n",
        "    treatment_timeline_status = state.treatment_tracker.get_timeline_status() if state.treatment_tracker else \"No oncology treatment timeline tracked.\"\n",
        "\n",
        "    # Prepare JSON data for the prompt\n",
        "    critical_problems_json = json.dumps([p.model_dump() for p in critical_problems], indent=2)\n",
        "    important_problems_json = json.dumps([p.model_dump() for p in important_problems], indent=2)\n",
        "    regular_problems_json = json.dumps([p.model_dump() for p in regular_problems], indent=2)\n",
        "    urgent_plans_json = json.dumps([cp.model_dump() for cp in urgent_plans], indent=2)\n",
        "    non_urgent_plans_json = json.dumps([cp.model_dump() for cp in non_urgent_plans], indent=2)\n",
        "    treatment_tracker_json = state.treatment_tracker.model_dump_json(indent=2) if state.treatment_tracker else \"{}\"\n",
        "\n",
        "    # Include workflow alerts and priority alerts from previous agents\n",
        "    workflow_alerts_str = \"\\n- \" + \"\\n- \".join(state.workflow_alerts) if state.workflow_alerts else \"None.\"\n",
        "    priority_alerts_str = \"\\n- \" + \"\\n- \".join(state.priority_alerts) if state.priority_alerts else \"None.\"\n",
        "    errors_str = \"\\n- \" + \"\\n- \".join(state.errors) if state.errors else \"None.\"\n",
        "    warnings_str = \"\\n- \" + \"\\n- \".join(state.warnings) if state.warnings else \"None.\"\n",
        "\n",
        "\n",
        "    # Define the summary prompt\n",
        "    summary_prompt = ChatPromptTemplate.from_messages([\n",
        "        (\"system\", \"\"\"You are a medical AI assistant specialized in generating comprehensive and actionable medical summary reports in markdown format.\n",
        "         Based on the provided extracted and analyzed medical problems, care plans, and treatment timeline data for patient MRN {mrn}, create a structured report.\n",
        "         The report should be easy to read and highlight key information for clinical staff.\n",
        "\n",
        "         REPORT SECTIONS:\n",
        "         # Patient Medical Summary - MRN: {mrn}\n",
        "         Note Date: {note_date}\n",
        "         Author: {note_author}\n",
        "         Clinical Note Snippet: {clinical_note_snippet}...\n",
        "\n",
        "         ## Problem List by Priority\n",
        "         (Categorize and list problems by Critical, Important, Regular)\n",
        "\n",
        "         ## Care Plans by Urgency & Status\n",
        "         (Categorize and list plans by Urgent, Non-Urgent, including their workflow_status and days_overdue)\n",
        "\n",
        "         ## Oncology Treatment Timeline\n",
        "         (Summarize treatment tracker status, highlighting key dates and delays. Mention KHCC workflow indicators if applicable.)\n",
        "         Treatment Target Date: {treatment_target_date}\n",
        "         Timeline Status: {timeline_status}\n",
        "\n",
        "         ## Action Items & Recommendations\n",
        "         (Provide a prioritized list of actions. Use the suggested action_recommendations from priority_management_agent if available. Ensure immediate actions are clearly highlighted.)\n",
        "\n",
        "         ### IMMEDIATE ACTION REQUIRED\n",
        "         (List critical problems and urgent, overdue/delayed care plans)\n",
        "\n",
        "         ### PRIORITY ITEMS\n",
        "         (List important problems and urgent, pending/in-progress care plans)\n",
        "\n",
        "         ### ROUTINE MANAGEMENT\n",
        "         (List regular problems and non-urgent care plans)\n",
        "\n",
        "         ## Alerts and Warnings\n",
        "         (List priority alerts, workflow alerts, errors, and warnings generated during processing)\n",
        "         Priority Alerts: {priority_alerts_str}\n",
        "         Workflow Alerts: {workflow_alerts_str}\n",
        "         Processing Errors: {errors_str}\n",
        "         Processing Warnings: {warnings_str}\n",
        "\n",
        "         ## System Processing Details\n",
        "         (Include processing mode, confidence score, and key metrics)\n",
        "         Processing Mode: {processing_mode}\n",
        "         Validation Confidence: {validation_confidence:.2f}\n",
        "         Total Problems Identified: {total_problems}\n",
        "         Total Care Plans Identified: {total_care_plans}\n",
        "         Iterations: {iterations}\n",
        "         Agent History: {agent_history}\n",
        "         Debug Logs (if DEBUG is True): {debug_logs_summary}\n",
        "\n",
        "         Ensure clear formatting using Markdown. Do not include any extraneous text outside the report structure.\n",
        "         \"\"\"),\n",
        "        (\"human\", \"\"\"Generate the comprehensive medical summary report in markdown format for patient MRN {mrn}.\n",
        "         Problems: {all_problems_json}\n",
        "         Care Plans: {all_plans_json}\n",
        "         Treatment Timeline: {treatment_tracker_json}\n",
        "         Processing State:\n",
        "         - Note Date: {note_date}\n",
        "         - Note Author: {note_author}\n",
        "         - Clinical Note Snippet: {clinical_note_snippet}\n",
        "         - Critical Problems: {critical_problems_json}\n",
        "         - Important Problems: {important_problems_json}\n",
        "         - Regular Problems: {regular_problems_json}\n",
        "         - Urgent Plans: {urgent_plans_json}\n",
        "         - Non-Urgent Plans: {non_urgent_plans_json}\n",
        "         - Treatment Target Date: {treatment_target_date}\n",
        "         - Timeline Status: {timeline_status}\n",
        "         - Action Recommendations: {action_recommendations}\n",
        "         - Priority Alerts: {priority_alerts_str}\n",
        "         - Workflow Alerts: {workflow_alerts_str}\n",
        "         - Errors: {errors_str}\n",
        "         - Warnings: {warnings_str}\n",
        "         - Processing Mode: {processing_mode}\n",
        "         - Validation Confidence: {validation_confidence}\n",
        "         - Total Problems: {total_problems}\n",
        "         - Total Care Plans: {total_care_plans}\n",
        "         - Iterations: {iterations}\n",
        "         - Agent History: {agent_history}\n",
        "         - Debug Logs Summary: {debug_logs_summary}\n",
        "         \"\"\")\n",
        "    ])\n",
        "\n",
        "    chain = summary_prompt | llm\n",
        "\n",
        "    medical_summary = None\n",
        "\n",
        "    try:\n",
        "        # Prepare inputs for the prompt\n",
        "        clinical_note_snippet = state.clinical_note[:500] + \"...\" if len(state.clinical_note) > 500 else state.clinical_note\n",
        "        treatment_target_date = state.treatment_tracker.date_should_start_treatment if state.treatment_tracker else \"N/A\"\n",
        "        debug_logs_summary = \"\\n- \" + \"\\n- \".join(state.debug_logs[-10:]) + \"...\" if len(state.debug_logs) > 0 else \"No debug logs.\" # Summarize debug logs\n",
        "\n",
        "        response = chain.invoke({\n",
        "            \"mrn\": state.patient_mrn,\n",
        "            \"note_date\": state.note_date,\n",
        "            \"note_author\": state.note_author,\n",
        "            \"clinical_note_snippet\": clinical_note_snippet,\n",
        "            \"all_problems_json\": json.dumps([p.model_dump() for p in state.final_problems], indent=2),\n",
        "            \"all_plans_json\": json.dumps([cp.model_dump() for cp in state.final_care_plans], indent=2),\n",
        "            \"treatment_tracker_json\": treatment_tracker_json,\n",
        "            \"critical_problems_json\": critical_problems_json,\n",
        "            \"important_problems_json\": important_problems_json,\n",
        "            \"regular_problems_json\": regular_problems_json,\n",
        "            \"urgent_plans_json\": urgent_plans_json,\n",
        "            \"non_urgent_plans_json\": non_urgent_plans_json,\n",
        "            \"treatment_target_date\": treatment_target_date,\n",
        "            \"timeline_status\": treatment_timeline_status,\n",
        "            \"action_recommendations\": state.action_recommendations,\n",
        "            \"priority_alerts_str\": priority_alerts_str,\n",
        "            \"workflow_alerts_str\": workflow_alerts_str,\n",
        "            \"errors_str\": errors_str,\n",
        "            \"warnings_str\": warnings_str,\n",
        "            \"processing_mode\": state.processing_mode,\n",
        "            \"validation_confidence\": state.validation_confidence,\n",
        "            \"total_problems\": len(state.final_problems),\n",
        "            \"total_care_plans\": len(state.final_care_plans),\n",
        "            \"iterations\": state.iterations,\n",
        "            \"agent_history\": state.agent_history,\n",
        "            \"debug_logs_summary\": debug_logs_summary\n",
        "        })\n",
        "\n",
        "        medical_summary = response.content\n",
        "        state.final_medical_summary = medical_summary\n",
        "        state.debug_logs.append(\"medical_summary_agent: Successfully generated medical summary.\")\n",
        "        logging.info(\"Successfully generated medical summary.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"medical_summary_agent unexpected error during summary generation: {e}\"\n",
        "        state.errors.append(error_msg)\n",
        "        state.final_medical_summary = f\"Error generating medical summary: {e}\"\n",
        "        logging.error(error_msg)\n",
        "\n",
        "\n",
        "    # Final State Update and Routing\n",
        "    state.processing_end_time = datetime.datetime.now().isoformat()\n",
        "    state.is_complete = True # Processing is now complete\n",
        "    state.current_step = \"end\" # Indicate the final step\n",
        "    state.current_agent = \"medical_summary_agent\" # Mark as the last agent\n",
        "\n",
        "    logging.info(\"medical_summary_agent completed.\")\n",
        "    state.agent_history.append(\"medical_summary_agent: Finished summary generation. Processing complete.\")\n",
        "\n",
        "    return state\n",
        "\n",
        "print(\"âœ… medical_summary_agent function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "653e93b0"
      },
      "source": [
        "import logging\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "# Assuming all agent functions (start_agent, problem_extraction_agent, etc.)\n",
        "# and the MedicalAgentState are defined in previous cells.\n",
        "\n",
        "def should_retry_extraction(state: MedicalAgentState) -> Literal[\"extract_problems\", \"analyze_problems\", \"end\"]:\n",
        "    \"\"\"\n",
        "    Conditional edge to decide whether to retry extraction or proceed.\n",
        "    Retries if validation failed and extraction attempts are below max.\n",
        "    Otherwise, proceeds to analysis or ends if max attempts reached.\n",
        "    \"\"\"\n",
        "    logging.info(\"Checking if extraction retry is needed...\")\n",
        "    if state.validation_results and not state.validation_results.get(\"is_valid\", True):\n",
        "        if state.extraction_attempts < state.max_extraction_attempts:\n",
        "            state.debug_logs.append(f\"Validation failed (Attempt {state.extraction_attempts}/{state.max_extraction_attempts}). Retrying extraction.\")\n",
        "            logging.warning(f\"Validation failed. Retrying extraction (Attempt {state.extraction_attempts}/{state.max_extraction_attempts}).\")\n",
        "            return \"extract_problems\" # Loop back to extraction\n",
        "        else:\n",
        "            state.debug_logs.append(f\"Validation failed. Max extraction attempts ({state.max_extraction_attempts}) reached. Proceeding to analysis with potential issues.\")\n",
        "            logging.error(\"Max extraction attempts reached. Proceeding despite validation issues.\")\n",
        "            return \"analyze_problems\" # Proceed to analysis despite errors\n",
        "    else:\n",
        "        state.debug_logs.append(\"Validation successful or no extraction issues detected. Proceeding to analysis.\")\n",
        "        logging.info(\"Validation successful. Proceeding to analysis.\")\n",
        "        return \"analyze_problems\" # Validation passed, proceed\n",
        "\n",
        "\n",
        "def build_medical_workflow_graph():\n",
        "    \"\"\"\n",
        "    Builds and compiles the LangGraph StateGraph for the medical workflow.\n",
        "    \"\"\"\n",
        "    logging.info(\"Building medical workflow graph...\")\n",
        "\n",
        "    workflow = StateGraph(MedicalAgentState)\n",
        "\n",
        "    # Define the nodes\n",
        "    workflow.add_node(\"start\", start_agent)\n",
        "    workflow.add_node(\"extract_problems\", problem_extraction_agent)\n",
        "    workflow.add_node(\"extract_care_plans\", care_plan_extraction_agent)\n",
        "    workflow.add_node(\"update_timeline\", treatment_timeline_agent)\n",
        "    workflow.add_node(\"validate\", medical_validator_agent)\n",
        "    workflow.add_node(\"analyze_problems\", problem_analyzer_agent)\n",
        "    workflow.add_node(\"manage_workflow\", care_plan_workflow_agent)\n",
        "    workflow.add_node(\"manage_priorities\", priority_management_agent)\n",
        "    workflow.add_node(\"generate_summary\", medical_summary_agent)\n",
        "    # Assuming an error handling node might be added later, but for now errors are logged in state\n",
        "\n",
        "    # Set the entry point\n",
        "    workflow.set_entry_point(\"start\")\n",
        "\n",
        "    # Add edges\n",
        "    workflow.add_edge(\"start\", \"extract_problems\")\n",
        "    workflow.add_edge(\"extract_problems\", \"extract_care_plans\")\n",
        "    workflow.add_edge(\"extract_care_plans\", \"update_timeline\")\n",
        "    workflow.add_edge(\"update_timeline\", \"validate\")\n",
        "\n",
        "    # Conditional edge after validation\n",
        "    workflow.add_conditional_edges(\n",
        "        \"validate\",\n",
        "        should_retry_extraction,\n",
        "        {\n",
        "            \"extract_problems\": \"extract_problems\", # Loop back to extraction\n",
        "            \"analyze_problems\": \"analyze_problems\", # Proceed to problem analysis\n",
        "            \"end\": END # Option to end if validation is critically bad and cannot proceed\n",
        "        }\n",
        "    )\n",
        "\n",
        "    workflow.add_edge(\"analyze_problems\", \"manage_workflow\")\n",
        "    workflow.add_edge(\"manage_workflow\", \"manage_priorities\")\n",
        "    workflow.add_edge(\"manage_priorities\", \"generate_summary\")\n",
        "\n",
        "    # Set the finish point\n",
        "    workflow.add_edge(\"generate_summary\", END)\n",
        "\n",
        "    # Compile the graph\n",
        "    app = workflow.compile()\n",
        "\n",
        "    logging.info(\"Medical workflow graph built and compiled.\")\n",
        "    return app\n",
        "\n",
        "print(\"âœ… build_medical_workflow_graph function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c354bcff"
      },
      "source": [
        "import logging\n",
        "import json\n",
        "from typing import List, Dict, Any, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "import datetime\n",
        "\n",
        "# Assuming MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker,\n",
        "# and build_medical_workflow_graph are defined in previous cells.\n",
        "\n",
        "def process_medical_workflow(\n",
        "    clinical_note: str,\n",
        "    patient_mrn: str,\n",
        "    previous_problems: List[MedicalProblem] = None, # Use None as default and convert to []\n",
        "    previous_care_plans: List[CarePlan] = None, # Use None as default and convert to []\n",
        "    treatment_tracker: Optional[PatientTreatmentTracker] = None,\n",
        "    processing_mode: str = \"comprehensive\",\n",
        "    note_author: str = \"System\", # Default author\n",
        "    note_date: str = None # Default to today if None\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Initializes state, executes the medical workflow graph, and processes results.\n",
        "\n",
        "    Args:\n",
        "        clinical_note: The clinical note text to process.\n",
        "        patient_mrn: The patient's medical record number.\n",
        "        previous_problems: Optional list of existing medical problems.\n",
        "        previous_care_plans: Optional list of existing care plans.\n",
        "        treatment_tracker: Optional existing patient treatment tracker.\n",
        "        processing_mode: The desired processing mode (\"quick\", \"comprehensive\", etc.).\n",
        "        note_author: The author of the clinical note.\n",
        "        note_date: The date of the clinical note (YYYY-MM-DD). Defaults to today.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing extracted, analyzed, and summarized medical information,\n",
        "        along with processing metrics, alerts, and errors.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Starting medical workflow process for MRN: {patient_mrn}, Mode: {processing_mode}\")\n",
        "\n",
        "    # Handle None defaults for mutable arguments\n",
        "    previous_problems = previous_problems if previous_problems is not None else []\n",
        "    previous_care_plans = previous_care_plans if previous_care_plans is not None else []\n",
        "    note_date = note_date if note_date is not None else datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Initialize the MedicalAgentState\n",
        "    initial_state = MedicalAgentState(\n",
        "        clinical_note=clinical_note,\n",
        "        patient_mrn=patient_mrn,\n",
        "        previous_problems=previous_problems,\n",
        "        previous_care_plans=previous_care_plans,\n",
        "        treatment_tracker=treatment_tracker,\n",
        "        processing_mode=processing_mode,\n",
        "        note_author=note_author,\n",
        "        note_date=note_date,\n",
        "        processing_start_time=datetime.datetime.now().isoformat(), # Set initial timestamp\n",
        "        agent_history=[\"System: Workflow initialized.\"] # Add initial history entry\n",
        "    )\n",
        "    logging.debug(\"Initial MedicalAgentState created.\")\n",
        "\n",
        "    try:\n",
        "        # Build and compile the graph (assuming this is already defined)\n",
        "        graph = build_medical_workflow_graph()\n",
        "        logging.debug(\"Medical workflow graph built.\")\n",
        "\n",
        "        # Execute the graph\n",
        "        logging.info(\"Invoking medical workflow graph...\")\n",
        "        final_state_dict = graph.invoke(initial_state.model_dump()) # Invoke with dictionary representation\n",
        "        logging.info(\"Medical workflow graph execution completed.\")\n",
        "\n",
        "        # Convert the final state dictionary back to MedicalAgentState for easier access\n",
        "        # Handle potential errors during graph execution that might leave state incomplete\n",
        "        try:\n",
        "            final_state = MedicalAgentState(**final_state_dict)\n",
        "            logging.debug(\"Final state converted back to MedicalAgentState.\")\n",
        "        except ValidationError as e:\n",
        "             error_msg = f\"Error validating final state after graph execution: {e}\"\n",
        "             logging.error(error_msg)\n",
        "             # If validation fails, use the dictionary representation and add an error\n",
        "             final_state = final_state_dict\n",
        "             if 'errors' in final_state and isinstance(final_state['errors'], list):\n",
        "                  final_state['errors'].append(error_msg)\n",
        "             else:\n",
        "                  final_state['errors'] = [error_msg]\n",
        "             final_state['final_medical_summary'] = \"Error processing workflow.\" # Indicate failure in summary\n",
        "\n",
        "        # =====================================================================\n",
        "        # Process and Format Results\n",
        "        # =====================================================================\n",
        "        results: Dict[str, Any] = {}\n",
        "\n",
        "        # Extract relevant data from the final state\n",
        "        results[\"extracted_problems\"] = final_state.extracted_problems if hasattr(final_state, 'extracted_problems') else []\n",
        "        results[\"extracted_care_plans\"] = final_state.extracted_care_plans if hasattr(final_state, 'extracted_care_plans') else []\n",
        "        results[\"final_problems\"] = final_state.final_problems if hasattr(final_state, 'final_problems') else []\n",
        "        results[\"final_care_plans\"] = final_state.final_care_plans if hasattr(final_state, 'final_care_plans') else []\n",
        "        results[\"treatment_timeline\"] = final_state.treatment_tracker.model_dump() if hasattr(final_state, 'treatment_tracker') and final_state.treatment_tracker else None\n",
        "        results[\"priority_alerts\"] = final_state.priority_alerts if hasattr(final_state, 'priority_alerts') else []\n",
        "        results[\"workflow_alerts\"] = final_state.workflow_alerts if hasattr(final_state, 'workflow_alerts') else []\n",
        "        results[\"medical_summary\"] = final_state.final_medical_summary if hasattr(final_state, 'final_medical_summary') else \"Summary not generated.\"\n",
        "        results[\"processing_metrics\"] = final_state.processing_metrics if hasattr(final_state, 'processing_metrics') else {}\n",
        "        results[\"validation_results\"] = final_state.validation_results if hasattr(final_state, 'validation_results') else None\n",
        "        results[\"validation_confidence\"] = final_state.validation_confidence if hasattr(final_state, 'validation_confidence') else 0.0\n",
        "        results[\"errors\"] = final_state.errors if hasattr(final_state, 'errors') else []\n",
        "        results[\"warnings\"] = final_state.warnings if hasattr(final_state, 'warnings') else []\n",
        "        results[\"agent_history\"] = final_state.agent_history if hasattr(final_state, 'agent_history') else []\n",
        "        results[\"debug_logs\"] = final_state.debug_logs if hasattr(final_state, 'debug_logs') else []\n",
        "        results[\"is_complete\"] = final_state.is_complete if hasattr(final_state, 'is_complete') else False\n",
        "        results[\"final_status\"] = \"Completed\" if results[\"is_complete\"] and not results[\"errors\"] else \"Completed with Errors\" if results[\"errors\"] else \"Processing Incomplete\"\n",
        "\n",
        "\n",
        "        logging.info(f\"Medical workflow process finished for MRN: {patient_mrn}. Status: {results['final_status']}\")\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"An unexpected error occurred during medical workflow processing: {e}\"\n",
        "        logging.error(error_msg, exc_info=True) # Log the full traceback\n",
        "\n",
        "        # Return an error state if an exception occurs before final state can be fully processed\n",
        "        return {\n",
        "            \"extracted_problems\": [],\n",
        "            \"extracted_care_plans\": [],\n",
        "            \"final_problems\": [],\n",
        "            \"final_care_plans\": [],\n",
        "            \"treatment_timeline\": None,\n",
        "            \"priority_alerts\": [f\"Critical System Error: {e}\"],\n",
        "            \"workflow_alerts\": [],\n",
        "            \"medical_summary\": f\"Critical error during processing: {e}\",\n",
        "            \"processing_metrics\": {\"status\": \"Failed\", \"error_type\": type(e).__name__},\n",
        "            \"validation_results\": None,\n",
        "            \"validation_confidence\": 0.0,\n",
        "            \"errors\": initial_state.errors + [error_msg], # Include errors accumulated in state before crash\n",
        "            \"warnings\": initial_state.warnings, # Include warnings\n",
        "            \"agent_history\": initial_state.agent_history + [f\"System: Workflow failed due to exception: {e}\"],\n",
        "            \"debug_logs\": initial_state.debug_logs,\n",
        "            \"is_complete\": True, # Mark as complete (failed)\n",
        "            \"final_status\": \"Failed\"\n",
        "        }\n",
        "\n",
        "print(\"âœ… process_medical_workflow function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c64c912"
      },
      "source": [
        "# Task\n",
        "Generate comprehensive medical_testing_suite(test_scenarios: Optional[Dict] = None) -> Dict[str, Any] for validating multi-agent medical workflows. Create test scenarios: oncology_new_patient = {\"clinical_note\": \"New breast cancer diagnosis, stage II, patient anxious about treatment\", \"patient_mrn\": \"ONC001\", \"expected_problems\": [{\"name\": \"Stage II Breast Cancer\", \"priority\": \"critical\", \"cancer_related\": True}], \"expected_care_plans\": [{\"plan\": \"Schedule staging scans\", \"urgency\": \"urgent\"}], \"expected_treatment_tracker\": {\"patient_status\": \"new\", \"days_remaining\": 30}}, treatment_delay_emergency = {\"clinical_note\": \"Patient with treatment delay, concerning progression\", \"existing_tracker\": {\"days_remaining_or_delayed\": 45}, \"expected_mode\": \"emergency\", \"expected_alerts\": [\"critical treatment delay\"]}, complex_oncology_case = {\"clinical_note\": \"Cancer patient with multiple complications: neuropathy, fatigue, anxiety\", \"previous_problems\": [existing_cancer_problem], \"expected_merging\": \"duplicate detection\", \"expected_priority_escalation\": True}. Include medical accuracy validation: verify cancer-related flags, treatment timeline compliance, priority classification correctness, workflow status calculations. Add performance benchmarks: extraction_time_ms < 10000, validation_accuracy > 0.90, treatment_timeline_accuracy > 0.95. Create mock data generators: generate_oncology_problems(cancer_type: str, stage: str), generate_treatment_plans(urgency: str, action_type: str), create_clinical_scenarios(patient_type: Literal[\"new\", \"relapsed\", \"regular\"]). Implement KHCC workflow validation: 30-day treatment targets, pathology repeat detection, radiology timeline compliance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d50cbda7"
      },
      "source": [
        "## Define test scenarios\n",
        "\n",
        "### Subtask:\n",
        "Create specific test case data structures for different medical scenarios (e.g., new oncology patient, treatment delay, complex case).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dc906a5"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the test_scenarios dictionary with the specified structure for different medical cases.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28b0f926"
      },
      "source": [
        "**Reasoning**:\n",
        "Correct the `patient_status` value in the `treatment_tracker` for the `treatment_delay_emergency` test case to use a valid literal from the `PatientTreatmentTracker` model definition, as indicated by the validation error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7808jg96PnV"
      },
      "source": [
        "import datetime\n",
        "\n",
        "# Create a placeholder mock MedicalProblem for the complex_oncology_case scenario\n",
        "# In a real test suite, this would be generated by a mock data function\n",
        "mock_existing_cancer_problem = MedicalProblem(\n",
        "    problem_name=\"Existing Stage III Lung Cancer\",\n",
        "    patient_mrn=\"CPLX003\",\n",
        "    priority_flag=\"important\",\n",
        "    is_cancer_related=True,\n",
        "    date_identified=\"2024-05-01\",\n",
        "    last_updated=\"2024-05-01\"\n",
        ")\n",
        "\n",
        "# Create specific test case data structures\n",
        "test_scenarios = {\n",
        "    \"oncology_new_patient\": {\n",
        "        \"clinical_note\": \"New breast cancer diagnosis, stage II, patient anxious about treatment. Biopsy planned for 2025-10-01.\",\n",
        "        \"patient_mrn\": \"ONC001\",\n",
        "        \"note_date\": \"2025-09-01\", # Add note date for context\n",
        "        \"expected_problems\": [\n",
        "            {\"problem_name\": \"Stage II Breast Cancer\", \"priority_flag\": \"critical\", \"is_cancer_related\": True}\n",
        "        ],\n",
        "        \"expected_care_plans\": [\n",
        "            {\"suggested_plan\": \"Schedule staging scans\", \"urgency_level\": \"urgent\"},\n",
        "            {\"suggested_plan\": \"Biopsy planned\", \"date_due\": \"2025-10-01\", \"action_type\": \"procedure\"} # More specific expected plan\n",
        "        ],\n",
        "        \"expected_treatment_tracker\": {\n",
        "            \"patient_status\": \"new\",\n",
        "            \"date_first_visit\": \"2025-09-01\", # Expected from note_date\n",
        "            \"date_should_start_treatment\": (datetime.datetime.strptime(\"2025-09-01\", \"%Y-%m-%d\") + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\"), # Expected 30 days out\n",
        "            \"date_biopsy_planned\": \"2025-10-01\" # Expected from note\n",
        "        },\n",
        "        \"expected_mode\": \"comprehensive\", # Expect comprehensive for new cancer patient\n",
        "        \"expected_alerts\": [] # No immediate critical alerts expected initially\n",
        "    },\n",
        "    \"treatment_delay_emergency\": {\n",
        "        \"clinical_note\": \"Patient with significant treatment delay, concerning progression noted on recent scan.\",\n",
        "        \"patient_mrn\": \"DELAY002\",\n",
        "         \"note_date\": \"2025-09-01\",\n",
        "        \"previous_care_plans\": [ # Add a previous urgent plan that is now overdue\n",
        "            CarePlan(\n",
        "                suggested_plan=\"Initiate chemotherapy\",\n",
        "                mrn=\"DELAY002\",\n",
        "                urgency_level=\"urgent\",\n",
        "                workflow_status=\"pending\", # Was pending\n",
        "                date_due=\"2025-08-01\", # Was due last month\n",
        "                date_initiated=None,\n",
        "                patient_status=\"stable\",\n",
        "                action_type=\"treatment\"\n",
        "            )\n",
        "        ],\n",
        "        \"treatment_tracker\": PatientTreatmentTracker( # Provide an existing tracker indicating delay\n",
        "            patient_mrn=\"DELAY002\",\n",
        "            date_first_visit=\"2025-06-01\",\n",
        "            date_should_start_treatment=\"2025-07-01\",\n",
        "            date_first_therapy_started=None,\n",
        "            patient_status=\"regular\", # Corrected to a valid literal for PatientTreatmentTracker\n",
        "            days_remaining_or_delayed=0 # Will be calculated by agent based on note_date vs target\n",
        "        ),\n",
        "        \"expected_mode\": \"emergency\",\n",
        "        \"expected_alerts\": [\"CRITICAL Workflow Delay:\", \"Treatment Delay Alert:\"] # Expect alerts related to delay and patient status\n",
        "    },\n",
        "    \"complex_oncology_case\": {\n",
        "        \"clinical_note\": \"Follow-up for Lung Cancer. Patient reports new onset neuropathy (likely chemo-related) and persistent fatigue. Also discussed anxiety management.\",\n",
        "        \"patient_mrn\": \"CPLX003\",\n",
        "        \"note_date\": \"2025-09-01\",\n",
        "        \"previous_problems\": [mock_existing_cancer_problem], # Include the mock existing problem\n",
        "        \"expected_problems\": [ # Expected problems after processing, including potential merges\n",
        "            {\"problem_name\": \"Stage III Lung Cancer\", \"priority_flag\": \"important\", \"is_cancer_related\": True}, # Existing problem kept/updated\n",
        "            {\"problem_name\": \"Chemotherapy-induced Neuropathy\", \"priority_flag\": \"important\", \"is_treatment_related\": True}, # New problem\n",
        "            {\"problem_name\": \"Fatigue\", \"priority_flag\": \"regular\"}, # New problem\n",
        "            {\"problem_name\": \"Anxiety\", \"priority_flag\": \"regular\", \"is_psychosocial\": True} # New problem\n",
        "        ],\n",
        "        \"expected_care_plans\": [\n",
        "             {\"suggested_plan\": \"Manage Neuropathy symptoms\", \"action_type\": \"treatment\"},\n",
        "             {\"suggested_plan\": \"Assess Fatigue\", \"action_type\": \"diagnostic\"},\n",
        "             {\"suggested_plan\": \"Consult Psychology for anxiety\", \"action_type\": \"consultation\"}\n",
        "        ],\n",
        "        \"expected_merging\": \"duplicate detection\", # Expect problem merging logic to run\n",
        "        \"expected_priority_escalation\": True, # Expect escalation due to multiple complications/psychosocial issues\n",
        "        \"expected_mode\": \"comprehensive\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Test scenarios defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d83e137"
      },
      "source": [
        "## Create mock data generators\n",
        "\n",
        "### Subtask:\n",
        "Implement functions to generate mock `MedicalProblem`, `CarePlan`, and `PatientTreatmentTracker` data for testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72c926be"
      },
      "source": [
        "**Reasoning**:\n",
        "Define functions to generate mock `MedicalProblem`, `CarePlan`, and `PatientTreatmentTracker` objects as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "544b5bc7"
      },
      "source": [
        "import datetime\n",
        "import uuid\n",
        "from typing import List, Dict, Any, Optional, Literal\n",
        "\n",
        "# Assuming MedicalProblem, CarePlan, PatientTreatmentTracker, PriorityClassifier, WorkflowCalculator are defined in previous cells\n",
        "\n",
        "def generate_oncology_problems(cancer_type: str, stage: str, mrn: str, note_date: str) -> List[MedicalProblem]:\n",
        "    \"\"\"\n",
        "    Generates mock MedicalProblem objects for an oncology patient.\n",
        "    \"\"\"\n",
        "    problems: List[MedicalProblem] = []\n",
        "\n",
        "    # Basic Cancer Diagnosis Problem\n",
        "    problems.append(MedicalProblem(\n",
        "        problem_name=f\"{stage} {cancer_type} Cancer\",\n",
        "        patient_mrn=mrn,\n",
        "        status=\"Active\",\n",
        "        priority_flag=\"critical\", # Cancer diagnosis is typically critical or important\n",
        "        severity_level=\"severe\" if \"IV\" in stage or \"metastatic\" in stage.lower() else \"moderate\",\n",
        "        is_cancer_related=True,\n",
        "        evidence=f\"Confirmed diagnosis of {stage} {cancer_type} cancer.\",\n",
        "        date_identified=note_date,\n",
        "        last_updated=note_date,\n",
        "        note_source=\"mock_generator\"\n",
        "    ))\n",
        "\n",
        "    # Potential related problems (examples)\n",
        "    if \"Lung\" in cancer_type:\n",
        "        problems.append(MedicalProblem(\n",
        "            problem_name=\"Shortness of Breath\",\n",
        "            patient_mrn=mrn,\n",
        "            status=\"Active\",\n",
        "            priority_flag=\"important\",\n",
        "            is_cancer_related=True,\n",
        "            evidence=\"Patient reported dyspnea.\",\n",
        "            date_identified=note_date,\n",
        "            last_updated=note_date,\n",
        "            note_source=\"mock_generator\"\n",
        "        ))\n",
        "    if \"Breast\" in cancer_type:\n",
        "         problems.append(MedicalProblem(\n",
        "            problem_name=\"Breast Mass\",\n",
        "            patient_mrn=mrn,\n",
        "            status=\"Inactive\", # Assuming mass led to diagnosis, now less of a problem itself\n",
        "            priority_flag=\"regular\",\n",
        "            is_cancer_related=True,\n",
        "            evidence=\"Initial finding.\",\n",
        "            date_identified=\"YYYY-MM-DD_prior\", # Placeholder for a prior date\n",
        "            last_updated=note_date,\n",
        "            note_source=\"mock_generator\"\n",
        "        ))\n",
        "\n",
        "\n",
        "    # Add a psychosocial problem\n",
        "    problems.append(MedicalProblem(\n",
        "        problem_name=\"Anxiety related to diagnosis\",\n",
        "        patient_mrn=mrn,\n",
        "        status=\"Active\",\n",
        "        priority_flag=\"regular\",\n",
        "        is_psychosocial=True,\n",
        "        evidence=\"Patient expressed concerns about treatment.\",\n",
        "        date_identified=note_date,\n",
        "        last_updated=note_date,\n",
        "        note_source=\"mock_generator\"\n",
        "    ))\n",
        "\n",
        "\n",
        "    # Use PriorityClassifier to ensure priority is set correctly\n",
        "    for problem in problems:\n",
        "         problem.priority_flag = PriorityClassifier.classify_problem_priority(\n",
        "             problem_name=problem.problem_name,\n",
        "             clinical_context=f\"Patient has {cancer_type} cancer, stage {stage}.\", # Provide some context\n",
        "             # patient_status could be added here if needed\n",
        "         )\n",
        "\n",
        "    return problems\n",
        "\n",
        "def generate_treatment_plans(\n",
        "    urgency: Literal[\"urgent\", \"non-urgent\"],\n",
        "    action_type: Literal[\"diagnostic\", \"treatment\", \"consultation\", \"follow-up\", \"monitoring\", \"medication\", \"procedure\"],\n",
        "    mrn: str,\n",
        "    note_date: str,\n",
        "    count: int = 1,\n",
        "    status: Literal[\"pending\", \"delayed\", \"overdue\", \"in-progress\", \"completed\", \"cancelled\"] = \"pending\", # Allow setting initial status\n",
        "    days_offset_due: int = None # Offset due date from note_date in days\n",
        ") -> List[CarePlan]:\n",
        "    \"\"\"\n",
        "    Generates mock CarePlan objects.\n",
        "    \"\"\"\n",
        "    plans: List[CarePlan] = []\n",
        "    base_date = datetime.datetime.strptime(note_date, \"%Y-%m-%d\").date()\n",
        "\n",
        "    for i in range(count):\n",
        "        suggested_plan_desc = f\"Mock {action_type.capitalize()} Plan {i+1}\"\n",
        "        if action_type == \"diagnostic\":\n",
        "            suggested_plan_desc = f\"Schedule {urgency.capitalize()} Scan\"\n",
        "        elif action_type == \"treatment\":\n",
        "             suggested_plan_desc = f\"Initiate {urgency.capitalize()} Therapy\"\n",
        "        elif action_type == \"consultation\":\n",
        "             suggested_plan_desc = f\"Consult with {urgency.capitalize()} Specialist\"\n",
        "        elif action_type == \"follow-up\":\n",
        "             suggested_plan_desc = f\"Routine {urgency.capitalize()} Follow-up\"\n",
        "\n",
        "\n",
        "        # Determine due date\n",
        "        if days_offset_due is not None:\n",
        "             due_date_obj = base_date + datetime.timedelta(days=days_offset_due)\n",
        "             date_due_str = due_date_obj.strftime(\"%Y-%m-%d\")\n",
        "        else:\n",
        "            # Default due date based on urgency\n",
        "            if urgency == \"urgent\":\n",
        "                date_due_obj = base_date + datetime.timedelta(days=2) # Within 48 hours\n",
        "            else:\n",
        "                date_due_obj = base_date + datetime.timedelta(days=30) # Within a month\n",
        "            date_due_str = date_due_obj.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        # Calculate initial workflow status based on the generated due date and note date\n",
        "        initial_workflow_status, initial_days_overdue = WorkflowCalculator.calculate_workflow_status(\n",
        "            date_due=date_due_str,\n",
        "            current_date=note_date # Use note date as the \"current date\" for initial status\n",
        "        )\n",
        "\n",
        "        plans.append(CarePlan(\n",
        "            suggested_plan=suggested_plan_desc,\n",
        "            mrn=mrn,\n",
        "            urgency_level=urgency,\n",
        "            date_due=date_due_str,\n",
        "            action_type=action_type,\n",
        "            workflow_status=status if status != \"pending\" else initial_workflow_status, # Use provided status or initial calculated\n",
        "            days_overdue=initial_days_overdue, # Set initial overdue days\n",
        "            critical_finding= urgency == \"urgent\" and action_type in [\"diagnostic\", \"treatment\", \"procedure\"], # Simple rule\n",
        "            note_date=note_date,\n",
        "            note_author=\"Mock Generator\",\n",
        "            estimated_duration=\"Varies\"\n",
        "        ))\n",
        "\n",
        "    return plans\n",
        "\n",
        "\n",
        "def create_clinical_scenarios(\n",
        "    patient_type: Literal[\"new\", \"relapsed\", \"regular\"],\n",
        "    mrn: str,\n",
        "    note_date: str,\n",
        "    cancer_type: Optional[str] = None, # Allow specifying cancer type for oncology scenarios\n",
        "    stage: Optional[str] = None # Allow specifying stage\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Generates mock data for different clinical scenarios.\n",
        "    \"\"\"\n",
        "    previous_problems: List[MedicalProblem] = []\n",
        "    previous_care_plans: List[CarePlan] = []\n",
        "    treatment_tracker: Optional[PatientTreatmentTracker] = None\n",
        "\n",
        "    base_date_obj = datetime.datetime.strptime(note_date, \"%Y-%m-%d\").date()\n",
        "\n",
        "    if patient_type == \"new\" and cancer_type and stage:\n",
        "        # New oncology patient scenario\n",
        "        first_visit_date = (base_date_obj - datetime.timedelta(days=7)).strftime(\"%Y-%m-%d\") # Assume first visit was a week ago\n",
        "        target_treatment_date = (datetime.datetime.strptime(first_visit_date, \"%Y-%m-%d\") + datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        previous_problems = generate_oncology_problems(cancer_type, stage, mrn, first_visit_date) # Problems from first visit\n",
        "        previous_care_plans = generate_treatment_plans(\"urgent\", \"diagnostic\", mrn, first_visit_date, count=2, days_offset_due=7) # Initial urgent diagnostic plans\n",
        "\n",
        "        treatment_tracker = PatientTreatmentTracker(\n",
        "            patient_mrn=mrn,\n",
        "            date_first_visit=first_visit_date,\n",
        "            date_should_start_treatment=target_treatment_date,\n",
        "            patient_status=\"new\",\n",
        "            created_date=first_visit_date,\n",
        "            last_updated=note_date # Updated as of current note\n",
        "        )\n",
        "        # Update tracker status based on current note date\n",
        "        treatment_tracker.update_timeline_status(current_date=note_date)\n",
        "\n",
        "\n",
        "    elif patient_type == \"relapsed\" and cancer_type and stage:\n",
        "        # Relapsed oncology patient scenario\n",
        "        initial_visit_date = (base_date_obj - datetime.timedelta(days=365)).strftime(\"%Y-%m-%d\") # Assume initial visit was a year ago\n",
        "        relapse_date = (base_date_obj - datetime.timedelta(days=30)).strftime(\"%Y-%m-%d\") # Relapse detected a month ago\n",
        "        target_treatment_date = (datetime.datetime.strptime(relapse_date, \"%Y-%m-%d\") + datetime.timedelta(days=14)).strftime(\"%Y-%m-%d\") # Target treatment 2 weeks from relapse detection\n",
        "\n",
        "        # Previous problems including the initial diagnosis (now inactive) and relapse (active)\n",
        "        previous_problems.extend(generate_oncology_problems(cancer_type, \"Initial Stage\", mrn, initial_visit_date))\n",
        "        previous_problems[-1].status = \"Inactive\" # Mark initial diagnosis as inactive\n",
        "        previous_problems[-1].last_updated = relapse_date # Mark as inactive around relapse time\n",
        "\n",
        "        relapse_problem = MedicalProblem(\n",
        "            problem_name=f\"{cancer_type} Cancer Recurrence / Relapse ({stage})\",\n",
        "            patient_mrn=mrn,\n",
        "            status=\"Active\",\n",
        "            priority_flag=\"critical\", # Relapse is often critical\n",
        "            severity_level=\"severe\",\n",
        "            is_cancer_related=True,\n",
        "            evidence=\"Confirmed recurrence on scan/biopsy.\",\n",
        "            date_identified=relapse_date,\n",
        "            last_updated=note_date,\n",
        "            note_source=\"mock_generator\"\n",
        "        )\n",
        "        previous_problems.append(relapse_problem)\n",
        "\n",
        "\n",
        "        # Previous care plans including follow-ups and recent diagnostics/treatment plans for relapse\n",
        "        previous_care_plans.extend(generate_treatment_plans(\"non-urgent\", \"follow-up\", mrn, initial_visit_date, count=3, days_offset_due=90, status=\"completed\")) # Old follow-ups\n",
        "        previous_care_plans.extend(generate_treatment_plans(\"urgent\", \"diagnostic\", mrn, relapse_date, count=1, days_offset_due=7, status=\"completed\")) # Relapse diagnostic\n",
        "        previous_care_plans.extend(generate_treatment_plans(\"urgent\", \"treatment\", mrn, relapse_date, count=1, days_offset_due=14, status=\"pending\")) # Pending treatment plan\n",
        "\n",
        "        treatment_tracker = PatientTreatmentTracker(\n",
        "            patient_mrn=mrn,\n",
        "            date_first_visit=initial_visit_date,\n",
        "            date_should_start_treatment=target_treatment_date, # Target based on relapse date\n",
        "            patient_status=\"relapsed\",\n",
        "            created_date=initial_visit_date,\n",
        "            last_updated=note_date\n",
        "        )\n",
        "        treatment_tracker.update_timeline_status(current_date=note_date)\n",
        "\n",
        "\n",
        "    elif patient_type == \"regular\":\n",
        "        # Regular follow-up patient scenario (non-oncology focus or stable oncology)\n",
        "        initial_visit_date = (base_date_obj - datetime.timedelta(days=180)).strftime(\"%Y-%m-%d\") # 6 months ago\n",
        "\n",
        "        previous_problems.append(MedicalProblem(\n",
        "            problem_name=\"Hypertension\",\n",
        "            patient_mrn=mrn,\n",
        "            status=\"Active\",\n",
        "            priority_flag=\"regular\",\n",
        "            date_identified=initial_visit_date,\n",
        "            last_updated=note_date,\n",
        "             note_source=\"mock_generator\"\n",
        "        ))\n",
        "        previous_problems.append(MedicalProblem(\n",
        "            problem_name=\"Type 2 Diabetes\",\n",
        "            patient_mrn=mrn,\n",
        "            status=\"Active\",\n",
        "            priority_flag=\"important\",\n",
        "            date_identified=initial_visit_date,\n",
        "            last_updated=note_date,\n",
        "            note_source=\"mock_generator\"\n",
        "        ))\n",
        "\n",
        "        previous_care_plans.extend(generate_treatment_plans(\"non-urgent\", \"follow-up\", mrn, initial_visit_date, count=1, days_offset_due=180, status=\"pending\")) # Upcoming follow-up\n",
        "        previous_care_plans.extend(generate_treatment_plans(\"regular\", \"monitoring\", mrn, initial_visit_date, count=1, days_offset_due=30, status=\"completed\")) # Recent lab order (completed)\n",
        "\n",
        "        # No treatment tracker needed unless it's a stable oncology patient\n",
        "\n",
        "    else:\n",
        "        # Default or unknown scenario\n",
        "        pass # Return empty lists and None tracker\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"previous_problems\": previous_problems,\n",
        "        \"previous_care_plans\": previous_care_plans,\n",
        "        \"treatment_tracker\": treatment_tracker\n",
        "    }\n",
        "\n",
        "print(\"âœ… Mock data generation functions defined.\")\n",
        "\n",
        "# Example Usage (Optional - for testing the generators)\n",
        "# print(\"\\n--- Testing Mock Data Generators ---\")\n",
        "# mrn_test = \"TEST123\"\n",
        "# note_date_test = \"2025-10-01\"\n",
        "\n",
        "# print(\"\\nTesting generate_oncology_problems:\")\n",
        "# onc_problems = generate_oncology_problems(\"Lung\", \"Stage III\", mrn_test, note_date_test)\n",
        "# for p in onc_problems:\n",
        "#     print(f\"- Problem: {p.problem_name}, Priority: {p.priority_flag}, Cancer Related: {p.is_cancer_related}\")\n",
        "\n",
        "# print(\"\\nTesting generate_treatment_plans:\")\n",
        "# urgent_plans = generate_treatment_plans(\"urgent\", \"diagnostic\", mrn_test, note_date_test, count=2, days_offset_due=1)\n",
        "# for cp in urgent_plans:\n",
        "#      print(f\"- Plan: {cp.suggested_plan}, Urgency: {cp.urgency_level}, Due: {cp.date_due}, Status: {cp.workflow_status}\")\n",
        "\n",
        "# print(\"\\nTesting create_clinical_scenarios (New Oncology):\")\n",
        "# new_onc_scenario = create_clinical_scenarios(\"new\", \"NEWONC456\", \"2025-10-01\", cancer_type=\"Prostate\", stage=\"Stage I\")\n",
        "# print(f\"Generated {len(new_onc_scenario['previous_problems'])} previous problems and {len(new_onc_scenario['previous_care_plans'])} previous plans.\")\n",
        "# if new_onc_scenario['treatment_tracker']:\n",
        "#      print(f\"Treatment Tracker Status: {new_onc_scenario['treatment_tracker'].get_timeline_status()}\")\n",
        "\n",
        "# print(\"\\nTesting create_clinical_scenarios (Relapsed Oncology):\")\n",
        "# relapsed_onc_scenario = create_clinical_scenarios(\"relapsed\", \"RELAPSED789\", \"2025-10-01\", cancer_type=\"Ovarian\", stage=\"Stage IV\")\n",
        "# print(f\"Generated {len(relapsed_onc_scenario['previous_problems'])} previous problems and {len(relapsed_onc_scenario['previous_care_plans'])} previous plans.\")\n",
        "# if relapsed_onc_scenario['treatment_tracker']:\n",
        "#      print(f\"Treatment Tracker Status: {relapsed_onc_scenario['treatment_tracker'].get_timeline_status()}\")\n",
        "\n",
        "# print(\"\\nTesting create_clinical_scenarios (Regular):\")\n",
        "# regular_scenario = create_clinical_scenarios(\"regular\", \"REG101\", \"2025-10-01\")\n",
        "# print(f\"Generated {len(regular_scenario['previous_problems'])} previous problems and {len(regular_scenario['previous_care_plans'])} previous plans.\")\n",
        "# print(f\"Treatment Tracker: {regular_scenario['treatment_tracker']}\")\n",
        "\n",
        "# print(\"\\n--- Mock Data Generators Testing Complete ---\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14d466ca"
      },
      "source": [
        "## Implement scenario execution\n",
        "\n",
        "### Subtask:\n",
        "Create a function to run the `process_medical_workflow` with the inputs from each test scenario defined in `test_scenarios`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81ac27f5"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `execute_scenario` function to run the workflow for a single test scenario.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9166550f"
      },
      "source": [
        "import datetime\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "# Assuming process_medical_workflow, MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker are defined\n",
        "\n",
        "def execute_scenario(scenario: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the medical workflow for a single test scenario.\n",
        "\n",
        "    Args:\n",
        "        scenario: A dictionary containing the test scenario inputs and expectations.\n",
        "\n",
        "    Returns:\n",
        "        The results dictionary from the process_medical_workflow function.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Executing scenario: {scenario.get('description', 'Unnamed Scenario')}\")\n",
        "\n",
        "    # Extract inputs with defaults\n",
        "    clinical_note = scenario.get(\"clinical_note\", \"\")\n",
        "    patient_mrn = scenario.get(\"patient_mrn\", f\"MRN_{uuid.uuid4()}\") # Generate a unique MRN if not provided\n",
        "    # Handle previous data - use provided lists or generate mock data if scenario specifies patient_type\n",
        "    previous_problems = scenario.get(\"previous_problems\")\n",
        "    previous_care_plans = scenario.get(\"previous_care_plans\")\n",
        "    treatment_tracker = scenario.get(\"treatment_tracker\")\n",
        "\n",
        "    # If previous_problems/care_plans/treatment_tracker are not explicitly provided,\n",
        "    # check if the scenario includes 'patient_type' to generate mock history\n",
        "    if previous_problems is None or previous_care_plans is None or treatment_tracker is None:\n",
        "         patient_type = scenario.get(\"patient_type\")\n",
        "         if patient_type:\n",
        "              cancer_type = scenario.get(\"cancer_type\")\n",
        "              stage = scenario.get(\"stage\")\n",
        "              note_date_for_history = scenario.get(\"note_date\", datetime.datetime.now().strftime(\"%Y-%m-%d\")) # Use scenario note_date or today\n",
        "              logging.info(f\"Generating mock history for patient type: {patient_type}\")\n",
        "              mock_history = create_clinical_scenarios(\n",
        "                  patient_type=patient_type,\n",
        "                  mrn=patient_mrn,\n",
        "                  note_date=note_date_for_history,\n",
        "                  cancer_type=cancer_type,\n",
        "                  stage=stage\n",
        "              )\n",
        "              # Use generated mock data only if not explicitly provided in the scenario\n",
        "              previous_problems = previous_problems if previous_problems is not None else mock_history[\"previous_problems\"]\n",
        "              previous_care_plans = previous_care_plans if previous_care_plans is not None else mock_history[\"previous_care_plans\"]\n",
        "              treatment_tracker = treatment_tracker if treatment_tracker is not None else mock_history[\"treatment_tracker\"]\n",
        "         else:\n",
        "              # Default to empty lists and None tracker if no history generation specified\n",
        "              previous_problems = previous_problems if previous_problems is not None else []\n",
        "              previous_care_plans = previous_care_plans if previous_care_plans is not None else []\n",
        "              treatment_tracker = treatment_tracker if treatment_tracker is not None else None\n",
        "\n",
        "\n",
        "    processing_mode = scenario.get(\"processing_mode\", \"comprehensive\")\n",
        "    note_author = scenario.get(\"note_author\", \"Test System\")\n",
        "    note_date = scenario.get(\"note_date\", datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "    # Call the main workflow processing function\n",
        "    results = process_medical_workflow(\n",
        "        clinical_note=clinical_note,\n",
        "        patient_mrn=patient_mrn,\n",
        "        previous_problems=previous_problems,\n",
        "        previous_care_plans=previous_care_plans,\n",
        "        treatment_tracker=treatment_tracker,\n",
        "        processing_mode=processing_mode,\n",
        "        note_author=note_author,\n",
        "        note_date=note_date\n",
        "    )\n",
        "\n",
        "    logging.info(f\"Scenario execution complete for MRN: {patient_mrn}. Status: {results.get('final_status', 'Unknown')}\")\n",
        "    return results\n",
        "\n",
        "print(\"âœ… execute_scenario function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44f9d902"
      },
      "source": [
        "## Develop validation logic\n",
        "\n",
        "### Subtask:\n",
        "Implement functions to validate the output of `process_medical_workflow` against expected results for each scenario, including medical accuracy checks (flags, timelines, priorities, statuses).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "006126e2"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `validate_results` function to check the outputs of the workflow against the expected values defined in the scenario, including medical accuracy and processing mode checks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddb31fce"
      },
      "source": [
        "import logging\n",
        "from typing import Dict, Any, List, Optional\n",
        "from difflib import SequenceMatcher\n",
        "import datetime\n",
        "\n",
        "# Assuming MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker, WorkflowCalculator are defined\n",
        "\n",
        "def are_problems_similar(p1: MedicalProblem, p2_expected: Dict[str, Any], similarity_threshold: float = 0.8) -> bool:\n",
        "    \"\"\"Checks if a MedicalProblem object is similar to an expected problem dictionary.\"\"\"\n",
        "    # Check problem name similarity\n",
        "    name_similarity = SequenceMatcher(None, p1.problem_name.lower(), p2_expected.get(\"problem_name\", \"\").lower()).ratio()\n",
        "\n",
        "    if name_similarity < similarity_threshold:\n",
        "        return False\n",
        "\n",
        "    # Check key attributes if provided in expected\n",
        "    if \"priority_flag\" in p2_expected and p1.priority_flag != p2_expected[\"priority_flag\"]:\n",
        "        return False\n",
        "    if \"is_cancer_related\" in p2_expected and p1.is_cancer_related != p2_expected[\"is_cancer_related\"]:\n",
        "        return False\n",
        "    if \"is_treatment_related\" in p2_expected and p1.is_treatment_related != p2_expected[\"is_treatment_related\"]:\n",
        "        return False\n",
        "    if \"is_psychosocial\" in p2_expected and p1.is_psychosocial != p2_expected[\"is_psychosocial\"]:\n",
        "        return False\n",
        "    # Add other attribute checks as needed\n",
        "\n",
        "    return True\n",
        "\n",
        "def are_care_plans_similar(cp1: CarePlan, cp2_expected: Dict[str, Any], similarity_threshold: float = 0.7) -> bool:\n",
        "    \"\"\"Checks if a CarePlan object is similar to an expected care plan dictionary.\"\"\"\n",
        "    # Check suggested plan similarity\n",
        "    plan_similarity = SequenceMatcher(None, cp1.suggested_plan.lower(), cp2_expected.get(\"suggested_plan\", \"\").lower()).ratio()\n",
        "\n",
        "    if plan_similarity < similarity_threshold:\n",
        "        return False\n",
        "\n",
        "    # Check key attributes if provided in expected\n",
        "    if \"urgency_level\" in cp2_expected and cp1.urgency_level != cp2_expected[\"urgency_level\"]:\n",
        "        return False\n",
        "    if \"action_type\" in cp2_expected and cp1.action_type != cp2_expected[\"action_type\"]:\n",
        "        return False\n",
        "    if \"date_due\" in cp2_expected and cp1.date_due != cp2_expected[\"date_due\"]:\n",
        "         # Allow for some flexibility if date is estimated, but check format\n",
        "         try:\n",
        "              datetime.datetime.strptime(cp1.date_due, \"%Y-%m-%d\")\n",
        "              datetime.datetime.strptime(cp2_expected[\"date_due\"], \"%Y-%m-%d\")\n",
        "              # Consider adding tolerance for date differences if needed\n",
        "              if cp1.date_due != cp2_expected[\"date_due\"]:\n",
        "                   logging.debug(f\"Care plan date_due mismatch: Expected {cp2_expected['date_due']}, Got {cp1.date_due}\")\n",
        "                   # Decide if this is a hard fail or a warning based on test strictness\n",
        "                   # For now, treat as a mismatch if not exact\n",
        "                   return False\n",
        "         except ValueError:\n",
        "              logging.warning(f\"Invalid date format in care plan similarity check: cp1.date_due={cp1.date_due}, cp2_expected['date_due']={cp2_expected['date_due']}\")\n",
        "              return False # Treat invalid date format as not similar\n",
        "\n",
        "\n",
        "    # Check workflow status and overdue days if expected\n",
        "    if \"workflow_status\" in cp2_expected and cp1.workflow_status != cp2_expected[\"workflow_status\"]:\n",
        "        return False\n",
        "    # Checking days_overdue might be complex as it depends on current date vs note date\n",
        "    # A more robust test might involve setting a specific 'current_date' for validation\n",
        "    # if \"days_overdue\" in cp2_expected and cp1.days_overdue != cp2_expected[\"days_overdue\"]:\n",
        "    #     return False\n",
        "\n",
        "    # Add other attribute checks as needed\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def validate_results(scenario: Dict[str, Any], results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Validates the output of the medical workflow against expected results for a scenario.\n",
        "\n",
        "    Args:\n",
        "        scenario: The test scenario dictionary with inputs and expectations.\n",
        "        results: The results dictionary from process_medical_workflow.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary summarizing the validation outcome.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Validating results for scenario: {scenario.get('description', 'Unnamed Scenario')}\")\n",
        "    validation_outcome: Dict[str, Any] = {\n",
        "        \"scenario_name\": scenario.get('description', 'Unnamed Scenario'),\n",
        "        \"is_valid\": True,\n",
        "        \"issues\": [],\n",
        "        \"passed_checks\": [],\n",
        "        \"summary\": \"\"\n",
        "    }\n",
        "\n",
        "    # --- 1. Check Expected Problems ---\n",
        "    expected_problems = scenario.get(\"expected_problems\", [])\n",
        "    final_problems = results.get(\"final_problems\", [])\n",
        "    problems_matched = 0\n",
        "    for exp_p in expected_problems:\n",
        "        matched = False\n",
        "        for final_p in final_problems:\n",
        "            if are_problems_similar(final_p, exp_p):\n",
        "                problems_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Problem matched: Expected '{exp_p.get('problem_name', 'N/A')}', Got '{final_p.problem_name}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Expected problem not found or attributes mismatch: {exp_p.get('problem_name', 'N/A')} (Expected: {exp_p})\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "    if problems_matched == len(expected_problems):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_problems)} expected problems found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {problems_matched} of {len(expected_problems)} expected problems were matched.\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 2. Check Expected Care Plans ---\n",
        "    expected_care_plans = scenario.get(\"expected_care_plans\", [])\n",
        "    final_care_plans = results.get(\"final_care_plans\", [])\n",
        "    care_plans_matched = 0\n",
        "    for exp_cp in expected_care_plans:\n",
        "        matched = False\n",
        "        for final_cp in final_care_plans:\n",
        "            if are_care_plans_similar(final_cp, exp_cp):\n",
        "                care_plans_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Care Plan matched: Expected '{exp_cp.get('suggested_plan', 'N/A')}', Got '{final_cp.suggested_plan}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Expected care plan not found or attributes mismatch: {exp_cp.get('suggested_plan', 'N/A')} (Expected: {exp_cp})\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "    if care_plans_matched == len(expected_care_plans):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_care_plans)} expected care plans found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {care_plans_matched} of {len(expected_care_plans)} expected care plans were matched.\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 3. Check Expected Treatment Tracker State ---\n",
        "    expected_tracker = scenario.get(\"expected_treatment_tracker\")\n",
        "    actual_tracker = results.get(\"treatment_timeline\") # This is a dict\n",
        "    if expected_tracker:\n",
        "        if actual_tracker:\n",
        "            tracker_issues = []\n",
        "            for key, expected_value in expected_tracker.items():\n",
        "                actual_value = actual_tracker.get(key)\n",
        "                if actual_value != expected_value:\n",
        "                    tracker_issues.append(f\"Mismatch for '{key}': Expected '{expected_value}', Got '{actual_value}'\")\n",
        "\n",
        "            if tracker_issues:\n",
        "                validation_outcome[\"is_valid\"] = False\n",
        "                issue = f\"Treatment tracker state mismatch: {', '.join(tracker_issues)}\"\n",
        "                validation_outcome[\"issues\"].append(issue)\n",
        "                logging.error(f\"Validation Issue: {issue}\")\n",
        "            else:\n",
        "                validation_outcome[\"passed_checks\"].append(\"Treatment tracker state matches expected.\")\n",
        "                logging.debug(\"Treatment tracker state matched.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = \"Expected treatment tracker state, but no tracker was found in results.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "    elif actual_tracker:\n",
        "         # If no tracker was expected but one was created\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = \"No treatment tracker expected, but one was created in results.\"\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue}\")\n",
        "    else:\n",
        "         validation_outcome[\"passed_checks\"].append(\"No treatment tracker expected or found.\")\n",
        "         logging.debug(\"No treatment tracker expected or found.\")\n",
        "\n",
        "\n",
        "    # --- 4. Check for Expected Alerts ---\n",
        "    expected_alerts = scenario.get(\"expected_alerts\", [])\n",
        "    actual_alerts = results.get(\"priority_alerts\", []) + results.get(\"workflow_alerts\", [])\n",
        "    alerts_matched = 0\n",
        "    for exp_alert in expected_alerts:\n",
        "        matched = False\n",
        "        # Check if the expected alert string is contained within any actual alert\n",
        "        if any(exp_alert.lower() in actual_alert.lower() for actual_alert in actual_alerts):\n",
        "            alerts_matched += 1\n",
        "            matched = True\n",
        "            logging.debug(f\"Alert matched: Expected '{exp_alert}' found in results.\")\n",
        "            break # Stop checking for this expected alert once a match is found\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Expected alert not found: '{exp_alert}'\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "    if alerts_matched == len(expected_alerts):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_alerts)} expected alerts found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {alerts_matched} of {len(expected_alerts)} expected alerts were matched.\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 5. Check Expected Processing Mode ---\n",
        "    expected_mode = scenario.get(\"expected_mode\")\n",
        "    actual_mode = results.get(\"processing_metrics\", {}).get(\"start_agent_summary\", {}).get(\"processing_mode\")\n",
        "    if expected_mode:\n",
        "        if actual_mode == expected_mode:\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Processing mode matches expected: {expected_mode}.\")\n",
        "            logging.debug(f\"Processing mode matched: {expected_mode}\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Processing mode mismatch: Expected '{expected_mode}', Got '{actual_mode}'.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 6. Check Expected Merging Behavior ---\n",
        "    expected_merging = scenario.get(\"expected_merging\")\n",
        "    if expected_merging == \"duplicate detection\":\n",
        "        initial_problem_count = len(scenario.get(\"previous_problems\", [])) + len(results.get(\"extracted_problems\", []))\n",
        "        final_problem_count = len(results.get(\"final_problems\", []))\n",
        "        if final_problem_count <= initial_problem_count: # Check if merging reduced or kept the count\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Problem merging appears to have occurred (Final count {final_problem_count} <= Initial count {initial_problem_count}).\")\n",
        "            logging.debug(f\"Merging check passed. Initial: {initial_problem_count}, Final: {final_problem_count}\")\n",
        "\n",
        "            # Optional: Check merge_results for specific actions if needed\n",
        "            merge_results = results.get(\"merge_results\", {})\n",
        "            if merge_results.get(\"problem_merge_actions\"):\n",
        "                 validation_outcome[\"passed_checks\"].append(f\"Problem merge actions recorded: {len(merge_results['problem_merge_actions'])}.\")\n",
        "                 logging.debug(f\"Merge actions recorded: {merge_results['problem_merge_actions']}\")\n",
        "            elif initial_problem_count > final_problem_count:\n",
        "                 # If counts differ but no actions recorded, might be an issue with logging\n",
        "                 validation_outcome[\"warnings\"].append(\"Problem counts differ, but no merge actions were logged.\")\n",
        "                 logging.warning(\"Warning: Problem counts differ, but no merge actions logged.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Problem merging expected but did not reduce count (Final count {final_problem_count} > Initial count {initial_problem_count}).\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 7. Check Expected Priority Escalation ---\n",
        "    expected_escalation = scenario.get(\"expected_priority_escalation\", False)\n",
        "    actual_priority_alerts = results.get(\"priority_alerts\", [])\n",
        "    actual_errors = results.get(\"errors\", [])\n",
        "    escalation_detected = any(\"escalation required\" in alert.lower() for alert in actual_priority_alerts) or \\\n",
        "                          any(\"escalation required\" in error.lower() for error in actual_errors) or \\\n",
        "                          any(\"immediate action required\" in alert.lower() for alert in actual_priority_alerts) # Also check for immediate action\n",
        "\n",
        "    if expected_escalation:\n",
        "        if escalation_detected:\n",
        "            validation_outcome[\"passed_checks\"].append(\"Expected priority escalation was detected.\")\n",
        "            logging.debug(\"Priority escalation detected.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = \"Expected priority escalation was NOT detected.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "    elif escalation_detected:\n",
        "         # If escalation was detected but not expected\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = \"Unexpected priority escalation was detected.\"\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue}\")\n",
        "         validation_outcome[\"warnings\"].append(\"Unexpected escalation detected.\") # Add warning too\n",
        "\n",
        "\n",
        "    # --- Final Summary ---\n",
        "    if validation_outcome[\"is_valid\"]:\n",
        "        validation_outcome[\"summary\"] = \"Validation successful.\"\n",
        "        logging.info(\"Validation successful.\")\n",
        "    else:\n",
        "        validation_outcome[\"summary\"] = \"Validation failed. See issues.\"\n",
        "        logging.error(\"Validation failed.\")\n",
        "\n",
        "    return validation_outcome\n",
        "\n",
        "print(\"âœ… validate_results function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22f526a0"
      },
      "source": [
        "## Implement performance benchmarking\n",
        "\n",
        "### Subtask:\n",
        "Add logic to measure and report performance metrics like execution time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25f3dafb"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the `execute_scenario` function to record execution time and update the `validate_results` function to include the new performance benchmarks (execution time, validation accuracy, treatment timeline accuracy).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fbb961f"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "from typing import Dict, Any, List, Optional\n",
        "\n",
        "# Assuming process_medical_workflow, MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker, WorkflowCalculator, create_clinical_scenarios, are_problems_similar, are_care_plans_similar, test_scenarios are defined\n",
        "\n",
        "def execute_scenario(scenario: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Executes the medical workflow for a single test scenario and records performance metrics.\n",
        "\n",
        "    Args:\n",
        "        scenario: A dictionary containing the test scenario inputs and expectations.\n",
        "\n",
        "    Returns:\n",
        "        The results dictionary from the process_medical_workflow function,\n",
        "        augmented with performance metrics like execution time.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Executing scenario: {scenario.get('description', 'Unnamed Scenario')}\")\n",
        "\n",
        "    # Extract inputs with defaults\n",
        "    clinical_note = scenario.get(\"clinical_note\", \"\")\n",
        "    patient_mrn = scenario.get(\"patient_mrn\", f\"MRN_{uuid.uuid4()}\") # Generate a unique MRN if not provided\n",
        "    # Handle previous data - use provided lists or generate mock data if scenario specifies patient_type\n",
        "    previous_problems = scenario.get(\"previous_problems\")\n",
        "    previous_care_plans = scenario.get(\"previous_care_plans\")\n",
        "    treatment_tracker = scenario.get(\"treatment_tracker\")\n",
        "\n",
        "    # If previous_problems/care_plans/treatment_tracker are not explicitly provided,\n",
        "    # check if the scenario includes 'patient_type' to generate mock history\n",
        "    if previous_problems is None or previous_care_plans is None or treatment_tracker is None:\n",
        "         patient_type = scenario.get(\"patient_type\")\n",
        "         if patient_type:\n",
        "              cancer_type = scenario.get(\"cancer_type\")\n",
        "              stage = scenario.get(\"stage\")\n",
        "              note_date_for_history = scenario.get(\"note_date\", datetime.datetime.now().strftime(\"%Y-%m-%d\")) # Use scenario note_date or today\n",
        "              logging.info(f\"Generating mock history for patient type: {patient_type}\")\n",
        "              mock_history = create_clinical_scenarios(\n",
        "                  patient_type=patient_type,\n",
        "                  mrn=patient_mrn,\n",
        "                  note_date=note_date_for_history,\n",
        "                  cancer_type=cancer_type,\n",
        "                  stage=stage\n",
        "              )\n",
        "              # Use generated mock data only if not explicitly provided in the scenario\n",
        "              previous_problems = previous_problems if previous_problems is not None else mock_history[\"previous_problems\"]\n",
        "              previous_care_plans = previous_care_plans if previous_care_plans is not None else mock_history[\"previous_care_plans\"]\n",
        "              treatment_tracker = treatment_tracker if treatment_tracker is not None else mock_history[\"treatment_tracker\"]\n",
        "         else:\n",
        "              # Default to empty lists and None tracker if no history generation specified\n",
        "              previous_problems = previous_problems if previous_problems is not None else []\n",
        "              previous_care_plans = previous_care_plans if previous_care_plans is not None else []\n",
        "              treatment_tracker = treatment_tracker if treatment_tracker is not None else None\n",
        "\n",
        "\n",
        "    processing_mode = scenario.get(\"processing_mode\", \"comprehensive\")\n",
        "    note_author = scenario.get(\"note_author\", \"Test System\")\n",
        "    note_date = scenario.get(\"note_date\", datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "    # Record start time\n",
        "    start_time = time.perf_counter()\n",
        "    logging.debug(f\"Workflow started at {start_time}\")\n",
        "\n",
        "\n",
        "    # Call the main workflow processing function\n",
        "    results = process_medical_workflow(\n",
        "        clinical_note=clinical_note,\n",
        "        patient_mrn=patient_mrn,\n",
        "        previous_problems=previous_problems,\n",
        "        previous_care_plans=previous_care_plans,\n",
        "        treatment_tracker=treatment_tracker,\n",
        "        processing_mode=processing_mode,\n",
        "        note_author=note_author,\n",
        "        note_date=note_date\n",
        "    )\n",
        "\n",
        "    # Record end time and calculate execution time\n",
        "    end_time = time.perf_counter()\n",
        "    execution_time_ms = (end_time - start_time) * 1000\n",
        "    logging.debug(f\"Workflow ended at {end_time}\")\n",
        "    logging.info(f\"Execution time for MRN {patient_mrn}: {execution_time_ms:.2f} ms\")\n",
        "\n",
        "\n",
        "    # Add execution time to the results dictionary\n",
        "    results[\"execution_time_ms\"] = execution_time_ms\n",
        "\n",
        "    logging.info(f\"Scenario execution complete for MRN: {patient_mrn}. Status: {results.get('final_status', 'Unknown')}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "def validate_results(scenario: Dict[str, Any], results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Validates the output of the medical workflow against expected results for a scenario,\n",
        "    including medical accuracy and performance benchmarks.\n",
        "\n",
        "    Args:\n",
        "        scenario: The test scenario dictionary with inputs and expectations.\n",
        "        results: The results dictionary from process_medical_workflow,\n",
        "                 including performance metrics.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary summarizing the validation outcome.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Validating results for scenario: {scenario.get('description', 'Unnamed Scenario')}\")\n",
        "    validation_outcome: Dict[str, Any] = {\n",
        "        \"scenario_name\": scenario.get('description', 'Unnamed Scenario'),\n",
        "        \"is_valid\": True,\n",
        "        \"issues\": [],\n",
        "        \"passed_checks\": [],\n",
        "        \"performance_benchmarks\": {}, # Added for performance metrics\n",
        "        \"summary\": \"\"\n",
        "    }\n",
        "\n",
        "    # --- 1. Check Expected Problems ---\n",
        "    expected_problems = scenario.get(\"expected_problems\", [])\n",
        "    final_problems = results.get(\"final_problems\", [])\n",
        "    problems_matched = 0\n",
        "    for exp_p in expected_problems:\n",
        "        matched = False\n",
        "        for final_p in final_problems:\n",
        "            # Use are_problems_similar for flexible matching\n",
        "            if are_problems_similar(final_p, exp_p):\n",
        "                problems_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Problem matched: Expected '{exp_p.get('problem_name', 'N/A')}', Got '{final_p.problem_name}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Expected problem not found or attributes mismatch: {exp_p.get('problem_name', 'N/A')} (Expected: {exp_p})\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "    if problems_matched == len(expected_problems):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_problems)} expected problems found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {problems_matched} of {len(expected_problems)} expected problems were matched.\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 2. Check Expected Care Plans ---\n",
        "    expected_care_plans = scenario.get(\"expected_care_plans\", [])\n",
        "    final_care_plans = results.get(\"final_care_plans\", [])\n",
        "    care_plans_matched = 0\n",
        "    for exp_cp in expected_care_plans:\n",
        "        matched = False\n",
        "        for final_cp in final_care_plans:\n",
        "             # Use are_care_plans_similar for flexible matching\n",
        "            if are_care_plans_similar(final_cp, exp_cp):\n",
        "                care_plans_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Care Plan matched: Expected '{exp_cp.get('suggested_plan', 'N/A')}', Got '{final_cp.suggested_plan}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Expected care plan not found or attributes mismatch: {exp_cp.get('suggested_plan', 'N/A')} (Expected: {exp_cp})\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "    if care_plans_matched == len(expected_care_plans):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_care_plans)} expected care plans found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {care_plans_matched} of {len(expected_care_plans)} expected care plans were matched.\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 3. Check Expected Treatment Tracker State ---\n",
        "    expected_tracker = scenario.get(\"expected_treatment_tracker\")\n",
        "    actual_tracker = results.get(\"treatment_timeline\") # This is a dict\n",
        "    if expected_tracker:\n",
        "        if actual_tracker:\n",
        "            tracker_issues = []\n",
        "            for key, expected_value in expected_tracker.items():\n",
        "                actual_value = actual_tracker.get(key)\n",
        "                if actual_value != expected_value:\n",
        "                    tracker_issues.append(f\"Mismatch for '{key}': Expected '{expected_value}', Got '{actual_value}'\")\n",
        "\n",
        "            if tracker_issues:\n",
        "                validation_outcome[\"is_valid\"] = False\n",
        "                issue = f\"Treatment tracker state mismatch: {', '.join(tracker_issues)}\"\n",
        "                validation_outcome[\"issues\"].append(issue)\n",
        "                logging.error(f\"Validation Issue: {issue}\")\n",
        "            else:\n",
        "                validation_outcome[\"passed_checks\"].append(\"Treatment tracker state matches expected.\")\n",
        "                logging.debug(\"Treatment tracker state matched.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = \"Expected treatment tracker state, but no tracker was found in results.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "    elif actual_tracker:\n",
        "         # If no tracker was expected but one was created\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = \"No treatment tracker expected, but one was created in results.\"\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue}\")\n",
        "    else:\n",
        "         validation_outcome[\"passed_checks\"].append(\"No treatment tracker expected or found.\")\n",
        "         logging.debug(\"No treatment tracker expected or found.\")\n",
        "\n",
        "\n",
        "    # --- 4. Check for Expected Alerts ---\n",
        "    expected_alerts = scenario.get(\"expected_alerts\", [])\n",
        "    actual_alerts = results.get(\"priority_alerts\", []) + results.get(\"workflow_alerts\", [])\n",
        "    alerts_matched = 0\n",
        "    for exp_alert in expected_alerts:\n",
        "        # Check if the expected alert string is contained within any actual alert\n",
        "        if any(exp_alert.lower() in actual_alert.lower() for actual_alert in actual_alerts):\n",
        "            alerts_matched += 1\n",
        "            logging.debug(f\"Alert matched: Expected '{exp_alert}' found in results.\")\n",
        "\n",
        "    if alerts_matched == len(expected_alerts):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_alerts)} expected alerts found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = f\"Only {alerts_matched} of {len(expected_alerts)} expected alerts were matched. Missing: {[a for a in expected_alerts if not any(a.lower() in act.lower() for act in actual_alerts)]}\"\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 5. Check Expected Processing Mode ---\n",
        "    expected_mode = scenario.get(\"expected_mode\")\n",
        "    actual_mode = results.get(\"processing_metrics\", {}).get(\"start_agent_summary\", {}).get(\"processing_mode\")\n",
        "    if expected_mode:\n",
        "        if actual_mode == expected_mode:\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Processing mode matches expected: {expected_mode}.\")\n",
        "            logging.debug(f\"Processing mode matched: {expected_mode}\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Processing mode mismatch: Expected '{expected_mode}', Got '{actual_mode}'.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 6. Check Expected Merging Behavior ---\n",
        "    expected_merging = scenario.get(\"expected_merging\")\n",
        "    if expected_merging == \"duplicate detection\":\n",
        "        # Calculate initial problems from previous + extracted\n",
        "        initial_problems_from_results = results.get(\"extracted_problems\", []) # Extracted from THIS note\n",
        "        # Need original previous problems count - get from scenario input if possible\n",
        "        initial_problem_count = len(scenario.get(\"previous_problems\", [])) + len(initial_problems_from_results)\n",
        "        final_problem_count = len(results.get(\"final_problems\", []))\n",
        "\n",
        "        # Check if merging reduced or kept the count (indicating merging logic ran)\n",
        "        if final_problem_count <= initial_problem_count:\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Problem merging appears to have occurred (Final count {final_problem_count} <= Initial count {initial_problem_count}).\")\n",
        "            logging.debug(f\"Merging check passed. Initial: {initial_problem_count}, Final: {final_problem_count}\")\n",
        "\n",
        "            # Optional: Check merge_results for specific actions if needed\n",
        "            merge_results = results.get(\"merge_results\", {})\n",
        "            if merge_results.get(\"problem_merge_actions\"):\n",
        "                 validation_outcome[\"passed_checks\"].append(f\"Problem merge actions recorded: {len(merge_results['problem_merge_actions'])}.\")\n",
        "                 logging.debug(f\"Merge actions recorded: {merge_results['problem_merge_actions']}\")\n",
        "            elif initial_problem_count > final_problem_count:\n",
        "                 # If counts differ but no actions recorded, might be an issue with logging\n",
        "                 validation_outcome[\"warnings\"].append(\"Problem counts differ, but no merge actions were logged.\")\n",
        "                 logging.warning(\"Warning: Problem counts differ, but no merge actions logged.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = f\"Problem merging expected but did not reduce count (Final count {final_problem_count} > Initial count {initial_problem_count}).\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "\n",
        "\n",
        "    # --- 7. Check Expected Priority Escalation ---\n",
        "    expected_escalation = scenario.get(\"expected_priority_escalation\", False)\n",
        "    actual_priority_alerts = results.get(\"priority_alerts\", [])\n",
        "    actual_errors = results.get(\"errors\", [])\n",
        "    escalation_detected = any(\"escalation required\" in alert.lower() for alert in actual_priority_alerts) or \\\n",
        "                          any(\"escalation required\" in error.lower() for error in actual_errors) or \\\n",
        "                          any(\"immediate action required\" in alert.lower() for alert in actual_priority_alerts) # Also check for immediate action\n",
        "\n",
        "    if expected_escalation:\n",
        "        if escalation_detected:\n",
        "            validation_outcome[\"passed_checks\"].append(\"Expected priority escalation was detected.\")\n",
        "            logging.debug(\"Priority escalation detected.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = \"Expected priority escalation was NOT detected.\"\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue}\")\n",
        "    elif escalation_detected:\n",
        "         # If escalation was detected but not expected\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = \"Unexpected priority escalation was detected.\"\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue}\")\n",
        "         validation_outcome[\"warnings\"].append(\"Unexpected escalation detected.\") # Add warning too\n",
        "\n",
        "\n",
        "    # --- 8. Performance Benchmarks ---\n",
        "    execution_time_ms = results.get(\"execution_time_ms\")\n",
        "    validation_confidence = results.get(\"validation_confidence\")\n",
        "    # Treatment timeline accuracy needs a defined metric. Using validation confidence related to tracker for now.\n",
        "    # A more robust check would involve comparing specific dates or calculated delays in the tracker.\n",
        "    treatment_timeline_accuracy = results.get(\"validation_confidence\") # Placeholder: Using overall validation confidence\n",
        "\n",
        "    performance_issues = []\n",
        "\n",
        "    # Benchmark 1: Execution Time\n",
        "    expected_max_execution_time_ms = scenario.get(\"benchmark_execution_time_ms\", 10000) # Default to 10 seconds\n",
        "    if execution_time_ms is not None:\n",
        "        validation_outcome[\"performance_benchmarks\"][\"execution_time_ms\"] = execution_time_ms\n",
        "        if execution_time_ms > expected_max_execution_time_ms:\n",
        "            performance_issues.append(f\"Execution time benchmark failed: {execution_time_ms:.2f} ms > {expected_max_execution_time_ms} ms.\")\n",
        "            validation_outcome[\"is_valid\"] = False # Performance failure can fail validation\n",
        "\n",
        "    # Benchmark 2: Validation Accuracy (Using Validation Confidence)\n",
        "    expected_min_validation_confidence = scenario.get(\"benchmark_validation_accuracy\", 0.90) # Default to 90%\n",
        "    if validation_confidence is not None:\n",
        "        validation_outcome[\"performance_benchmarks\"][\"validation_confidence\"] = validation_confidence\n",
        "        if validation_confidence < expected_min_validation_confidence:\n",
        "            performance_issues.append(f\"Validation accuracy benchmark failed: {validation_confidence:.2f} < {expected_min_validation_confidence:.2f}.\")\n",
        "            # Decide if this fails validation or is just a performance warning\n",
        "            # validation_outcome[\"is_valid\"] = False # Can optionally fail validation on low confidence\n",
        "\n",
        "    # Benchmark 3: Treatment Timeline Accuracy (Placeholder - Using Validation Confidence)\n",
        "    expected_min_timeline_accuracy = scenario.get(\"benchmark_timeline_accuracy\", 0.95) # Default to 95%\n",
        "    if treatment_timeline_accuracy is not None:\n",
        "         validation_outcome[\"performance_benchmarks\"][\"treatment_timeline_accuracy\"] = treatment_timeline_accuracy # Log the value used\n",
        "         # This check needs refinement based on a real timeline accuracy metric\n",
        "         # For now, check if overall validation confidence is below a potentially higher threshold for timeline critical scenarios\n",
        "         if expected_tracker and validation_confidence is not None and validation_confidence < expected_min_timeline_accuracy:\n",
        "              performance_issues.append(f\"Treatment timeline accuracy benchmark potentially failed (using validation confidence): {validation_confidence:.2f} < {expected_min_timeline_accuracy:.2f}. Requires review.\")\n",
        "              # This might be a warning rather than a hard fail initially\n",
        "\n",
        "\n",
        "    if performance_issues:\n",
        "        validation_outcome[\"issues\"].extend(performance_issues)\n",
        "        logging.error(f\"Performance Issues: {performance_issues}\")\n",
        "    elif execution_time_ms is not None and validation_confidence is not None:\n",
        "         validation_outcome[\"passed_checks\"].append(\"Performance benchmarks checked.\")\n",
        "\n",
        "\n",
        "    # --- Final Summary ---\n",
        "    if validation_outcome[\"is_valid\"]:\n",
        "        validation_outcome[\"summary\"] = \"Validation successful.\"\n",
        "        logging.info(\"Validation successful.\")\n",
        "    else:\n",
        "        validation_outcome[\"summary\"] = \"Validation failed. See issues.\"\n",
        "        logging.error(\"Validation failed.\")\n",
        "\n",
        "    return validation_outcome\n",
        "\n",
        "print(\"âœ… execute_scenario function updated to record execution time.\")\n",
        "print(\"âœ… validate_results function updated to include performance benchmarks.\")\n",
        "\n",
        "# Update test_scenarios with performance benchmarks (optional, using defaults if not provided)\n",
        "# Example:\n",
        "# test_scenarios[\"oncology_new_patient\"][\"benchmark_execution_time_ms\"] = 12000 # Allow more time for this scenario\n",
        "# test_scenarios[\"oncology_new_patient\"][\"description\"] = \"New Oncology Patient Scenario\" # Add description for logging\n",
        "# test_scenarios[\"treatment_delay_emergency\"][\"description\"] = \"Treatment Delay Emergency Scenario\"\n",
        "# test_scenarios[\"complex_oncology_case\"][\"description\"] = \"Complex Oncology Case Scenario\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b79423e"
      },
      "source": [
        "## Implement khcc workflow validation\n",
        "\n",
        "### Subtask:\n",
        "Add specific validation checks for KHCC-specific workflow rules (e.g., 30-day treatment targets, pathology repeat detection, radiology timeline compliance) within the `validate_results` function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b0443b9"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement specific validation checks for KHCC-specific workflow rules within the `validate_results` function by accessing the treatment timeline data, checking the 30-day treatment target, checking the pathology needs repeat flag, checking the radiology timeline dates, logging issues, and updating the overall validation status.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5225b775"
      },
      "source": [
        "import logging\n",
        "from typing import Dict, Any, List, Optional\n",
        "from difflib import SequenceMatcher\n",
        "import datetime\n",
        "\n",
        "# Assuming MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker, WorkflowCalculator are defined\n",
        "\n",
        "def are_problems_similar(p1: MedicalProblem, p2_expected: Dict[str, Any], similarity_threshold: float = 0.8) -> bool:\n",
        "    \"\"\"Checks if a MedicalProblem object is similar to an expected problem dictionary.\"\"\"\n",
        "    # Check problem name similarity\n",
        "    name_similarity = SequenceMatcher(None, p1.problem_name.lower(), p2_expected.get(\"problem_name\", \"\").lower()).ratio()\n",
        "\n",
        "    if name_similarity < similarity_threshold:\n",
        "        return False\n",
        "\n",
        "    # Check key attributes if provided in expected\n",
        "    if \"priority_flag\" in p2_expected and p1.priority_flag != p2_expected[\"priority_flag\"]:\n",
        "        return False\n",
        "    if \"is_cancer_related\" in p2_expected and p1.is_cancer_related != p2_expected[\"is_cancer_related\"]:\n",
        "        return False\n",
        "    if \"is_treatment_related\" in p2_expected and p1.is_treatment_related != p2_expected[\"is_treatment_related\"]:\n",
        "        return False\n",
        "    if \"is_psychosocial\" in p2_expected and p1.is_psychosocial != p2_expected[\"is_psychosocial\"]:\n",
        "        return False\n",
        "    # Add other attribute checks as needed\n",
        "\n",
        "    return True\n",
        "\n",
        "def are_care_plans_similar(cp1: CarePlan, cp2_expected: Dict[str, Any], similarity_threshold: float = 0.7) -> bool:\n",
        "    \"\"\"Checks if a CarePlan object is similar to an expected care plan dictionary.\"\"\"\n",
        "    # Check suggested plan similarity\n",
        "    plan_similarity = SequenceMatcher(None, cp1.suggested_plan.lower(), cp2_expected.get(\"suggested_plan\", \"\").lower()).ratio()\n",
        "\n",
        "    if plan_similarity < similarity_threshold:\n",
        "        return False\n",
        "\n",
        "    # Check key attributes if provided in expected\n",
        "    if \"urgency_level\" in cp2_expected and cp1.urgency_level != cp2_expected[\"urgency_level\"]:\n",
        "        return False\n",
        "    if \"action_type\" in cp2_expected and cp1.action_type != cp2_expected[\"action_type\"]:\n",
        "        return False\n",
        "    if \"date_due\" in cp2_expected and cp1.date_due != exp_cp[\"date_due\"]:\n",
        "         # Allow for some flexibility if date is estimated, but check format\n",
        "         try:\n",
        "              datetime.datetime.strptime(cp1.date_due, \"%Y-%m-%d\")\n",
        "              datetime.datetime.strptime(exp_cp[\"date_due\"], \"%Y-%m-%d\")\n",
        "              # Consider adding tolerance for date differences if needed\n",
        "              if cp1.date_due != exp_cp[\"date_due\"]:\n",
        "                   logging.debug(f\"Care plan date_due mismatch: Expected {exp_cp['date_due']}, Got {cp1.date_due}\")\n",
        "                   # Decide if this is a hard fail or a warning based on test strictness\n",
        "                   # For now, treat as a mismatch if not exact\n",
        "                   return False\n",
        "         except ValueError:\n",
        "              logging.warning(f\"Invalid date format in care plan similarity check: cp1.date_due={cp1.date_due}, exp_cp['date_due']={exp_cp['date_due']}\")\n",
        "              return False # Treat invalid date format as not similar\n",
        "\n",
        "\n",
        "    # Check workflow status and overdue days if expected\n",
        "    if \"workflow_status\" in exp_cp and cp1.workflow_status != exp_cp[\"workflow_status\"]:\n",
        "        return False\n",
        "    # Checking days_overdue might be complex as it depends on current date vs note date\n",
        "    # A more robust test might involve setting a specific 'current_date' for validation\n",
        "    # if \"days_overdue\" in exp_cp and cp1.days_overdue != exp_cp[\"days_overdue\"]:\n",
        "    #     return False\n",
        "\n",
        "    # Add other attribute checks as needed\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def validate_results(scenario: Dict[str, Any], results: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Validates the output of the medical workflow against expected results for a scenario,\n",
        "    including medical accuracy, performance benchmarks, and KHCC-specific rules.\n",
        "\n",
        "    Args:\n",
        "        scenario: The test scenario dictionary with inputs and expectations.\n",
        "        results: The results dictionary from process_medical_workflow,\n",
        "                 including performance metrics.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary summarizing the validation outcome.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Validating results for scenario: {scenario.get('description', 'Unnamed Scenario')}\")\n",
        "    validation_outcome: Dict[str, Any] = {\n",
        "        \"scenario_name\": scenario.get('description', 'Unnamed Scenario'),\n",
        "        \"is_valid\": True,\n",
        "        \"issues\": [],\n",
        "        \"passed_checks\": [],\n",
        "        \"performance_benchmarks\": {}, # Added for performance metrics\n",
        "        \"summary\": \"\",\n",
        "        \"khcc_workflow_checks\": [] # Added for KHCC specific checks\n",
        "    }\n",
        "\n",
        "    # --- 1. Check Expected Problems ---\n",
        "    expected_problems = scenario.get(\"expected_problems\", [])\n",
        "    final_problems = results.get(\"final_problems\", [])\n",
        "    problems_matched = 0\n",
        "    for exp_p in expected_problems:\n",
        "        matched = False\n",
        "        for final_p in final_problems:\n",
        "            # Use are_problems_similar for flexible matching\n",
        "            if are_problems_similar(final_p, exp_p):\n",
        "                problems_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Problem matched: Expected '{exp_p.get('problem_name', 'N/A')}', Got '{final_p.problem_name}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                \"type\": \"problem_mismatch\",\n",
        "                \"description\": f\"Expected problem not found or attributes mismatch: {exp_p.get('problem_name', 'N/A')} (Expected: {exp_p})\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "    if problems_matched == len(expected_problems):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_problems)} expected problems found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = {\n",
        "            \"type\": \"problem_count_mismatch\",\n",
        "            \"description\": f\"Only {problems_matched} of {len(expected_problems)} expected problems were matched.\"\n",
        "        }\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    # --- 2. Check Expected Care Plans ---\n",
        "    expected_care_plans = scenario.get(\"expected_care_plans\", [])\n",
        "    final_care_plans = results.get(\"final_care_plans\", [])\n",
        "    care_plans_matched = 0\n",
        "    for exp_cp in expected_care_plans:\n",
        "        matched = False\n",
        "        for final_cp in final_care_plans:\n",
        "             # Use are_care_plans_similar for flexible matching\n",
        "            if are_care_plans_similar(final_cp, exp_cp):\n",
        "                care_plans_matched += 1\n",
        "                matched = True\n",
        "                logging.debug(f\"Care Plan matched: Expected '{exp_cp.get('suggested_plan', 'N/A')}', Got '{final_cp.suggested_plan}'\")\n",
        "                break\n",
        "        if not matched:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                \"type\": \"care_plan_mismatch\",\n",
        "                \"description\": f\"Expected care plan not found or attributes mismatch: {exp_cp.get('suggested_plan', 'N/A')} (Expected: {exp_cp})\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    if care_plans_matched == len(expected_care_plans):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_care_plans)} expected care plans found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = {\n",
        "            \"type\": \"care_plan_count_mismatch\",\n",
        "            \"description\": f\"Only {care_plans_matched} of {len(expected_care_plans)} expected care plans were matched.\"\n",
        "        }\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    # --- 3. Check Expected Treatment Tracker State ---\n",
        "    expected_tracker = scenario.get(\"expected_treatment_tracker\")\n",
        "    actual_tracker_dict = results.get(\"treatment_timeline\") # This is a dict\n",
        "    if expected_tracker:\n",
        "        if actual_tracker_dict:\n",
        "            tracker_issues = []\n",
        "            for key, expected_value in expected_tracker.items():\n",
        "                actual_value = actual_tracker_dict.get(key)\n",
        "                if actual_value != expected_value:\n",
        "                    tracker_issues.append(f\"Mismatch for '{key}': Expected '{expected_value}', Got '{actual_value}'\")\n",
        "\n",
        "            if tracker_issues:\n",
        "                validation_outcome[\"is_valid\"] = False\n",
        "                issue = {\n",
        "                    \"type\": \"treatment_tracker_mismatch\",\n",
        "                    \"description\": f\"Treatment tracker state mismatch: {', '.join(tracker_issues)}\"\n",
        "                }\n",
        "                validation_outcome[\"issues\"].append(issue)\n",
        "                logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "            else:\n",
        "                validation_outcome[\"passed_checks\"].append(\"Treatment tracker state matches expected.\")\n",
        "                logging.debug(\"Treatment tracker state matched.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                 \"type\": \"treatment_tracker_missing\",\n",
        "                 \"description\": \"Expected treatment tracker state, but no tracker was found in results.\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "    elif actual_tracker_dict:\n",
        "         # If no tracker was expected but one was created\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = {\n",
        "             \"type\": \"unexpected_treatment_tracker\",\n",
        "             \"description\": \"No treatment tracker expected, but one was created in results.\"\n",
        "         }\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "    else:\n",
        "         validation_outcome[\"passed_checks\"].append(\"No treatment tracker expected or found.\")\n",
        "         logging.debug(\"No treatment tracker expected or found.\")\n",
        "\n",
        "\n",
        "    # --- 4. Check for Expected Alerts ---\n",
        "    expected_alerts = scenario.get(\"expected_alerts\", [])\n",
        "    actual_alerts = results.get(\"priority_alerts\", []) + results.get(\"workflow_alerts\", [])\n",
        "    alerts_matched = 0\n",
        "    for exp_alert in expected_alerts:\n",
        "        # Check if the expected alert string is contained within any actual alert\n",
        "        if any(exp_alert.lower() in actual_alert.lower() for actual_alert in actual_alerts):\n",
        "            alerts_matched += 1\n",
        "            logging.debug(f\"Alert matched: Expected '{exp_alert}' found in results.\")\n",
        "\n",
        "    if alerts_matched == len(expected_alerts):\n",
        "        validation_outcome[\"passed_checks\"].append(f\"All {len(expected_alerts)} expected alerts found.\")\n",
        "    else:\n",
        "        validation_outcome[\"is_valid\"] = False\n",
        "        issue = {\n",
        "             \"type\": \"alert_mismatch\",\n",
        "             \"description\": f\"Only {alerts_matched} of {len(expected_alerts)} expected alerts were matched. Missing: {[a for a in expected_alerts if not any(a.lower() in act.lower() for act in actual_alerts)]}\"\n",
        "        }\n",
        "        validation_outcome[\"issues\"].append(issue)\n",
        "        logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    # --- 5. Check Expected Processing Mode ---\n",
        "    expected_mode = scenario.get(\"expected_mode\")\n",
        "    actual_mode = results.get(\"processing_metrics\", {}).get(\"start_agent_summary\", {}).get(\"processing_mode\")\n",
        "    if expected_mode:\n",
        "        if actual_mode == expected_mode:\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Processing mode matches expected: {expected_mode}.\")\n",
        "            logging.debug(f\"Processing mode matched: {expected_mode}\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                 \"type\": \"processing_mode_mismatch\",\n",
        "                 \"description\": f\"Processing mode mismatch: Expected '{expected_mode}', Got '{actual_mode}'.\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    # --- 6. Check Expected Merging Behavior ---\n",
        "    expected_merging = scenario.get(\"expected_merging\")\n",
        "    if expected_merging == \"duplicate detection\":\n",
        "        # Calculate initial problems from previous + extracted\n",
        "        initial_problems_from_results = results.get(\"extracted_problems\", []) # Extracted from THIS note\n",
        "        # Need original previous problems count - get from scenario input if possible\n",
        "        initial_problem_count = len(scenario.get(\"previous_problems\", [])) + len(initial_problems_from_results)\n",
        "        final_problem_count = len(results.get(\"final_problems\", []))\n",
        "\n",
        "        # Check if merging reduced or kept the count (indicating merging logic ran)\n",
        "        if final_problem_count <= initial_problem_count:\n",
        "            validation_outcome[\"passed_checks\"].append(f\"Problem merging appears to have occurred (Final count {final_problem_count} <= Initial count {initial_problem_count}).\")\n",
        "            logging.debug(f\"Merging check passed. Initial: {initial_problem_count}, Final: {final_problem_count}\")\n",
        "\n",
        "            # Optional: Check merge_results for specific actions if needed\n",
        "            merge_results = results.get(\"merge_results\", {})\n",
        "            if merge_results.get(\"problem_merge_actions\"):\n",
        "                 validation_outcome[\"passed_checks\"].append(f\"Problem merge actions recorded: {len(merge_results['problem_merge_actions'])}.\")\n",
        "                 logging.debug(f\"Merge actions recorded: {merge_results['problem_merge_actions']}\")\n",
        "            elif initial_problem_count > final_problem_count:\n",
        "                 # If counts differ but no actions recorded, might be an issue with logging\n",
        "                 validation_outcome[\"warnings\"].append(\"Problem counts differ, but no merge actions were logged.\")\n",
        "                 logging.warning(\"Warning: Problem counts differ, but no merge actions logged.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                 \"type\": \"merging_failed\",\n",
        "                 \"description\": f\"Problem merging expected but did not reduce count (Final count {final_problem_count} > Initial count {initial_problem_count}).\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "\n",
        "\n",
        "    # --- 7. Check Expected Priority Escalation ---\n",
        "    expected_escalation = scenario.get(\"expected_priority_escalation\", False)\n",
        "    actual_priority_alerts = results.get(\"priority_alerts\", [])\n",
        "    actual_errors = results.get(\"errors\", [])\n",
        "    escalation_detected = any(\"escalation required\" in alert.lower() for alert in actual_priority_alerts) or \\\n",
        "                          any(\"escalation required\" in error.lower() for error in actual_errors) or \\\n",
        "                          any(\"immediate action required\" in alert.lower() for alert in actual_priority_alerts) # Also check for immediate action\n",
        "\n",
        "    if expected_escalation:\n",
        "        if escalation_detected:\n",
        "            validation_outcome[\"passed_checks\"].append(\"Expected priority escalation was detected.\")\n",
        "            logging.debug(\"Priority escalation detected.\")\n",
        "        else:\n",
        "            validation_outcome[\"is_valid\"] = False\n",
        "            issue = {\n",
        "                 \"type\": \"escalation_missing\",\n",
        "                 \"description\": \"Expected priority escalation was NOT detected.\"\n",
        "            }\n",
        "            validation_outcome[\"issues\"].append(issue)\n",
        "            logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "    elif escalation_detected:\n",
        "         # If escalation was detected but not expected\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         issue = {\n",
        "              \"type\": \"unexpected_escalation\",\n",
        "              \"description\": \"Unexpected priority escalation was detected.\"\n",
        "         }\n",
        "         validation_outcome[\"issues\"].append(issue)\n",
        "         logging.error(f\"Validation Issue: {issue['description']}\")\n",
        "         validation_outcome[\"warnings\"].append(\"Unexpected escalation detected.\") # Add warning too\n",
        "\n",
        "\n",
        "    # --- 8. Performance Benchmarks ---\n",
        "    execution_time_ms = results.get(\"execution_time_ms\")\n",
        "    validation_confidence = results.get(\"validation_confidence\")\n",
        "    # Treatment timeline accuracy needs a defined metric. Using validation confidence related to tracker for now.\n",
        "    # A more robust check would involve comparing specific dates or calculated delays in the tracker.\n",
        "    treatment_timeline_accuracy = results.get(\"validation_confidence\") # Placeholder: Using overall validation confidence\n",
        "\n",
        "    performance_issues = []\n",
        "\n",
        "    # Benchmark 1: Execution Time\n",
        "    expected_max_execution_time_ms = scenario.get(\"benchmark_execution_time_ms\", 10000) # Default to 10 seconds\n",
        "    if execution_time_ms is not None:\n",
        "        validation_outcome[\"performance_benchmarks\"][\"execution_time_ms\"] = execution_time_ms\n",
        "        if execution_time_ms > expected_max_execution_time_ms:\n",
        "            performance_issues.append(f\"Execution time benchmark failed: {execution_time_ms:.2f} ms > {expected_max_execution_time_ms} ms.\")\n",
        "            validation_outcome[\"is_valid\"] = False # Performance failure can fail validation\n",
        "\n",
        "    # Benchmark 2: Validation Accuracy (Using Validation Confidence)\n",
        "    expected_min_validation_confidence = scenario.get(\"benchmark_validation_accuracy\", 0.90) # Default to 90%\n",
        "    if validation_confidence is not None:\n",
        "        validation_outcome[\"performance_benchmarks\"][\"validation_confidence\"] = validation_confidence\n",
        "        if validation_confidence < expected_min_validation_confidence:\n",
        "            performance_issues.append(f\"Validation accuracy benchmark failed: {validation_confidence:.2f} < {expected_min_validation_confidence:.2f}.\")\n",
        "            # Decide if this fails validation or is just a performance warning\n",
        "            # validation_outcome[\"is_valid\"] = False # Can optionally fail validation on low confidence\n",
        "\n",
        "    # Benchmark 3: Treatment Timeline Accuracy (Placeholder - Using Validation Confidence)\n",
        "    expected_min_timeline_accuracy = scenario.get(\"benchmark_timeline_accuracy\", 0.95) # Default to 95%\n",
        "    if treatment_timeline_accuracy is not None:\n",
        "         validation_outcome[\"performance_benchmarks\"][\"treatment_timeline_accuracy\"] = treatment_timeline_accuracy # Log the value used\n",
        "         # This check needs refinement based on a real timeline accuracy metric\n",
        "         # For now, check if overall validation confidence is below a potentially higher threshold for timeline critical scenarios\n",
        "         if expected_tracker and validation_confidence is not None and validation_confidence < expected_min_timeline_accuracy:\n",
        "              performance_issues.append(f\"Treatment timeline accuracy benchmark potentially failed (using validation confidence): {validation_confidence:.2f} < {expected_min_timeline_accuracy:.2f}. Requires review.\")\n",
        "              # This might be a warning rather than a hard fail initially\n",
        "\n",
        "\n",
        "    if performance_issues:\n",
        "        for p_issue in performance_issues:\n",
        "             validation_outcome[\"issues\"].append({\n",
        "                 \"type\": \"performance_benchmark_failed\",\n",
        "                 \"description\": p_issue\n",
        "             })\n",
        "        # validation_outcome[\"issues\"].extend(performance_issues) # Add as distinct issues\n",
        "        logging.error(f\"Performance Issues: {performance_issues}\")\n",
        "    elif execution_time_ms is not None and validation_confidence is not None:\n",
        "         validation_outcome[\"passed_checks\"].append(\"Performance benchmarks checked.\")\n",
        "\n",
        "    # --- 9. KHCC-Specific Workflow Validation ---\n",
        "    logging.info(\"Starting KHCC-specific workflow validation...\")\n",
        "    khcc_issues = []\n",
        "    actual_tracker = results.get(\"treatment_timeline\") # Access the tracker dict\n",
        "    actual_final_care_plans = results.get(\"final_care_plans\", [])\n",
        "    actual_alerts_list = results.get(\"priority_alerts\", []) + results.get(\"workflow_alerts\", [])\n",
        "    note_date_str = scenario.get(\"note_date\", datetime.datetime.now().strftime(\"%Y-%m-%d\")) # Get note date from scenario or use today\n",
        "    try:\n",
        "         note_date_obj = datetime.datetime.strptime(note_date_str, \"%Y-%m-%d\").date()\n",
        "    except ValueError:\n",
        "         khcc_issues.append({\n",
        "              \"type\": \"khcc_validation_error\",\n",
        "              \"description\": f\"Invalid note date format for KHCC validation: {note_date_str}. Expected YYYY-MM-DD.\"\n",
        "         })\n",
        "         logging.error(f\"Invalid note date for KHCC validation: {note_date_str}\")\n",
        "         validation_outcome[\"is_valid\"] = False\n",
        "         validation_outcome[\"khcc_workflow_checks\"] = khcc_issues # Add error and skip checks\n",
        "         validation_outcome[\"issues\"].extend(khcc_issues)\n",
        "         logging.info(\"KHCC-specific workflow validation completed with errors.\")\n",
        "         return validation_outcome # Exit validation if note date is invalid\n",
        "\n",
        "\n",
        "    if actual_tracker:\n",
        "        # Check Rule 1: 30-day treatment target\n",
        "        target_start_date_str = actual_tracker.get(\"date_should_start_treatment\")\n",
        "        days_remaining_or_delayed = actual_tracker.get(\"days_remaining_or_delayed\")\n",
        "        first_visit_date_str = actual_tracker.get(\"date_first_visit\")\n",
        "\n",
        "        if target_start_date_str and first_visit_date_str and days_remaining_or_delayed is not None:\n",
        "             try:\n",
        "                  first_visit_date_obj = datetime.datetime.strptime(first_visit_date_str, \"%Y-%m-%d\").date()\n",
        "                  target_start_date_obj = datetime.datetime.strptime(target_start_date_str, \"%Y-%m-%d\").date()\n",
        "                  expected_target_date_obj = first_visit_date_obj + datetime.timedelta(days=30)\n",
        "\n",
        "                  # Check if the tracker's target date matches the 30-day rule (allowing 1-2 day variance)\n",
        "                  if abs((target_start_date_obj - expected_target_date_obj).days) > 2:\n",
        "                       khcc_issues.append({\n",
        "                           \"type\": \"khcc_timeline_compliance\",\n",
        "                           \"description\": f\"Treatment target date ({target_start_date_str}) does not align with 30-day rule from first visit ({first_visit_date_str}). Expected ~{expected_target_date_obj.strftime('%Y-%m-%d')}.\"\n",
        "                       })\n",
        "                       validation_outcome[\"is_valid\"] = False\n",
        "\n",
        "                  # Check for significant delay (>30 days overdue from target)\n",
        "                  if days_remaining_or_delayed > 30:\n",
        "                       khcc_issues.append({\n",
        "                           \"type\": \"khcc_timeline_compliance\",\n",
        "                           \"description\": f\"Significant treatment delay detected ({days_remaining_or_delayed} days past target {target_start_date_str}). Requires escalation according to KHCC process.\"\n",
        "                       })\n",
        "                       validation_outcome[\"is_valid\"] = False\n",
        "                  elif days_remaining_or_delayed > 7: # Warn for delays > 7 days\n",
        "                       khcc_issues.append({\n",
        "                            \"type\": \"khcc_timeline_warning\",\n",
        "                            \"description\": f\"Treatment delay detected ({days_remaining_or_delayed} days past target {target_start_date_str}). Monitoring required.\"\n",
        "                       })\n",
        "\n",
        "\n",
        "             except ValueError:\n",
        "                  khcc_issues.append({\n",
        "                       \"type\": \"khcc_validation_error\",\n",
        "                       \"description\": f\"Invalid date format in treatment tracker for 30-day check (first_visit: {first_visit_date_str}, target_start: {target_start_date_str}).\"\n",
        "                  })\n",
        "                  validation_outcome[\"is_valid\"] = False\n",
        "        elif actual_tracker.get(\"patient_status\") == \"new\":\n",
        "             khcc_issues.append({\n",
        "                  \"type\": \"khcc_timeline_compliance\",\n",
        "                  \"description\": \"New patient tracker created but missing key date fields for 30-day target check (date_should_start_treatment, date_first_visit).\"\n",
        "             })\n",
        "             validation_outcome[\"is_valid\"] = False # Critical for new patients\n",
        "\n",
        "        # Check Rule 2: Pathology Needs Repeat\n",
        "        pathology_needs_repeat = actual_tracker.get(\"pathology_needs_repeat\", False)\n",
        "        if pathology_needs_repeat:\n",
        "            # Check if there's a relevant care plan or alert\n",
        "            action_needed = False\n",
        "            # Check care plans for keywords like \"repeat pathology\", \"pathology review\"\n",
        "            if any(\"pathology\" in cp.suggested_plan.lower() and (\"repeat\" in cp.suggested_plan.lower() or \"review\" in cp.suggested_plan.lower()) for cp in actual_final_care_plans):\n",
        "                 action_needed = True\n",
        "            # Check alerts for keywords like \"pathology repeat\"\n",
        "            elif any(\"pathology repeat\" in alert.lower() for alert in actual_alerts_list):\n",
        "                 action_needed = True\n",
        "\n",
        "            if not action_needed:\n",
        "                 khcc_issues.append({\n",
        "                      \"type\": \"khcc_timeline_compliance\",\n",
        "                      \"description\": \"Pathology needs repeat flag is TRUE in treatment tracker, but no corresponding care plan or alert was found.\"\n",
        "                 })\n",
        "                 validation_outcome[\"is_valid\"] = False\n",
        "            else:\n",
        "                 validation_outcome[\"khcc_workflow_checks\"].append(\"Pathology needs repeat flagged and corresponding action/alert found.\")\n",
        "\n",
        "\n",
        "        # Check Rule 3: Radiology Timeline Compliance (presence and order)\n",
        "        first_radio_date_str = actual_tracker.get(\"date_first_radiology_report\")\n",
        "        full_radio_date_str = actual_tracker.get(\"date_full_radiology_evaluation\")\n",
        "\n",
        "        if first_radio_date_str or full_radio_date_str: # Only check if radiology dates exist\n",
        "            try:\n",
        "                 first_radio_date_obj = datetime.datetime.strptime(first_radio_date_str, \"%Y-%m-%d\").date() if first_radio_date_str else None\n",
        "                 full_radio_date_obj = datetime.datetime.strptime(full_radio_date_str, \"%Y-%m-%d\").date() if full_radio_date_str else None\n",
        "\n",
        "                 if first_radio_date_obj and full_radio_date_obj:\n",
        "                      # Check if first date is before or same as full evaluation date\n",
        "                      if first_radio_date_obj > full_radio_date_obj:\n",
        "                           khcc_issues.append({\n",
        "                                \"type\": \"khcc_timeline_compliance\",\n",
        "                                \"description\": f\"Radiology date order mismatch: First radiology report ({first_radio_date_str}) is after full evaluation date ({full_radio_date_str}).\"\n",
        "                           })\n",
        "                           validation_outcome[\"is_valid\"] = False\n",
        "                      else:\n",
        "                            validation_outcome[\"khcc_workflow_checks\"].append(\"Radiology dates appear in logical order.\")\n",
        "\n",
        "                 elif full_radio_date_obj and not first_radio_date_obj:\n",
        "                      khcc_issues.append({\n",
        "                           \"type\": \"khcc_timeline_compliance\",\n",
        "                           \"description\": \"Full radiology evaluation date exists, but first radiology report date is missing.\"\n",
        "                      })\n",
        "                      validation_outcome[\"is_valid\"] = False\n",
        "                 # If only first_radio_date_obj exists, that's potentially valid if full eval is pending\n",
        "\n",
        "                 # Check if radiology dates are within a reasonable timeframe after first visit (optional, depends on specific workflow)\n",
        "                 # if first_visit_date_obj and first_radio_date_obj and (first_radio_date_obj - first_visit_date_obj).days > 14:\n",
        "                 #      khcc_issues.append(...) # Example: Warning for delayed first radiology\n",
        "\n",
        "            except ValueError:\n",
        "                 khcc_issues.append({\n",
        "                      \"type\": \"khcc_validation_error\",\n",
        "                      \"description\": f\"Invalid date format in treatment tracker for radiology checks (first: {first_radio_date_str}, full: {full_radio_date_str}).\"\n",
        "                 })\n",
        "                 validation_outcome[\"is_valid\"] = False\n",
        "\n",
        "        # Add more KHCC-specific checks here as needed...\n",
        "        # E.g., Check if staging (proposed_stage) is present if biopsy/radiology reports are complete\n",
        "        # E.g., Check if a treatment plan exists if staging is complete and patient status is appropriate\n",
        "\n",
        "        if khcc_issues:\n",
        "             validation_outcome[\"is_valid\"] = False # KHCC issues fail validation\n",
        "             validation_outcome[\"issues\"].extend(khcc_issues) # Add KHCC issues to main issues list\n",
        "             validation_outcome[\"khcc_workflow_checks\"] = khcc_issues # Store KHCC issues separately too\n",
        "             logging.error(f\"KHCC-specific workflow validation failed with {len(khcc_issues)} issues.\")\n",
        "        else:\n",
        "             validation_outcome[\"passed_checks\"].append(\"KHCC-specific workflow checks passed (if applicable).\")\n",
        "             logging.info(\"KHCC-specific workflow validation passed.\")\n",
        "\n",
        "    else:\n",
        "         # If no treatment tracker exists, and it was expected (e.g., for oncology patients)\n",
        "         # This check is partly covered in step 3, but can add a specific KHCC note here\n",
        "         if scenario.get(\"patient_type\") in [\"new\", \"relapsed\"] or any(p.is_cancer_related for p in final_problems):\n",
        "              khcc_issues.append({\n",
        "                   \"type\": \"khcc_timeline_compliance\",\n",
        "                   \"description\": \"Oncology patient identified, but no treatment tracker was created or found.\"\n",
        "              })\n",
        "              validation_outcome[\"is_valid\"] = False\n",
        "              validation_outcome[\"issues\"].extend(khcc_issues)\n",
        "              validation_outcome[\"khcc_workflow_checks\"] = khcc_issues\n",
        "              logging.error(\"KHCC validation failed: Oncology patient without treatment tracker.\")\n",
        "         else:\n",
        "              validation_outcome[\"passed_checks\"].append(\"No treatment tracker expected or found (non-oncology scenario).\")\n",
        "              logging.debug(\"No treatment tracker expected or found (non-oncology scenario).\")\n",
        "\n",
        "\n",
        "    # --- Final Summary ---\n",
        "    if validation_outcome[\"is_valid\"]:\n",
        "        validation_outcome[\"summary\"] = \"Validation successful.\"\n",
        "        logging.info(\"Validation successful.\")\n",
        "    else:\n",
        "        validation_outcome[\"summary\"] = \"Validation failed. See issues.\"\n",
        "        logging.error(\"Validation failed.\")\n",
        "\n",
        "    return validation_outcome\n",
        "\n",
        "print(\"âœ… validate_results function updated with KHCC-specific workflow checks.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "740e9e13"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the main `medical_testing_suite` function that orchestrates the execution and validation of all test scenarios, reporting the overall results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dff78b74"
      },
      "source": [
        "import logging\n",
        "from typing import Dict, Any, List, Optional\n",
        "import datetime\n",
        "\n",
        "# Assuming execute_scenario, validate_results, and test_scenarios are defined\n",
        "\n",
        "def medical_testing_suite(test_scenarios: Optional[Dict[str, Dict[str, Any]]] = None) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Comprehensive testing suite for validating the multi-agent medical workflow.\n",
        "\n",
        "    Executes each defined scenario and validates the results against expectations,\n",
        "    including medical accuracy, performance benchmarks, and KHCC-specific rules.\n",
        "\n",
        "    Args:\n",
        "        test_scenarios: A dictionary where keys are scenario names and values\n",
        "                        are dictionaries containing scenario inputs and expectations.\n",
        "                        If None, uses the predefined global test_scenarios.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary summarizing the results of all test scenarios, including\n",
        "        validation outcomes and a final pass/fail status.\n",
        "    \"\"\"\n",
        "    logging.info(\"Starting medical testing suite...\")\n",
        "\n",
        "    # Use the provided scenarios or the global ones if none provided\n",
        "    scenarios_to_run = test_scenarios if test_scenarios is not None else globals().get('test_scenarios', {})\n",
        "\n",
        "    if not scenarios_to_run:\n",
        "        logging.error(\"No test scenarios found.\")\n",
        "        return {\"overall_status\": \"failed\", \"summary\": \"No test scenarios were provided or found.\", \"scenario_results\": {}}\n",
        "\n",
        "    overall_results: Dict[str, Any] = {\n",
        "        \"overall_status\": \"pending\",\n",
        "        \"total_scenarios\": len(scenarios_to_run),\n",
        "        \"passed_scenarios\": 0,\n",
        "        \"failed_scenarios\": 0,\n",
        "        \"scenario_results\": {},\n",
        "        \"summary\": \"\"\n",
        "    }\n",
        "\n",
        "    for scenario_name, scenario_data in scenarios_to_run.items():\n",
        "        logging.info(f\"\\n--- Running Scenario: {scenario_name} ---\")\n",
        "        scenario_data[\"description\"] = scenario_name # Add scenario name to data for logging\n",
        "\n",
        "        try:\n",
        "            # Execute the scenario workflow\n",
        "            results = execute_scenario(scenario_data)\n",
        "            logging.debug(f\"Execution results for {scenario_name}: {json.dumps(results, indent=2)}\")\n",
        "\n",
        "            # Validate the results\n",
        "            validation_outcome = validate_results(scenario_data, results)\n",
        "            logging.debug(f\"Validation outcome for {scenario_name}: {json.dumps(validation_outcome, indent=2)}\")\n",
        "\n",
        "            # Store results and validation outcome\n",
        "            overall_results[\"scenario_results\"][scenario_name] = {\n",
        "                \"execution_results\": results,\n",
        "                \"validation_outcome\": validation_outcome\n",
        "            }\n",
        "\n",
        "            # Update overall counts\n",
        "            if validation_outcome[\"is_valid\"]:\n",
        "                overall_results[\"passed_scenarios\"] += 1\n",
        "                logging.info(f\"Scenario '{scenario_name}' PASSED validation.\")\n",
        "            else:\n",
        "                overall_results[\"failed_scenarios\"] += 1\n",
        "                logging.error(f\"Scenario '{scenario_name}' FAILED validation.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle unexpected errors during scenario execution or validation\n",
        "            overall_results[\"failed_scenarios\"] += 1\n",
        "            error_msg = f\"An unexpected error occurred during scenario '{scenario_name}' execution or validation: {e}\"\n",
        "            logging.error(error_msg, exc_info=True) # Log the full traceback\n",
        "            overall_results[\"scenario_results\"][scenario_name] = {\n",
        "                \"execution_results\": {\"final_status\": \"Error\", \"errors\": [error_msg]},\n",
        "                \"validation_outcome\": {\"is_valid\": False, \"issues\": [{\"type\": \"unexpected_error\", \"description\": error_msg}], \"summary\": \"Validation aborted due to unexpected error.\"}\n",
        "            }\n",
        "            logging.error(f\"Scenario '{scenario_name}' FAILED due to unexpected error.\")\n",
        "\n",
        "\n",
        "    # Determine overall status and summary\n",
        "    if overall_results[\"failed_scenarios\"] == 0:\n",
        "        overall_results[\"overall_status\"] = \"passed\"\n",
        "        overall_results[\"summary\"] = f\"All {overall_results['total_scenarios']} scenarios passed.\"\n",
        "        logging.info(\"Medical testing suite completed successfully.\")\n",
        "    else:\n",
        "        overall_results[\"overall_status\"] = \"failed\"\n",
        "        overall_results[\"summary\"] = f\"{overall_results['failed_scenarios']} of {overall_results['total_scenarios']} scenarios failed.\"\n",
        "        logging.error(\"Medical testing suite completed with failures.\")\n",
        "\n",
        "    return overall_results\n",
        "\n",
        "print(\"âœ… medical_testing_suite function defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c66959d9"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Test Scenarios Defined:** Specific test cases for different medical scenarios (new oncology patient, treatment delay, complex oncology case) were successfully structured in a Python dictionary, including inputs like clinical notes and expected outputs like problems, care plans, and treatment tracker states.\n",
        "*   **Mock Data Generators Implemented:** Functions were created to generate mock `MedicalProblem`, `CarePlan`, and `PatientTreatmentTracker` objects, allowing for flexible creation of test history data for various patient types (new, relapsed, regular) and oncology details.\n",
        "*   **Scenario Execution Logic:** A function `execute_scenario` was developed to take a scenario dictionary, extract inputs, optionally generate mock history, call the core workflow processing function (`process_medical_workflow`), and return the results.\n",
        "*   **Comprehensive Validation Logic:** The `validate_results` function was implemented to compare the workflow output against the expected results defined in the scenarios. It includes flexible matching for problems and care plans using string similarity, checks for expected alerts, processing mode, merging behavior, and priority escalation.\n",
        "*   **Performance Benchmarking:** Logic was added to `execute_scenario` to measure the execution time of the workflow. `validate_results` was updated to include checks against performance benchmarks for execution time, validation accuracy (using validation confidence), and a placeholder for treatment timeline accuracy.\n",
        "*   **KHCC Workflow Validation:** Specific checks for KHCC (King Hussein Cancer Center) workflow rules were integrated into `validate_results`, including verifying the 30-day treatment target calculation, checking for corresponding actions/alerts when pathology needs repeating is flagged, and validating the presence and order of radiology dates in the treatment tracker.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   Refine the treatment timeline accuracy benchmark in `validate_results` to use specific date comparisons or calculated delay metrics from the `PatientTreatmentTracker` rather than relying solely on overall validation confidence.\n",
        "*   Expand the test scenario coverage to include more edge cases and specific KHCC workflow variations, such as scenarios involving treatment plan modifications, patient status changes, specific alert triggers, and variations in clinical note phrasing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0750cb7"
      },
      "source": [
        "# Task\n",
        "Generate the `medical_output_manager` function and all necessary helper functions and visualizations as described in the plan. Include the specified output formats (JSON, CSV, Markdown), stakeholder-specific formatting, clinical visualizations, and KHCC integration hooks. Ensure the function takes the `MedicalAgentState` and output parameters and returns the formatted output. Also, update the testing suite to include checks for the output manager's functionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3000f3f4"
      },
      "source": [
        "## Define output formats\n",
        "\n",
        "### Subtask:\n",
        "Create helper functions for generating output in JSON, CSV, and Markdown formats, considering the specified content for each.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5eee4cf"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the helper functions for generating output in JSON, CSV, and Markdown formats as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e23769a"
      },
      "source": [
        "import json\n",
        "import csv\n",
        "import io\n",
        "import logging\n",
        "\n",
        "# Assuming MedicalAgentState, MedicalProblem, CarePlan, PatientTreatmentTracker are defined\n",
        "\n",
        "def format_output_json(state: MedicalAgentState, stakeholder: Literal[\"clinical\", \"administrative\", \"patient\"] = \"clinical\") -> str:\n",
        "    \"\"\"\n",
        "    Formats the relevant final output data from MedicalAgentState into a JSON string,\n",
        "    tailored for a specific stakeholder.\n",
        "\n",
        "    Args:\n",
        "        state: The final MedicalAgentState object.\n",
        "        stakeholder: The target audience for the output ('clinical', 'administrative', 'patient').\n",
        "\n",
        "    Returns:\n",
        "        A JSON string representation of the output.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Formatting output as JSON for {stakeholder} stakeholder...\")\n",
        "    output_data = {}\n",
        "\n",
        "    # Common data included for all stakeholders in JSON\n",
        "    output_data[\"patient_mrn\"] = state.patient_mrn\n",
        "    output_data[\"note_date\"] = state.note_date\n",
        "    output_data[\"processing_mode\"] = state.processing_mode\n",
        "    output_data[\"final_status\"] = \"Completed\" if state.is_complete and not state.errors else \"Completed with Errors\" if state.errors else \"Processing Incomplete\"\n",
        "\n",
        "    if stakeholder == \"clinical\":\n",
        "        output_data[\"final_problems\"] = [p.model_dump() for p in state.final_problems] if state.final_problems else []\n",
        "        output_data[\"final_care_plans\"] = [cp.model_dump() for cp in state.final_care_plans] if state.final_care_plans else []\n",
        "        output_data[\"treatment_tracker\"] = state.treatment_tracker.model_dump() if state.treatment_tracker else None\n",
        "        output_data[\"priority_alerts\"] = state.priority_alerts\n",
        "        output_data[\"workflow_alerts\"] = state.workflow_alerts\n",
        "        output_data[\"action_recommendations\"] = state.action_recommendations\n",
        "        output_data[\"validation_results\"] = state.validation_results\n",
        "        output_data[\"validation_confidence\"] = state.validation_confidence\n",
        "        output_data[\"errors\"] = state.errors\n",
        "        output_data[\"warnings\"] = state.warnings\n",
        "        output_data[\"agent_history\"] = state.agent_history\n",
        "        if DEBUG:\n",
        "            output_data[\"debug_logs\"] = state.debug_logs\n",
        "\n",
        "\n",
        "    elif stakeholder == \"administrative\":\n",
        "        # Administrative focus: metrics, workflow, resource implications\n",
        "        output_data[\"total_problems_identified\"] = len(state.final_problems)\n",
        "        output_data[\"total_care_plans_identified\"] = len(state.final_care_plans)\n",
        "        output_data[\"overdue_care_plans_count\"] = len([cp for cp in state.final_care_plans if cp.workflow_status in [\"overdue\", \"delayed\"]])\n",
        "        output_data[\"critical_priority_problems_count\"] = len([p for p in state.final_problems if p.priority_flag == 'critical'])\n",
        "        output_data[\"urgent_care_plans_count\"] = len([cp for cp in state.final_care_plans if cp.urgency_level == 'urgent'])\n",
        "        if state.treatment_tracker:\n",
        "             output_data[\"treatment_delay_days\"] = state.treatment_tracker.days_remaining_or_delayed if state.treatment_tracker.date_first_therapy_started is None else 0 # Only count if not started\n",
        "             output_data[\"patient_status_tracker\"] = state.treatment_tracker.patient_status\n",
        "        else:\n",
        "             output_data[\"treatment_delay_days\"] = None\n",
        "             output_data[\"patient_status_tracker\"] = None\n",
        "\n",
        "        output_data[\"processing_metrics\"] = state.processing_metrics\n",
        "        output_data[\"validation_confidence\"] = state.validation_confidence\n",
        "        output_data[\"errors_count\"] = len(state.errors)\n",
        "        output_data[\"warnings_count\"] = len(state.warnings)\n",
        "        output_data[\"priority_alerts\"] = state.priority_alerts # Include critical alerts\n",
        "        output_data[\"workflow_alerts\"] = state.workflow_alerts # Include workflow alerts\n",
        "\n",
        "        # Placeholder for resource considerations if LLM provided them\n",
        "        if state.priority_analysis and state.priority_analysis.get(\"resource_conflicts\"):\n",
        "            output_data[\"resource_considerations\"] = state.priority_analysis[\"resource_conflicts\"]\n",
        "\n",
        "\n",
        "    elif stakeholder == \"patient\":\n",
        "        # Patient focus: simplified summary, next steps, key issues\n",
        "        output_data[\"patient_name\"] = \"Patient Name (Placeholder)\" # Assume name lookup is possible\n",
        "        output_data[\"summary_for_patient\"] = \"A summary of your recent visit has been processed.\" # Simple introductory message\n",
        "        # Provide simplified lists focusing on key information\n",
        "        output_data[\"your_main_health_concerns\"] = [{\"name\": p.problem_name, \"status\": p.status, \"priority\": p.priority_flag} for p in state.final_problems if p.priority_flag in [\"critical\", \"important\"]]\n",
        "        output_data[\"upcoming_appointments_or_actions\"] = [{\"plan\": cp.suggested_plan, \"due_date\": cp.date_due, \"status\": cp.workflow_status, \"urgency\": cp.urgency_level} for cp in state.final_care_plans if cp.workflow_status not in [\"completed\", \"cancelled\"]]\n",
        "        if state.treatment_tracker:\n",
        "             output_data[\"treatment_timeline_status\"] = state.treatment_tracker.get_timeline_status()\n",
        "        else:\n",
        "             output_data[\"treatment_timeline_status\"] = \"No specific treatment timeline is being tracked.\"\n",
        "\n",
        "        # Simplify alerts for the patient\n",
        "        output_data[\"important_updates_or_alerts\"] = state.priority_alerts + [alert for alert in state.workflow_alerts if \"CRITICAL\" in alert or \"URGENT\" in alert]\n",
        "        output_data[\"recommended_next_steps\"] = state.action_recommendations # Use action recommendations directly\n",
        "\n",
        "\n",
        "    # Use json.dumps with indentation for pretty printing\n",
        "    return json.dumps(output_data, indent=2)\n",
        "\n",
        "def format_output_csv(state: MedicalAgentState, stakeholder: Literal[\"clinical\", \"administrative\", \"patient\"] = \"clinical\") -> str:\n",
        "    \"\"\"\n",
        "    Formats the final problems and care plans into a CSV string,\n",
        "    tailored for a specific stakeholder.\n",
        "\n",
        "    Args:\n",
        "        state: The final MedicalAgentState object.\n",
        "        stakeholder: The target audience for the output ('clinical', 'administrative', 'patient').\n",
        "\n",
        "    Returns:\n",
        "        A CSV string representation of problems and care plans.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Formatting output as CSV for {stakeholder} stakeholder...\")\n",
        "    csv_output = io.StringIO()\n",
        "    writer = csv.writer(csv_output)\n",
        "\n",
        "    writer.writerow([f\"--- Medical Data for Patient MRN: {state.patient_mrn} ({stakeholder.capitalize()}) ---\"])\n",
        "    writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "\n",
        "    if stakeholder in [\"clinical\", \"administrative\"]:\n",
        "        # Clinical and Administrative need detailed problem and care plan lists\n",
        "        # Write Problems\n",
        "        writer.writerow([\"--- Medical Problems ---\"])\n",
        "        problem_headers = [\"Problem ID\", \"Problem Name\", \"Status\", \"Priority Flag\", \"Severity Level\",\n",
        "                           \"Is Cancer Related\", \"Is Treatment Related\", \"Is Psychosocial\",\n",
        "                           \"Requires Immediate Attention\", \"Date Identified\", \"Last Updated\", \"Evidence\"]\n",
        "        if stakeholder == \"administrative\":\n",
        "            problem_headers = [\"Problem Name\", \"Status\", \"Priority Flag\", \"Is Cancer Related\"] # Simplified for admin\n",
        "        writer.writerow(problem_headers)\n",
        "        if state.final_problems:\n",
        "            for p in state.final_problems:\n",
        "                if stakeholder == \"clinical\":\n",
        "                     writer.writerow([\n",
        "                        p.problem_id, p.problem_name, p.status, p.priority_flag, p.severity_level,\n",
        "                        p.is_cancer_related, p.is_treatment_related, p.is_psychosocial,\n",
        "                        p.requires_immediate_attention, p.date_identified, p.last_updated, p.evidence\n",
        "                    ])\n",
        "                elif stakeholder == \"administrative\":\n",
        "                     writer.writerow([\n",
        "                        p.problem_name, p.status, p.priority_flag, p.is_cancer_related\n",
        "                    ])\n",
        "        writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "        # Write Care Plans\n",
        "        writer.writerow([\"--- Care Plans ---\"])\n",
        "        care_plan_headers = [\"Plan ID\", \"Suggested Plan\", \"Urgency Level\", \"Plan Urgency\",\n",
        "                             \"Workflow Status\", \"Date Due\", \"Date Initiated\", \"Date Completed\",\n",
        "                             \"Days Overdue\", \"Patient Status\", \"Critical Finding\", \"Action Type\",\n",
        "                             \"Note Date\", \"Note Author\", \"Estimated Duration\"]\n",
        "        if stakeholder == \"administrative\":\n",
        "             care_plan_headers = [\"Suggested Plan\", \"Urgency Level\", \"Workflow Status\", \"Date Due\", \"Days Overdue\", \"Action Type\"] # Simplified for admin\n",
        "        writer.writerow(care_plan_headers)\n",
        "        if state.final_care_plans:\n",
        "            for cp in state.final_care_plans:\n",
        "                if stakeholder == \"clinical\":\n",
        "                    writer.writerow([\n",
        "                        cp.plan_id, cp.suggested_plan, cp.urgency_level, cp.plan_urgency,\n",
        "                        cp.workflow_status, cp.date_due, cp.date_initiated, cp.date_completed,\n",
        "                        cp.days_overdue, cp.patient_status, cp.critical_finding, cp.action_type,\n",
        "                        cp.note_date, cp.note_author, cp.estimated_duration\n",
        "                    ])\n",
        "                elif stakeholder == \"administrative\":\n",
        "                     writer.writerow([\n",
        "                        cp.suggested_plan, cp.urgency_level, cp.workflow_status, cp.date_due, cp.days_overdue, cp.action_type\n",
        "                    ])\n",
        "        writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "        # Write Treatment Timeline (for clinical and administrative)\n",
        "        if state.treatment_tracker:\n",
        "            writer.writerow([\"--- Treatment Timeline ---\"])\n",
        "            treatment_headers = [\"Patient Status\", \"Date First Visit\", \"Date Should Start Treatment\",\n",
        "                                 \"Days Remaining or Delayed\", \"Proposed Stage\", \"Pathology Needs Repeat\",\n",
        "                                 \"Date First Pathology Report\", \"Date First Radiology Report\",\n",
        "                                 \"Date Full Radiology Evaluation\", \"First Therapy Type\", \"Date First Therapy Started\"]\n",
        "            if stakeholder == \"administrative\":\n",
        "                 treatment_headers = [\"Patient Status\", \"Date Should Start Treatment\", \"Days Remaining or Delayed\", \"Proposed Stage\", \"Pathology Needs Repeat\"] # Simplified\n",
        "            writer.writerow(treatment_headers)\n",
        "            tracker = state.treatment_tracker\n",
        "            if stakeholder == \"clinical\":\n",
        "                 writer.writerow([\n",
        "                    tracker.patient_status, tracker.date_first_visit, tracker.date_should_start_treatment,\n",
        "                    tracker.days_remaining_or_delayed, tracker.proposed_stage, tracker.pathology_needs_repeat,\n",
        "                    tracker.date_first_pathology_report, tracker.date_first_radiology_report,\n",
        "                    tracker.date_full_radiology_evaluation, tracker.first_therapy_type, tracker.date_first_therapy_started\n",
        "                 ])\n",
        "            elif stakeholder == \"administrative\":\n",
        "                 writer.writerow([\n",
        "                    tracker.patient_status, tracker.date_should_start_treatment, tracker.days_remaining_or_delayed,\n",
        "                    tracker.proposed_stage, tracker.pathology_needs_repeat\n",
        "                 ])\n",
        "            writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "\n",
        "    elif stakeholder == \"patient\":\n",
        "        # Patient CSV: Simplified list of active problems and upcoming plans\n",
        "        writer.writerow([\"--- Your Health Information ---\"])\n",
        "        writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "        writer.writerow([\"--- Main Health Concerns ---\"])\n",
        "        problem_headers_patient = [\"Problem Name\", \"Status\", \"Priority\"]\n",
        "        writer.writerow(problem_headers_patient)\n",
        "        if state.final_problems:\n",
        "            for p in state.final_problems:\n",
        "                if p.priority_flag in [\"critical\", \"important\"] or p.status == \"Active\": # Focus on active or high priority\n",
        "                    writer.writerow([p.problem_name, p.status, p.priority_flag])\n",
        "        writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "        writer.writerow([\"--- Your Action Plan / Next Steps ---\"])\n",
        "        care_plan_headers_patient = [\"Suggested Plan\", \"Due Date\", \"Status\", \"Urgency\"]\n",
        "        writer.writerow(care_plan_headers_patient)\n",
        "        if state.final_care_plans:\n",
        "            for cp in state.final_care_plans:\n",
        "                if cp.workflow_status not in [\"completed\", \"cancelled\"]: # Focus on pending/active plans\n",
        "                    writer.writerow([cp.suggested_plan, cp.date_due, cp.workflow_status, cp.urgency_level])\n",
        "        writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "        if state.treatment_tracker and state.treatment_tracker.patient_status in [\"new\", \"relapsed\"]:\n",
        "             writer.writerow([\"--- Treatment Timeline Status ---\"])\n",
        "             writer.writerow([\"Status\", \"Target Start Date\", \"Days Remaining/Delayed\"])\n",
        "             tracker = state.treatment_tracker\n",
        "             writer.writerow([tracker.get_timeline_status(), tracker.date_should_start_treatment, tracker.days_remaining_or_delayed])\n",
        "             writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "\n",
        "    # Add Alerts and Warnings for clinical and administrative\n",
        "    if stakeholder in [\"clinical\", \"administrative\"] and (state.priority_alerts or state.workflow_alerts or state.errors or state.warnings):\n",
        "         writer.writerow([\"--- Alerts and Issues ---\"])\n",
        "         if state.priority_alerts:\n",
        "              for alert in state.priority_alerts:\n",
        "                   writer.writerow([\"PRIORITY ALERT\", alert])\n",
        "         if state.workflow_alerts:\n",
        "              for alert in state.workflow_alerts:\n",
        "                   writer.writerow([\"WORKFLOW ALERT\", alert])\n",
        "         if state.errors:\n",
        "              for error in state.errors:\n",
        "                   writer.writerow([\"ERROR\", error])\n",
        "         if state.warnings:\n",
        "              for warning in state.warnings:\n",
        "                   writer.writerow([\"WARNING\", warning])\n",
        "         writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "\n",
        "    # Add Processing Metrics for administrative\n",
        "    if stakeholder == \"administrative\" and state.processing_metrics:\n",
        "         writer.writerow([\"--- Processing Metrics ---\"])\n",
        "         for key, value in state.processing_metrics.items():\n",
        "              writer.writerow([key, str(value)]) # Convert value to string for CSV\n",
        "         writer.writerow([]) # Add empty row for separation\n",
        "\n",
        "\n",
        "    return csv_output.getvalue()\n",
        "\n",
        "def format_output_markdown(state: MedicalAgentState, stakeholder: Literal[\"clinical\", \"administrative\", \"patient\"] = \"clinical\") -> str:\n",
        "    \"\"\"\n",
        "    Formats the final medical summary, alerts, errors, and warnings into a Markdown string,\n",
        "    tailored for a specific stakeholder.\n",
        "\n",
        "    Args:\n",
        "        state: The final MedicalAgentState object.\n",
        "        stakeholder: The target audience for the output ('clinical', 'administrative', 'patient').\n",
        "\n",
        "    Returns:\n",
        "        A Markdown string representation of the summary and issues.\n",
        "    \"\"\"\n",
        "    logging.info(f\"Formatting output as Markdown for {stakeholder} stakeholder...\")\n",
        "    markdown_output = \"\"\n",
        "\n",
        "    # --- Header ---\n",
        "    markdown_output += f\"# Patient Information Summary - MRN: {state.patient_mrn}\\n\\n\"\n",
        "    if stakeholder == \"patient\":\n",
        "         markdown_output += f\"## Summary for {state.patient_mrn}\\n\\n\" # Use MRN for patient view\n",
        "    else:\n",
        "         markdown_output += f\"Note Date: {state.note_date}\\n\"\n",
        "         markdown_output += f\"Author: {state.note_author}\\n\\n\"\n",
        "         # Include clinical note snippet only for clinical\n",
        "         if stakeholder == \"clinical\":\n",
        "              clinical_note_snippet = state.clinical_note[:500] + \"...\" if len(state.clinical_note) > 500 else state.clinical_note\n",
        "              markdown_output += f\"**Clinical Note Snippet:**\\n{clinical_note_snippet}\\n\\n\"\n",
        "\n",
        "    # --- Generated Summary (Main Content) ---\n",
        "    if state.final_medical_summary and stakeholder == \"clinical\":\n",
        "         # Include the full generated summary for clinical users\n",
        "        markdown_output += state.final_medical_summary\n",
        "    elif stakeholder == \"patient\":\n",
        "         # Provide a simplified summary for patients\n",
        "         markdown_output += \"Based on the recent clinical note and your health history, here is a summary of key information:\\n\\n\"\n",
        "         markdown_output += \"## Your Main Health Concerns\\n\\n\"\n",
        "         important_problems = [p for p in state.final_problems if p.priority_flag in [\"critical\", \"important\"] or p.status == \"Active\"]\n",
        "         if important_problems:\n",
        "              for p in important_problems:\n",
        "                   markdown_output += f\"- **{p.problem_name}**: Status: {p.status}, Priority: {p.priority_flag}\\n\"\n",
        "                   if p.evidence:\n",
        "                        markdown_output += f\"  *Evidence:* {p.evidence[:100]}...\\n\" # Snippet of evidence\n",
        "         else:\n",
        "              markdown_output += \"No major health concerns identified in this note.\\n\"\n",
        "\n",
        "         markdown_output += \"\\n## Your Action Plan / Next Steps\\n\\n\"\n",
        "         upcoming_plans = [cp for cp in state.final_care_plans if cp.workflow_status not in [\"completed\", \"cancelled\"]]\n",
        "         if upcoming_plans:\n",
        "              for cp in upcoming_plans:\n",
        "                   markdown_output += f\"- **{cp.suggested_plan}**: Due: {cp.date_due}, Status: {cp.workflow_status}, Urgency: {cp.urgency_level}\\n\"\n",
        "                   if cp.estimated_duration:\n",
        "                        markdown_output += f\"  *Estimated Duration:* {cp.estimated_duration}\\n\"\n",
        "         else:\n",
        "              markdown_output += \"No specific immediate actions or plans identified in this note.\\n\"\n",
        "\n",
        "         if state.treatment_tracker and state.treatment_tracker.patient_status in [\"new\", \"relapsed\"]:\n",
        "              markdown_output += \"\\n## Treatment Timeline Status\\n\\n\"\n",
        "              markdown_output += f\"**Overall Status:** {state.treatment_tracker.get_timeline_status()}\\n\"\n",
        "              markdown_output += f\"**Target Start Date:** {state.treatment_tracker.date_should_start_treatment}\\n\"\n",
        "              if state.treatment_tracker.days_remaining_or_delayed > 0:\n",
        "                   markdown_output += f\"**Delay:** {state.treatment_tracker.days_remaining_or_delayed} days delayed.\\n\"\n",
        "              elif state.treatment_tracker.days_remaining_or_delayed < 0:\n",
        "                   markdown_output += f\"**Days Remaining:** {abs(state.treatment_tracker.days_remaining_or_delayed)} days until target start.\\n\"\n",
        "\n",
        "         if state.priority_alerts or state.workflow_alerts:\n",
        "              markdown_output += \"\\n## Important Updates or Alerts\\n\\n\"\n",
        "              # Simplify alerts - only include critical or urgent ones for patients\n",
        "              patient_alerts = state.priority_alerts + [alert for alert in state.workflow_alerts if \"CRITICAL\" in alert or \"URGENT\" in alert]\n",
        "              if patient_alerts:\n",
        "                   for alert in patient_alerts:\n",
        "                        markdown_output += f\"- {alert}\\n\"\n",
        "              else:\n",
        "                   markdown_output += \"No urgent updates or alerts at this time.\\n\"\n",
        "\n",
        "\n",
        "    # --- Action Items / Recommendations (for clinical and administrative) ---\n",
        "    if stakeholder in [\"clinical\", \"administrative\"] and state.action_recommendations:\n",
        "        markdown_output += \"## Action Items & Recommendations\\n\\n\"\n",
        "        for rec in state.action_recommendations:\n",
        "            markdown_output += f\"- {rec}\\n\"\n",
        "        markdown_output += \"\\n\" # Add space after recommendations\n",
        "\n",
        "\n",
        "    # --- Alerts and Warnings (for clinical and administrative) ---\n",
        "    if stakeholder in [\"clinical\", \"administrative\"] and (state.priority_alerts or state.workflow_alerts or state.errors or state.warnings):\n",
        "         markdown_output += \"## System Alerts and Issues\\n\\n\"\n",
        "         if state.priority_alerts:\n",
        "              markdown_output += \"**PRIORITY ALERTS:**\\n\"\n",
        "              for alert in state.priority_alerts:\n",
        "                   markdown_output += f\"- {alert}\\n\"\n",
        "              markdown_output += \"\\n\"\n",
        "         if state.workflow_alerts:\n",
        "              markdown_output += \"**WORKFLOW ALERTS:**\\n\"\n",
        "              for alert in state.workflow_alerts:\n",
        "                   markdown_output += f\"- {alert}\\n\"\n",
        "              markdown_output += \"\\n\"\n",
        "         if state.errors:\n",
        "              markdown_output += \"**ERRORS:**\\n\"\n",
        "              for error in state.errors:\n",
        "                   markdown_output += f\"- {error}\\n\"\n",
        "              markdown_output += \"\\n\"\n",
        "         if state.warnings:\n",
        "              markdown_output += \"**WARNINGS:**\\n\"\n",
        "              for warning in state.warnings:\n",
        "                   markdown_output += f\"- {warning}\\n\"\n",
        "              markdown_output += \"\\n\"\n",
        "\n",
        "\n",
        "    # --- Processing Details (for clinical and administrative, optional debug) ---\n",
        "    if stakeholder in [\"clinical\", \"administrative\"]:\n",
        "         markdown_output += \"## System Processing Details\\n\\n\"\n",
        "         markdown_output += f\"Processing Mode: {state.processing_mode}\\n\"\n",
        "         markdown_output += f\"Validation Confidence: {state.validation_confidence:.2f}\\n\"\n",
        "         markdown_output += f\"Total Problems Identified: {len(state.final_problems)}\\n\"\n",
        "         markdown_output += f\"Total Care Plans Identified: {len(state.final_care_plans)}\\n\"\n",
        "         markdown_output += f\"Iterations: {state.iterations}\\n\"\n",
        "         if state.processing_metrics:\n",
        "             markdown_output += \"**Processing Metrics:**\\n\"\n",
        "             for key, value in state.processing_metrics.items():\n",
        "                 markdown_output += f\"- {key}: {value}\\n\"\n",
        "\n",
        "         if DEBUG and state.debug_logs:\n",
        "              markdown_output += \"\\n## Debug Logs\\n\\n\"\n",
        "              for log in state.debug_logs:\n",
        "                   markdown_output += f\"- {log}\\n\"\n",
        "\n",
        "         markdown_output += \"\\n**Agent History:**\\n\"\n",
        "         for entry in state.agent_history:\n",
        "              markdown_output += f\"- {entry}\\n\"\n",
        "\n",
        "\n",
        "    return markdown_output\n",
        "\n",
        "print(\"âœ… Helper functions updated with stakeholder-specific formatting.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}